/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *//*/*	Peter J. Wagner: pwagner@fmnh.org/*	Matthew Kosnik: mkosnik@uchicago.edu/*/*	This file is copyright (C) 2001, 2009 Peter J. Wagner & Matthew Kosnik/*/*	This program is free software; you can redistribute it and/or modify it /*	under the terms of version 2 the GNU General Public License as published /*	by the Free Software Foundation./*/*	This program is distributed in the hope that it will be useful, but WITHOUT/*	ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or /*	FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for /*	more details./*/*	To view a copy of the license go to:/*	http://www.fsf.org/copyleft/gpl.html/*	To receive a copy of the GNU General Public License write the Free Software/* 	Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA./*/*	Copies of this source code are available without cost from:/*	http://geosci.uchicago.edu/paleo/csource//*/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */#define distribution_fits#include <time.h>#include "distribution_fits.h"#include "matrixanalysis.h"#include "matrixreading.h"#include "minmax.h"#include "memory.h"#include "Probability.h"/* CALCULATES THE LOG LIKELIHOOD OF A GIVEN DISTRIBUTIONMultinomialNEEDS: -	A = theoretical distribution -	R = size of A  -	S = actual distribution -	N = abundance of S -	Z = size of SRETURNS: -	L = Summed log likelihood***********************************************************************/double calc_likelihood(double *A, int *S, int N, int Z) {double L = 0.0f;							/* Summed Log Likelihood */double a = 0.0f, b = 0.0f;int i = 0;									/* loop variable *//* CALCULATE LOG LIKELIHOOD FOR EACH TAXON IN BOTH LISTS	*/for (i=0; i<Z; i++) { 	a = log(A[i]) * S[i];					/* a = pi ^ni */	b = log(1-A[i]) * (N-S[i]);				/* b = (1 - pi) ^ (N-ni) */	L+=(a+b);								/* Sum L for all taxa */	}if (L>0) L=-1*DBL_MAX;						/* if c blows out = very bad fit */return L;}/* CALCULATES THE LOG LIKELIHOOD OF A GIVEN DISTRIBUTIONProbability of A finds from N specimens given hypothesized frequency based on Foote (in prep.)  NEEDS: -	A[i] = proportion for taxon rank i from the hypothetical distribution -	n[i] = number of specimens/occurrences for specimen i -	N = total number of specimens RETURNS: -	L = Summed log likelihood***********************************************************************/double calc_likelihood_Foote(double *A, int *n, int N) {double L = 0.0f;						/* Summed Log Likelihood */double lnp = 0.0f;						/* taxon support */double a = 0.0f, b = 0.0f, c = 0.0f;	/* temp variables */int i;									/* loop variable *//* CALCULATE LOG LIKELIHOOD FOR EACH TAXON WITH n > 1	*/for (i=0; n[i]>1; i++) {		a = log(A[i]) * n[i];				/* a = pi ^ni */	b = log(1-A[i]) * (N-n[i]);			/* b = (1 - pi) ^ (N-ni) */	c = log(1 - pow((1-A[i]),N));		/* c = 1 - ( 1 - pi ) ^ N - the probability of being sampled */	if (c>0)		c=0;							/* sometimes this gets wonky - blows out */	lnp = (a + b) - c;					/* L = (a * b) / c */	L+=lnp;								/* Sum L for all taxa */	}if (L>0) L=-1*DBL_MAX;					/* if c blows out = very bad fit */return L;}/* CALCULATES THE LOG LIKELIHOOD OF A DISTRIBUTION GIVEN OBSERVED AND EXPECTED NUMBERS OF TAXA WITH X FINDS P. Wagner 11/14/2003 NEEDS: -	X[i] = expected proportion for taxa with nufinds[i] finds -	nufinds[i] = number of finds (of the pool of observed unique numbers of finds) -	histogram[n] = observed number of taxa with n finds -  unqfinds = the number of number of finds (= richness+1 if all taxa have a unique number, = 2 if all taxa have the same number of finds [+1 for unsampled taxa]) RETURNS: -	L = Summed log likelihood*************************************************************************************************/double calc_likelihood_exp(double *X, long *nufinds, long *histogram, int unqfnds){double L = 0.0f;						/* Summed Log Likelihood */double a = 0.0f;						/* temp variables */int i, n;								/* loop variable */for (i=1; i<unqfnds; ++i)	{	n=nufinds[i];	a=histogram[n];	L = L+(a*log(X[i]));	}if (L>0) L=-1*DBL_MAX;					/* if c blows out = very bad fit */return L;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE UNIFORM DISTRIBUTION ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *count_fit_mul_uni(int *empdist, int ntaxa, int nspec){int i = 0;					/* LOOP VARIABLE													*/int r = 0;					/* LOOP RICHNESS													*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rin;					/* initial slope													*/int ri;						/* how much to increment ev in each loop							*/int lri[2];					/* last two slope increments										*/int iri;					/* initial slope increment at each richness							*/double rs[3];				/* previous log likelihoods (cell number = num previous).			*/double *brp;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist;			/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbes;				/* previous best support for decay rate								*/brp=dvector(2);for (i=0; i<2; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */rin=chao2(empdist,ntaxa);pbes = 0.0f;for (i=0; i<2; i++) brp[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) rs[i] = 0.0f;lri[0]=lri[1]=0.0f;ri=iri=rin/2;while (ri+rin<= ntaxa)	ri/=2;obsrvd[0]=0;for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{/*	obsrvd[0]=r-ntaxa;	*/	fitdist=dvector(r);	for (i=0; i<r; ++i)	fitdist[i]=1/((double) r);	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	rs[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	free_dvector(expect);	if (rs[0] >= brp[0]) {					/* IF BETTER THAN BEST FIT */		pbes = brp[0];						/* save last best ssq for evenness */		brp[0] = rs[0];						/* STORE FIT */		brp[1] = r;							/* STORE SLOPE */				/* while we are getting better on the initial increment, just ride with it			*/		if (ri==iri)	{			lri[1]=lri[0];			lri[0]=ri;			}		else if ((r-ri)>=ntaxa)	{			lri[1]=lri[0];			lri[0]=ri;			ri*=-1;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lri[1]=lri[0];			lri[0]=ri;			ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		}	/* if this richness is better than the last		*/	/* optimal richness is overshot 				*/	else {		r=brp[1];				/* step back to best richness	 */				/* if we start off going downhill, then cut the increment in half */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (ri%2==0 || abs(ri)==1)	ri/=2;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(ri)==1)				ri=0;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;/*			if (rs[1]>rs[0])	{				if (				if (ri%2==0 || abs(ri)==1)	ri/=-2;				else						ri=(ri/abs(ri))*(abs(ri)+1)/-2;				}			else	{				if (ri%2==0 || abs(ri)==1)	ri/=2;				else						ri=(ri/abs(ri))*(abs(ri)+1)/2;				}	*/			}		/* if this increment is half of the last, then reverse it - unless that goes too low! */		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)			ri*=-1;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		else	{			if (ri%2==0 || abs(ri)==1)	ri/=2;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		}		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! */	while ((r+ri)< ntaxa)	ri=(ri/abs(ri))*(abs(ri)+1)/2;		rs[2] = rs[1];	rs[1] = brp[0];		if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *count_fit_mul_geo(int *empdist, int ntaxa, int nspec) {int i = 0;					/* LOOP VARIABLE													*/int r = 0;					/* LOOP RICHNESS													*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double es[3];				/* previous log likelihoods (cell number = num previous).			*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist;			/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbes;				/* previous best support for decay rate								*/double x;bep=dvector(2);for (i=0; i<2; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */if (empdist[ntaxa-1]>=1)/*	ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));	*/	ein=pow(10,(log10(empdist[0])-log10(empdist[ntaxa-1]))/((double) (ntaxa-1)));else/*	ein=pow(empdist[0],1/((double) ntaxa));	*/	ein=pow(10,(log10(empdist[0])-1)/((double) (ntaxa-1)));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;iei=ein-1;if (ei==0)	ei=0.00001f;pbes = 0.0f;/*	ei = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;lei[0]=lei[1]=0.0f;ei=iei;while (ei+ein<= emin)	ei/=2;for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {			x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	r=x;	if ((x-r)>0.5)	++r;	if (r>=ntaxa)	{		/* generate geometric distribution with richness r and decay of ev */		fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION */		expect=expfinds(fitdist,r,nspec,nspec);		expect[0]=0;		x=sumdvector(expect,nspec+1);		for (i=1; i<=nspec; ++i)	expect[i]/=x;		free_dvector(fitdist);	//	x=sumdvector(expect,nspec);	//	for (r=1; r<=nspec; ++r)	expect[r]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		}			else	es[0]=-1*DBL_MAX;	/*Debugging line */	if (ev<=emin) printf("\nDANGER: Geo R=%d, ev=%f, S=%f ",r,ev,es[0]);	if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */		pbes = bep[0];								/* save last best ssq for evenness */		bep[0] = es[0];								/* STORE FIT */		bep[1] = ev;								/* STORE SLOPE */				/* while we are getting better on the initial increment, just ride with it			*/		if (ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			if (ev==(ein+iei))	{				ei/=-2;				}			else if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that	*//*				if (es[0]>es[2])	ei/=2;				else				ei/=-2;	*/				ei/=2;							/* redone 20.03.2009 to get this to search properly	*/				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*//*				if (es[0]>es[1])	ei/=2;				else				ei/=-2;	*/				if (fabs(lei[0])==ei)	ei/=2;				else					ei*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || (2*fabs(ei)==fabs(lei[0])))	{			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4				if (es[0]>es[2])	ei/=2;			/* otherwise go to ev-x/2												else				ei*=-1;	*/			if (fabs(lei[0])==ei)		{				lei[1]=lei[0];				lei[0]=ei;				ei/=2;					}			else	{				lei[1]=lei[0];				lei[0]=ei;				ei*=-1;				}			}		ev=bep[1];		}	/* make sure that ei does not take ev below 1.0 */	while (ev+ei<= emin)	{		if (fabs(lei[0])==fabs(lei[1]))	ei/=2;		else							ei=-1*lei[0];		}			es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}free_dvector(obsrvd);return bep;}/* CALCULATE LIKELIHOOD OF BEST GEOMETRIC SERIES OF FINITE RICHNESS ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *count_fit_mul_geos(int *empdist, int ntaxa, int nspec) {int i = 0;					/* LOOP VARIABLE													*/int r = 0;					/* LOOP RICHNESS													*/int ri;						/* richness increment												*/int iri;					/* initial richness increment each loop								*/int lri[2];					/* last two richness increments										*/int rin;					/* initial richness													*/int mxr=5000;				/* this is as long as we can make an array							*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double es[3];				/* previous log likelihoods (cell number = num previous).			*/double rs[3];				/* previous log likelihoods (cell number = num previous).			*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array		*/double *fitdist;			/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbes;				/* previous best support for decay rate								*/double x;					/* sum of expected number of taxa									*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */if (empdist[ntaxa-1]>=1)	ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));else	ein=pow(empdist[0],1/((double) ntaxa));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);if (rin<ntaxa)	rin=ntaxa;iri=ri=ntaxa/4;if (ri<2)	iri=ri=2;iei=ein-1;if (ei==0)	ei=0.00001f;for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;		for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate geometric distribution with richness r and decay of ev */		fitdist = proportional_geos_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds *///		expect=expfindsprop(fitdist,r,nspec,nspec);		expect=expfinds(fitdist,r,nspec,nspec);		expect[0]=0;		x=sumdvector(expect,nspec+1);		for (i=1; i<=nspec; ++i)	expect[i]/=x;		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei/=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (fabs(ei)==fabs(iei))	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei/=-2;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}	/* end case where ei is no the original */				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* reset evenness incrementer */	if (r!=rin)		iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */	else if (r==rin || ei==0)		iei=bep[1]-ein;		/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* optimal richness is overshot */	else {		r=brp[2];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! */	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	{				if (abs(ri)==1)	ri=0;			else			ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		}		/* geometric might go on and on forever with miniscule increases when it is a very poor fit */	if (ri==iri && ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC))))	ri=0;			if (ei<0)	iei*=-1;	if (ei<mei)	iei=100*mei;		rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD OF BEST ZIPF SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_mul_zipf(int *empdist, int ntaxa, int nspec){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;					/* initial richness increment each loop									*/int	lri[2];					/* recent changes in richness											*/int mxr=10000;				/* this is as long as we can make an array								*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rin;					/* initial richness 													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 0.000000f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double rs[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array			*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double x;					/* sum of expected number of taxa									*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the Zipf-Mandelbrot, based on the log-log slopes between the initial taxa */if (empdist[0]>empdist[1] && empdist[1]>1)	ein=(log(empdist[0])/log(empdist[1]));if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;if (ntaxa>=10)	{	ev=((double) empdist[9])/((double) empdist[0]);	ein=-1*log(ev)/log(10);	}if (ein<emin)/*	ein=pow((log(empdist[0])/log(empdist[6])),0.5);	*/		if (empdist[2]==1 && empdist[0]>empdist[1])		ein=pow((log(empdist[0])/log(empdist[1])),2);if (ein<emin)	ein=0.50f;/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);iri=ri=ntaxa/4;if (ri<2)	iri=ri=2;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/iei=ein/2;if (iei==0)	iei=0.00001f;obsrvd[0]=0;for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{/*	obsrvd[0]=r-ntaxa;	*/	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein< emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds *//*		expect=expfindsprop(fitdist,r,nspec,nspec);	*/		expect=expfinds(fitdist,r,nspec,nspec);		expect[0]=0;		x=sumdvector(expect,nspec+1);		for (i=1; i<=nspec; ++i)	expect[i]/=x;		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei/=-1;				}			}	/* end case where likelihood is improved	*/							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (fabs(ei)==fabs(iei))	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei/=-2;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}	/* end case where ei is no the original */				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;								if (ev+ei<= emin)	{					if (fabs(lei[0])==fabs(lei[1]))	ei/=-2;					else							ei/=-1;					}				}			ev=bep[1];			}	/* end case where likelihood is not improved	*/		/* make sure that ei does not take ev below 1.0 *//*		if (ev+ei<= emin)	ei/=2;	*/		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* reset evenness incrementer */	if (r!=rin)		iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */	else if (r==rin || ei==0)		iei=bep[1]-ein;		/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* optimal richness is overshot */		else {		r=brp[2];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}	/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! 	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	ri/=2;		}				*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;	/*	if (abs(ri)%2==1 && abs(ri)>1)	{		if (ri>0)	++ri;		else		--ri;		}	*/	if (ei<0)	iei*=-1;	if (ei<mei)	iei=100*mei;		rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD OF THE BEST UNTRUNCATED LOG-NORMAL SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: magnitude of increase per octave	- result[2]: optimal richnessCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_mul_lgn(int *empdist, int ntaxa, int nspec) {int i=0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;					/* initial richness increment each loop									*/int lri[2];					/* previous richness increment											*/int rin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxr=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double rs[3];				/* previous richness log likelihoods (cell number = num previous).		*/double bep[2];				/* BEST decay for hypothesized evenness at given S - return array format */double *brp;				/* BEST richness parameters - return array								*/double pbes;				/* previous best support for modal decay								*/double pbrs;				/* previous best support for richness									*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *fitdist;			/* fit distribution												*/double mdmx;double x;					/* sum of expected number of taxa									*/brp=dvector(3);for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);iri=ri=ntaxa/4;if (ri<2)	ri=2;lri[0]=lri[1]=0;	if (2*rin<10)			mdmx=1.5;else if (2*rin<20)		mdmx=2.0;else if (2*rin<75)		mdmx=2.5;else if (2*rin<350)		mdmx=3.0;else if (2*rin<2000)	mdmx=3.5;else if (2*rin<15000)	mdmx=4.0;else 					mdmx=4.5;if (rin%2==1)				r=empdist[rin/2];else						r=(((double) empdist[rin/2])+((double) empdist[(rin/2)-1]))/2;if (rin/2 < ntaxa)			ein = pow(e,(log(((double) empdist[0])/((double) empdist[rin/2]))/mdmx));else	{	if (empdist[ntaxa-1]>0)	ein = pow(e,(log(((double) empdist[0])/((double) empdist[ntaxa-1]))/mdmx));	else					ein = pow(e,log(((double) empdist[0])/mdmx));	}if (ein==1)	ein=1.20f;iei=ein-1;pbrs=0.0f;for (i=0; i<3; i++) brp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	rs[i]= -1.0*DBL_MAX;/* adjust true richness until that fails to improve likelihood	*/for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	/* generally speaking, if you decrease richness, then you increase the probability of observation	*/	/* 		by increasing evenness, which means looking at lower values of ev.							*/	if (r!=rin && r<brp[2])			if (ei>0)	ei*=-1;	else if (r!=rin && r>brp[2])	if (ei<0)	ei*=-1;		/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate log-normal distribution with richness r and decay of magnitude of increase ev */		fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		expect[0]=0;		x=sumdvector(expect,nspec+1);		for (i=1; i<=nspec; ++i)	expect[i]/=x;		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */						/* while we are getting better on the initial increment, or its negative, just ride with it			*/			if (fabs(ei)==fabs(iei))	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei*=-1;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/		if ((ev+ei)<=emin)	{			if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/			else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/			}		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* end cases of improved richness parameter */	/* optimal richness is overshot */	else {		r=brp[2];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! 	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	ri/=2;		}	*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;	/*	if (abs(ri)%2==1 && abs(ri)>1)	{		if (ri>0)	++ri;		else		--ri;		}	*/	rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD OF BEST TRUNCATED LOG-NORMAL SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood (truncated)	- result[1]: magnitude of increase per octave (truncated)	- result[2]: optimal richness (truncated)	- result[3]: mode (truncated)	- result[4]: log likelihood (untruncated)	- result[5]: magnitude of increase per octave (untruncated)	- result[6]: optimal richness (untruncated)		- result[7]: mode of untruncated is 0COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_mul_lnt(int *empdist, int ntaxa, int nspec) {int j=0,i=0;			/* LOOP VARIABLE															*/int r = 0;				/* LOOP RICHNESS															*/int ri;					/* richness increment														*/int iri;				/* initial richness increment each loop										*/int lri[2];				/* previous richness increment												*/int rin=0;				/* initial richness to use in each search (begins as ntaxa)					*/int mxr=5000;			/* this is as long as we can make an array									*/int unqfnd=0;			/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double mode;			/* mode of log-normal, given as a taxon number								*/double x=1.0f;			/* x is the absolute value of the mode - cannot do abs(double)				*/double y=1.0f;double z=1.0f;double mi=-1.0f;		/* how much to increment the mode											*/double imi=-1.0f;double lmi[2];			/* prior increment															*/double mimin=0.125;		/* minimum mode change													*/double mdmx=1.5f;double mdmn=-2.5f;double tr;double ev = 0.000f;		/* LOOP SLOPE 																*/double emin = 1.00f;	/* min slope																*/double mxev=75.0f;		/* maximum magnitude change to consider										*/double ein = 0.000f;	/* initial slope															*/double ei = 0.000f;		/* how much to increment ev in each loop									*/double iei;				/* initial slope increment at each richness								*/double aei=0.00f;		/* absolute evenness increment											*/double mei=0.000001f;	/* minimum evenness increment											*/double es[3];			/* previous modal decay log likelihoods (cell number = num previous).		*/double rs[3];			/* previous richness log likelihoods (cell number = num previous).			*/double ms[3];			/* previous mode log likelihoods (cell number = num previous).				*/double bep[2];			/* BEST modal decay parameters - return array format 						*/double brp[3];			/* BEST richness parameters - return array									*/double pbes;			/* previous best support for modal decay									*/double pbrs;			/* previous best support for richness										*/double pbms;			/* previous best support for mode location									*/double *expect;			/* expected number of species with 0Émax finds								*/double *obsrvd;			/* observed number of species with 0Émax finds								*/double *fitdist;		/* fit distribution															*/double *bmp;			/* Best mode parameters - return array format								*/double lei[2];			/* last evenness increment													*/bmp=dvector(8);for (i=0; i<8; i++) bmp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);if (rin<100)			j=4;else					j=5;if (2*rin<75)			mdmx=2.5;else if (2*rin<350)		mdmx=3.0;else if (2*rin<2000)	mdmx=3.5;else if (2*rin<15000)	mdmx=4.0;else 					mdmx=4.5;if (rin/2 < ntaxa)	ein = pow(e,log(empdist[0]/empdist[rin/2])/mdmx);else				ein = pow(e,log(empdist[0]/empdist[ntaxa-1])/mdmx);aei=iei=ein-1;mdmn=-1*mdmx;/*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/for (i=0; i<3; ++i)	ms[i]=-1.0*DBL_MAX;pbms=0.0f;/* adjust mode until that fails to improve likelihood	*/	/* for some reason the program is disobeying the second part of the conditional */imi=mi;for (mode=0; x>=mimin && (mode>=mdmn && mode<=mdmx)/* && ((pbms == 0.0f) || (bmp[0] > (pbms + SUPINC)))*/; mode+=mi)	{	if (mode==0)	{/*		ei = ein-0.95;	*/		tr=0;		}	else	{/*		ei = ein/10;	*/		tr=1;		}		iei=-1*(ein-1.05);		pbrs=0.0f;	for (i=0; i<3; i++) brp[i]=-1.0*DBL_MAX;	for (i=0; i<3; ++i)	rs[i]= -1.0*DBL_MAX;	/* adjust true richness until that fails to improve likelihood	*/	lri[0]=ri=rin;	if (ri<2)	ri=2;			iri=ri;	for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{		obsrvd[0]=0;		pbes = 0.0f;		/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/		for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;		for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;		lei[0]=lei[1]=0.0f;		ei=iei;		/* increment slope until that fails to improve likelihood or resolution limit reached */		for (ev = ein; ((ev>=emin && aei>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {							/* generate log-normal distribution with richness r and decay of magnitude of increase ev */			fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */			/* find the expected proportions of taxa with 0Éx finds *//*			expect=expfindsprop(fitdist,r,nspec,nspec);	*/			expect=expfinds(fitdist,r,nspec,nspec);			expect[0]=0;			x=sumdvector(expect,nspec+1);			for (i=1; i<=nspec; ++i)	expect[i]/=x;			free_dvector(fitdist);			es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);			free_dvector(expect);			/*Debugging line */			if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);			if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */				pbes = bep[0];								/* save last best ssq for evenness */				rs[0]=bep[0] = es[0];						/* STORE FIT */				bep[1] = ev;								/* STORE SLOPE */								/* while we are getting better on the initial increment, just ride with it			*/				if (ei==iei)	{					lei[1]=lei[0];					lei[0]=ei;					}				/* if we have a later improvement, wander halfway back to the last improvement 	*/				/* (remember, we always start at the most likely slope up to that point			*/				else	{					lei[1]=lei[0];					lei[0]=ei;					ei/=-2;					}				}									/* If likelihood has not increased, then reset and change the increment  value	*/			else	{				/* if we went from x -> -x, then we want to cut the increment in half */				if (ei==-1*lei[0] || ei==iei)	{					lei[1]=lei[0];					lei[0]=ei;					if (ei==iei)	{						/* determine whether es[0] or es[2] is the second best - move towards that	*/						if (es[0]>es[2])	ei/=2;						else				ei/=-2;						}					else	{						/* determine whether es[0] or es[1] is the second best - move towards that	*/						if (es[0]>es[1])	ei/=2;						else				ei/=-2;						}					}				/* if we just divided in half, then we want to reverse the increment */				else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{					lei[1]=lei[0];					lei[0]=ei;					/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/					if (es[0]>es[2])	ei/=2;					/* otherwise go to ev-x/2									*/					else				ei*=-1;					}				ev=bep[1];				}			/* make sure that ei does not take ev below 1.0 */			while (ev+ei<= emin)	ei/=2;			es[2] = es[1];									/* Store last 2 attempts to identify	*/			es[1] = es[0];									/* when the peak is past 				*/			aei=ei;											/* tally absolute evenness increment	*/			if (aei<0)	aei*=-1;			}		/* reset evenness incrementer */		if (r!=rin)			aei=iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */		else if (r==rin || ei==0)			aei=iei=bep[1]-ein;				/* if this richness is better than the last */		if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */			brp[2] = r;			for (i=0; i<2; i++)				brp[i] = bep[i];			ein=bep[1];										/* set initial decay to best decay found so far */ 			/* if we are past the initial ri, then we want to use it only once	*/			/* otherwise, we repeat r's											*/			if (r!=rin)	{				lri[1]=lri[0];				lri[0]=ri;				}			if (ri!=iri && ri!=(-1*iri))		ri/=2;			}		/* optimal richness is overshot */		else {			r=brp[2];				/* step back to best richness	 */					/* if we start off going downhill, then go the other way */			if (ri==iri && r==rin)	{				lri[1]=lri[0];				lri[0]=ri;				ri*=-1;				while ((r+ri)<ntaxa)		ri/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (abs(ri)==abs(lri[0]))	{				lri[1]=lri[0];				lri[0]=ri;				/* go towards the one with the higher likelihood */				if (rs[1]>rs[0])			ri/=-2;				else						ri/=2;				}			/* if this increment is less then the last, then */			else if (abs(ri)<abs(lri[0]))	{				lri[1]=lri[0];				lri[0]=ri;				ri*=-1;				}			}				/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */		/* do not bother going for r < observed! */		while ((r+ri)>mxr || (r+ri)< ntaxa)	{			if (r==mxr)	ri*=-1;			else	ri/=2;			}				if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;				if (abs(ri)%2==1 && abs(ri)>1)	{			if (ri>0)	++ri;			else		--ri;			}		if (ei<0)	iei*=-1;		if (ei<mei)	iei=100*mei;		aei=iei;		if (aei<0)	aei*=-1;				rs[2] = rs[1];		rs[1] = bep[0];		}	/* if this mode is better than the last */	if (brp[0] >= bmp[0]) {								/* IF BETTER THAN BEST FIT */		pbms=bmp[0];		for (i=0; i<3; i++)			bmp[i] = brp[i];		bmp[3] = mode;		/* save the best untruncated log-normal separately */		if (mode==0)	{			for (i=0; i<3; ++i)	bmp[i+4]=brp[i];			bmp[7]=0;			}		/* if we are truncating the log-normal, then we want to use the mode shift only once */		else {			lmi[1]=lmi[0];			lmi[0]=mi;			}		if (mi!=imi && mi!=(-1*imi))	mi/=2;		}	/* optimal mode is overshot */	else	{		mode=bmp[3];		if (mi==imi && mode==0)	{			lmi[1]=lmi[0];			lmi[0]=mi;			mi*=-1;			}		else if (mi==(-1*lmi[0]) || mi==lmi[0])	{			lmi[1]=lmi[0];			lmi[0]=mi;			if (ms[1]>ms[0])	mi/=-2;			else				mi/=2;			} 		else if (abs(mi)<abs(lmi[0]))	{			lmi[1]=lmi[0];			lmi[0]=mi;			mi*=-1;			}		}	/* it might go on and on forever with miniscule increases when it is a very poor fit */	if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))	ri=0;	ms[2] = ms[1];	ms[1] = brp[0];/*	if (msw>=2 && mrn==1)	{		mi/=2;		if (mi<1)	x=-1*mi;		mrn=0;		}	*/		/* do not overshoot mode limits! */	while ((mode+mi<mdmn || mode+mi>mdmx) && x>mimin)	{		mi/=2;		if (mi<1)	x=-1*mi;		}			ein=bmp[1];										/* set initial modal decay to best modal decay found so far 	*/ 	rin=bmp[2];										/* set initial richness to best richness found so far			*/	x=mi;	if (x<0)	x*=-1;	}free_dvector(obsrvd);return bmp;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE ZERO-SUM MULTINOMIAL SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: most likely m	- result[2]: most likely thetaCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_mul_zsm(int *empdist, int ntaxa, int nspec){int i=0, j=0;					/* LOOP VARIABLE															*/int	 mt, tt, mtb;				/* loop busters	*/int theospc=5*nspec;			/* theoretical number of total specimens									*/double m=0.0f;					/* m for loop																*/double mi=0.25f;				/* m increment																*/double imi=0.25f;				/* initial m increment each loop											*/double lmi[2];					/* previous m increment														*/double min=0.75f;				/* initial m to use in each search (begins as ntaxa)						*/long double mmx=0.999999f;		/* maximum m to consider													*/long double mmn=0.000001f;		/* minimum m																*/double lti[2];					/* last two theta incrementers												*/double iti;						/* initial slope increment at each m										*/double theta=0.000f;			/* LOOP theta 																*/double tin=10.000f;				/* initial theta															*/double tmin=0.01f;				/* min theta slope															*/double ti=10.000f;				/* how much to increment theta in each loop									*/double mti=0.0001f;				/* minimum theta increment													*/double ts[11];					/* previous modal decay log likelihoods (cell number = num previous).		*/double ms[3];					/* previous m log likelihoods (cell number = num previous).					*/double *btp;					/* BEST decay for hypothesized theta at given S - return array format 		*/double bmp[2];					/* BEST m parameters - return array											*/double pbms;					/* previous best support for m												*/double pbts=-1*DBL_MAX;			/* previous best support for theta											*/double *expind;					/* expected number of species with 0Émax individuals						*/double *expsamp;				/* expected number of species with 0Émax finds								*/double *obsrvd;					/* observed number of species with 0Émax finds								*/double x,y,z;					/* dummy															*/btp=dvector(3);for (i=0; i<3; i++) btp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ts[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);tin=chao2(empdist,ntaxa);tin*=0.3;ti=iti=tin/4;mti=0.0001*iti;lti[0]=tin;lti[1]=0.0f;	/*min=(mmx+mmn)/2;		/* it seems that m's on either side of 0.85 repeat each other....	*//*imi=(1-min)/2;	*//* adjust true m until that fails to improve likelihood	*/mtb=tt=0;for (theta = tin; ((theta>=tmin && fabs(ti)>mti) || pbts == -1*DBL_MAX); theta += ti) {		/*Debugging line */	if (theta<=tmin) 	{		printf("\nDANGER: theta=%f, m=%f ",theta, m);			}	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	bmp[0]=bmp[1]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	mi=imi;		pbms=-1*DBL_MAX;	min=0.9999999f;	mi=imi=-2;	mt=0;	/* find the best theta for this m */	for (m=mmx; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expind=zerosum(theta,m,theospc);				x=sumdvector(expind,theospc);		if (x>=ntaxa)	{			for (j=1; expind[j]>0 && j<theospc; j=j)	++j;			expsamp=expfindsfromexpindprop(expind,j,nspec);			free_dvector(expind);			ms[0]=lnmultinomsuff(obsrvd,expsamp,empdist[0]+1);				free_dvector(expsamp);			}		else	{			ms[0]=-1*DBL_MAX;			free_dvector(expind);			}		/* if this m is better than the last */		if (ms[0] >= bmp[0] && ms[0]>-1*DBL_MAX) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			bmp[0]=ms[0];								/* STORE FIT */			bmp[1]=m;									/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;				if (mi==imi)						mi=(mmn-mmx)/2;				else if (m+mi<mmn || m+mi>mmx)		mi/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)						mi*=-1;			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*///		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))		else if ((bmp[1]==mmx || bmp[1]==mmn) && fabs(mi)<fabs(imi)/32)			mi=0;					/* if it is trying to get past the maximum, then kill it	*/		else if ((bmp[1]==mmx && (bmp[0]<btp[0] && btp[1]>mmx)) && (bmp[0]>ms[0] && (bmp[0]>ms[1] && bmp[0]>ms[2])))			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*/		else if (bmp[0]<1.25*btp[0] && (mt>=mtb && mtb>5))			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		++mt;		}	/* end search for m */	ts[0]=bmp[0];	if (ts[0] >= btp[0] && ts[0]>-1*DBL_MAX) {							/* IF BETTER THAN BEST FIT */		pbts = btp[0];								/* save last best ssq for theta */		btp[0] = ts[0];								/* STORE FIT */		btp[1] = bmp[1];							/* STORE m */		btp[2] = theta;								/* STORE m */				mtb=mt;										/* number of tries to find the best m	*/		/* while we are getting better on the initial increment, just ride with it			*/		if (fabs(ti)==fabs(iti))	{			lti[1]=lti[0];			lti[0]=ti;			if (theta+ti<tmin)				ti/=-2;						/* to avoid local optima, at least on intial search */			else if (btp[0] <= (pbts + SUPINC))	{				/* return to prior theta	*/				if (theta==(tin+iti))	{					theta=tin;					ti*=-1;					pbts-=1.0f;					}				else if (theta==(tin-iti))	{					theta=tin;					ti/=2;					pbts-=1.0f;					}				}	/* end case where we had trivial improvement within one step of initial theta */			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lti[1]=lti[0];			lti[0]=ti;			ti/=2;			if (theta+ti<tmin)				ti/=-1;			}		}	/* end case where likelihood has improved	*/					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		lti[1]=lti[0];		lti[0]=ti;		if (fabs(ti)==fabs(iti))	{			/* if the first increment does not help, then reverse direction	*/			if (theta==tin+iti)				ti*=-1;			/* if an increment after the first stops helping, then go half way	*/			else							ti/=2;			if (theta+ti<tmin)				ti/=-2;			}		else	{			if (fabs(lti[0])==fabs(lti[1]))	ti/=2;			else							ti*=-1;			if (theta+ti<tmin)				ti/=-2;			}/*			if (ti==-1*lti[0] || ti==iti)	{			if (ti==iti)	{				/* determine whether ts[0] or ts[2] is the second best - move towards that	/				if (ts[0]>ts[2])	ti/=2;				else				ti/=-2;				}			else	{				/* determine whether ts[0] or ts[1] is the second best - move towards that	/				if (ts[0]>ts[1])	ti/=2;				else				ti/=-2;				}			}		/* if we just divided in half, then we want to reverse the increment /		else if (ti==-1*iti || (2*ti==lti[0] || -2*ti==lti[0]))	{			/* if theta+x/2 got closer than theta-x, back up and go to theta+x/4	/			if (fabs(ti)==fabs(lti[0]))	ti/=2;			else						ti*=-1;			} */		theta=btp[2];		}			/* start the next m at the best m so far *//*	if (btp[1]>0.5)	imi=(mmx-btp[1])/2;	*//*	else			imi=(btp[1]-mmn)/2;	*//*	min=btp[1];		*/	/* make sure that imi is not too small */	if (fabs(imi)<0.0001)	{		if (imi<0)						imi=-0.0001;		else							imi=0.0001;		}	/* make sure that imi does not take m out of bounds */	if (min+imi>mmx || min+imi<mmn)		imi*=-1;	/* make sure that ti does not take theta below 1.0 */	if (theta+ti<= tmin)	{		if (fabs(lti[0])==fabs(ti))			ti/=-2;		else								ti/=-1;		}	if (ts[0]>-1*DBL_MAX)	{		for (i=10; i>0; --i)	 ts[i] = ts[i-1];				/* Store last 2 attempts to identify	*/		++tt;		}	if (tt>5)	{		y=maxdarray(ts,6);		z=mindarray(ts,6);		if (y-z<0.1)	ti=0.0f;		}		if (btp[0] < (pbts + SUPINC) && fabs(ti)<((fabs(iti)/20)))	ti=0.0f;	}	/* end search for theta */free_dvector(obsrvd);return btp;}double *count_fit_mul_zsm_test(int *empdist, int ntaxa, int nspec){int i=0;					/* LOOP VARIABLE															*//*int	r=0;					/* richness (calculated from distribution									*/int theospc=5*nspec;double m=0.0f;				/* m for loop																*/double mi=0.25f;			/* m increment																*/double imi=0.25f;			/* initial m increment each loop											*/double lmi[2];				/* previous m increment														*/double min=0.75f;			/* initial m to use in each search (begins as ntaxa)						*/long double mmx=0.999999f;	/* maximum m to consider													*/double mmn=0.85f;			/* minimum m																*/double lti[2];				/* last two theta incrementers												*/double iti;					/* initial slope increment at each m										*/double theta=0.000f;		/* LOOP theta 																*/double tmin=0.01f;			/* min theta slope															*/double tin=10.000f;			/* initial theta															*/double ti=10.000f;			/* how much to increment theta in each loop									*/double mti=0.0001f;			/* minimum theta increment													*/double ts[3];				/* previous modal decay log likelihoods (cell number = num previous).		*/double ms[3];				/* previous m log likelihoods (cell number = num previous).					*/double *btp;				/* BEST decay for hypothesized theta at given S - return array format 		*/double bmp[2];				/* BEST m parameters - return array											*/double pbms;				/* previous best support for m												*/double pbts=-1*DBL_MAX;		/* previous best support for theta											*/double *expect;				/* expected number of species with 0Émax finds								*/double *obsrvd;				/* observed number of species with 0Émax finds								*//*double *fitdist;			/* fit distribution															*/FILE	*fopen();	FILE 	*outfile;btp=dvector(3);for (i=0; i<3; i++) btp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ts[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);tin=chao2(empdist,ntaxa);tin*=0.3;ti=iti=tin/4;mti=0.0001*iti;lti[0]=tin;lti[1]=0.0f;	min=(mmx+mmn)/2;		/* it seems that m's on either side of 0.85 repeat each other....	*/outfile=fopen("zerosumtest.txt","w");fprintf(outfile,"theta\tÆtheta\tm\tÆm\tlnL\ttime\n");/*imi=(1-min)/2;	*/imi=mmx-min;/* adjust true m until that fails to improve likelihood	*/for (theta = tin; ((theta>=tmin && fabs(ti)>mti) || pbts == -1*DBL_MAX); theta += ti) {		/*Debugging line */	if (theta<=tmin) printf("\nDANGER: theta=%f, m=%f ",theta, m);	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	bmp[0]=bmp[1]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	mi=imi;		pbms=-1*DBL_MAX;	/* find the best theta for this m */	for (m=min; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expect=zerosum(theta,m,theospc);				/*		ms[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	*/		ms[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);		i=time((time_t *)NULL);		fprintf(outfile,"%7.6f\t%7.6f\t%7.6f\t%7.6f\t%7.6f\t%d\n",theta,ti,m,mi,ms[0],i);/*		fflush(stdout);	*/		fclose(outfile);		outfile=fopen("zerosumtest.txt","a");		/* if this m is better than the last */		if (ms[0] >= bmp[0]) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			ts[0]=bmp[0]=ms[0];							/* STORE FIT */			bmp[1]=m;									/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;				if (m+mi<mmn || m+mi>mmx)				mi/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)						mi*=-1;			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*/		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))			mi=0;					/* if it is trying to get past the maximum, then kill it	*/		else if ((bmp[1]==mmx && (bmp[0]<btp[0] && btp[1]>mmx)) && (bmp[0]>ms[0] && (bmp[0]>ms[1] && bmp[0]>ms[2])))			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*/		else if (bmp[0]<1.25*btp[0])			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		}	/* end search for m */	if (ts[0] >= btp[0]) {							/* IF BETTER THAN BEST FIT */		pbts = btp[0];								/* save last best ssq for theta */		btp[0] = ts[0];								/* STORE FIT */		btp[1] = bmp[1];							/* STORE m */		btp[2] = theta;								/* STORE m */				/* while we are getting better on the initial increment, just ride with it			*/		if (fabs(ti)==fabs(iti))	{			lti[1]=lti[0];			lti[0]=ti;			if (theta+ti<tmin)				ti/=-2;						/* to avoid local optima, at least on intial search */			else if (btp[0] <= (pbts + SUPINC))	{				/* return to prior theta	*/				if (theta==(tin+iti))	{					theta=tin;					ti*=-1;					pbts-=1.0f;					}				else if (theta==(tin-iti))	{					theta=tin;					ti/=2;					pbts-=1.0f;					}				}	/* end case where we had trivial improvement within one step of initial theta */			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lti[1]=lti[0];			lti[0]=ti;			ti/=2;			if (theta+ti<tmin)				ti/=-1;			}		}	/* end case where likelihood has improved	*/					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		lti[1]=lti[0];		lti[0]=ti;		if (fabs(ti)==fabs(iti))	{			/* if the first increment does not help, then reverse direction	*/			if (theta==tin+iti)				ti*=-1;			/* if an increment after the first stops helping, then go half way	*/			else							ti/=2;			if (theta+ti<tmin)				ti/=-2;			}		else	{			if (fabs(lti[0])==fabs(lti[1]))	ti/=2;			else							ti*=-1;			if (theta+ti<tmin)				ti/=-2;			}/*			if (ti==-1*lti[0] || ti==iti)	{			if (ti==iti)	{				/* determine whether ts[0] or ts[2] is the second best - move towards that	/				if (ts[0]>ts[2])	ti/=2;				else				ti/=-2;				}			else	{				/* determine whether ts[0] or ts[1] is the second best - move towards that	/				if (ts[0]>ts[1])	ti/=2;				else				ti/=-2;				}			}		/* if we just divided in half, then we want to reverse the increment /		else if (ti==-1*iti || (2*ti==lti[0] || -2*ti==lti[0]))	{			/* if theta+x/2 got closer than theta-x, back up and go to theta+x/4	/			if (fabs(ti)==fabs(lti[0]))	ti/=2;			else						ti*=-1;			} */		theta=btp[2];		}			/* start the next m at the best m so far *//*	if (btp[1]>0.5)	imi=(mmx-btp[1])/2;	*//*	else			imi=(btp[1]-mmn)/2;	*//*	min=btp[1];							*/	/* make sure that imi is not too small */	if (fabs(imi)<0.0001)	{		if (imi<0)						imi=-0.0001;		else							imi=0.0001;		}	/* make sure that imi does not take m out of bounds */	if (min+imi>mmx || min+imi<mmn)		imi*=-1;	/* make sure that ti does not take theta below 1.0 */	if (theta+ti<= tmin)	{		if (fabs(lti[0])==fabs(ti))			ti/=-2;		else								ti/=-1;		}	ts[2] = ts[1];									/* Store last 2 attempts to identify	*/	ts[1] = ts[0];									/* when the peak is past 				*/		if (btp[0] < (pbts + SUPINC) && fabs(ti)<((fabs(iti)/20)))	ti=0.0f;	}	/* end search for theta */tin=btp[2];ti=iti=tin/4;mti=0.0001*iti;mmn=0.0001f;mmx=0.85;lti[0]=tin;lti[1]=0.0f;	min=(mmx+mmn)/2;		/* it seems that m's on either side of 0.85 repeat each other....	*/imi=mmx-min;for (theta = tin; ((theta>=tmin && fabs(ti)>mti) || pbts == -1*DBL_MAX); theta += ti) {		/*Debugging line */	if (theta<=tmin) printf("\nDANGER: theta=%f, m=%f ",theta, m);	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	bmp[0]=bmp[1]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	mi=imi;		pbms=-1*DBL_MAX;	/* find the best theta for this m */	for (m=min; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expect=zerosum(theta,m,theospc);				/*		ms[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	*/		ms[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);		i=time((time_t *)NULL);		fprintf(outfile,"%7.6f\t%7.6f\t%7.6f\t%7.6f\t%7.6f\t%d\n",theta,ti,m,mi,ms[0],i);/*		fflush(stdout);	*/		fclose(outfile);		outfile=fopen("zerosumtest.txt","a");		/* if this m is better than the last */		if (ms[0] >= bmp[0]) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			ts[0]=bmp[0]=ms[0];							/* STORE FIT */			bmp[1]=m;									/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;				if (m+mi<mmn || m+mi>mmx)				mi/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)						mi*=-1;			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*/		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*/		else if (bmp[0]<1.75*btp[0])			mi=0;		else if ((fabs(mi)<fabs(imi)/16) && bmp[0]<1.25*btp[0])			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		}	/* end search for m */	if (ts[0] >= btp[0]) {							/* IF BETTER THAN BEST FIT */		pbts = btp[0];								/* save last best ssq for theta */		btp[0] = ts[0];								/* STORE FIT */		btp[1] = bmp[1];							/* STORE m */		btp[2] = theta;								/* STORE m */				/* while we are getting better on the initial increment, just ride with it			*/		if (fabs(ti)==fabs(iti))	{			lti[1]=lti[0];			lti[0]=ti;			if (theta+ti<tmin)				ti/=-2;						/* to avoid local optima, at least on intial search */			else if (btp[0] <= (pbts + SUPINC))	{				/* return to prior theta	*/				if (theta==(tin+iti))	{					theta=tin;					ti*=-1;					pbts-=1.0f;					}				else if (theta==(tin-iti))	{					theta=tin;					ti/=2;					pbts-=1.0f;					}				}	/* end case where we had trivial improvement within one step of initial theta */			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lti[1]=lti[0];			lti[0]=ti;			ti/=2;			if (theta+ti<tmin)				ti/=-1;			}		}	/* end case where likelihood has improved	*/					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		lti[1]=lti[0];		lti[0]=ti;		if (fabs(ti)==fabs(iti))	{			/* if the first increment does not help, then reverse direction	*/			if (theta==tin+iti)				ti*=-1;			/* if an increment after the first stops helping, then go half way	*/			else							ti/=2;			if (theta+ti<tmin)				ti/=-2;			}		else	{			if (fabs(lti[0])==fabs(lti[1]))	ti/=2;			else							ti*=-1;			if (theta+ti<tmin)				ti/=-2;			}/*			if (ti==-1*lti[0] || ti==iti)	{			if (ti==iti)	{				/* determine whether ts[0] or ts[2] is the second best - move towards that	/				if (ts[0]>ts[2])	ti/=2;				else				ti/=-2;				}			else	{				/* determine whether ts[0] or ts[1] is the second best - move towards that	/				if (ts[0]>ts[1])	ti/=2;				else				ti/=-2;				}			}		/* if we just divided in half, then we want to reverse the increment /		else if (ti==-1*iti || (2*ti==lti[0] || -2*ti==lti[0]))	{			/* if theta+x/2 got closer than theta-x, back up and go to theta+x/4	/			if (fabs(ti)==fabs(lti[0]))	ti/=2;			else						ti*=-1;			} */		theta=btp[2];		}			/* start the next m at the best m so far *//*	if (btp[1]>0.5)	imi=(mmx-btp[1])/2;	*//*	else			imi=(btp[1]-mmn)/2;	*//*	min=btp[1];		*/	/* make sure that imi is not too small */	if (fabs(imi)<0.0001)	{		if (imi<0)						imi=-0.0001;		else							imi=0.0001;		}	/* make sure that imi does not take m out of bounds */	if (min+imi>mmx || min+imi<mmn)		imi*=-1;	/* make sure that ti does not take theta below 1.0 */	if (theta+ti<= tmin)	{		if (fabs(lti[0])==fabs(ti))			ti/=-2;		else								ti/=-1;		}	ts[2] = ts[1];									/* Store last 2 attempts to identify	*/	ts[1] = ts[0];									/* when the peak is past 				*/	if (btp[0] < (pbts + SUPINC) && fabs(ti)<((fabs(iti)/20)))	ti=0.0f;	}	/* end search for theta */free_dvector(obsrvd);fclose(outfile);return btp;}double count_fit_mul_zsm_exact(int *empdist, int ntaxa, int nspec, double theta, double m){int i=0, j=0;				/* LOOP VARIABLE															*/int theospc=5*nspec;		/* theoretical number of total specimens									*/double S;					/* log likelihood							*/double *expind;				/* expected number of species with 0Émax individuals						*/double *expsamp;			/* expected number of species with 0Émax finds								*/double *obsrvd;				/* observed number of species with 0Émax finds								*/double x;					/* dummy															*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);expind=zerosum(theta,m,theospc);x=sumdvector(expind,theospc);for (j=1; expind[j]>0 && j<theospc; j=j)	++j;expsamp=expfindsfromexpindprop(expind,j,nspec);free_dvector(expind);S=lnmultinomsuff(obsrvd,expsamp,empdist[0]+1);	free_dvector(expsamp);/*if (x>=ntaxa)	{	for (j=1; expind[j]>0 && j<theospc; j=j)	++j;	expsamp=expfindsfromexpindprop(expind,j,nspec);	free_dvector(expind);	S=lnmultinomsuff(obsrvd,expsamp,empdist[0]+1);		free_dvector(expsamp);	}else	{	S=-1*DBL_MAX;	free_dvector(expind);	}	*/free_dvector(obsrvd);return S;}/* CALCULATES LIKELIHOOD OF AN AD HOC BEST-FIT DISTRIBUTION ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)RETURNS:	- es: log likelihoodCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double count_fit_mul_best(int *empdist, int ntaxa){int		i;double 	es=0.0f;				/* m for loop																*/double 	*obsrvd;				/* observed number of species with 0Émax finds								*/double 	freq;				/* frequency of taxa with 0Émax finds										*//*double *fitdist;			/* fit distribution															*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);for (i=1; i<=empdist[0]; ++i)	{	freq=obsrvd[i]/((double) ntaxa);	if (obsrvd[i]>0)	es+=obsrvd[i]*log(freq);	}	free_dvector(obsrvd);return es;}/*support_bars_mul_geos - routine to put error bars on richness given a geometric series & a multinomial distribution /* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- bestS (log likelihood of best geometric)	- bestM (slope of best geometric)	- ntaxa (size of array)	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- bars (number of support units)RETURNS:	- sbars[0]: slope parameter	- sbars[1]: support of sbars[0] given dataCOMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double **support_bars_mul_geo (double bestS, double bestM, int ntaxa, int *empdist, double bar){int i=0, j=0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double lev = 0.000f;			/* LOOP SLOPE 															*/double uev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double es;				/* previous log likelihoods (cell number = num previous).				*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double	x;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;rlb=rub=1;es=bestS;if (bestM/100>0.001)	ei=0.001;else					ei=bestM/100;for (ev=lev=bestM; (ev>=emin && (bestS-es)<bar); ev-=ei) {		/* generate Geometric distribution with richness r and log-decay of ev */	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION *///	for (r=1; ((1-(1/ev))*pow((1/ev),(r-1)))>pow(10,-9); r=r)	++r;	x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	r=x;	if ((x-r)>=0.5)	++r;		/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	expect[0]=0;	x=sumdvector(expect,nspec);	for (i=1; i<nspec; ++i)	expect[i]/=x;	es=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	free_dvector(expect);	lev=ev;	++rlb;	}es=bestS;for (ev=uev=bestM+ei; (bestS-es)<bar; ev+=ei) {		/* generate Geometric distribution with richness r and log-decay of ev */	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION *///	for (r=1; ((1-(1/ev))*pow((1/ev),(r-1)))>pow(10,-9); r=r)	++r;	x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	r=x;	if ((x-r)>=0.5)	++r;	/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	expect[0]=0;	x=sumdvector(expect,nspec);	for (i=1; i<nspec; ++i)	expect[i]/=x;	es=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	free_dvector(expect);	uev=ev;	++rub;	}sbars=dmatrix(rub+rlb+2,2);j=0;for (ev=lev; ev<=uev; ev+=ei)	{	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));//	for (r=1; ((1-(1/ev))*pow((1/ev),(r-1)))>pow(10,-9); r=r)	++r;	x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	r=x;	if ((x-r)>=0.5)	++r;	/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);		expect[0]=0;	x=sumdvector(expect,nspec);	for (i=1; i<nspec; ++i)	expect[i]/=x;	sbars[j][1]=ev;	sbars[j][0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	free_dvector(expect);		++j;	}return sbars;}/*support_bars_mul_geos - routine to put error bars on richness given a Geometric distribution*****************************************************************************************/double **support_bars_mul_unif (double bestS, int ntaxa, int bestR, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double diff;				/* difference in log-likelihoods										*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double **sbars;				/* support and slopes for richness values within bar units of support	*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);supportlo[0]=bestS;diff=0;rub=rlb=bestR;for (r=bestR-1; diff<=bar && r>=ntaxa; --r)	{	obsrvd[0]=0;	pbes = 0.0f;	fitdist=dvector(r);	for (i=0; i<r; ++i)	fitdist[i]=1/((double) r);	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);/*	supportlo[abs(bestR-r)-1] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);*/	supportlo[abs(bestR-r)-1]=lnmultinomsuff(obsrvd,expect,nspec);	free_dvector(expect);		diff=fabs(bestS-supportlo[abs(bestR-r)-1]);	rlb=r;	}diff=0;for (r=bestR+1; diff<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=0;	pbes = 0.0f;	fitdist=dvector(r);	for (i=0; i<r; ++i)	fitdist[i]=1/((double) r);	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);/*	supportup[abs(bestR-r)-1] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	*/	supportup[abs(bestR-r)-1]=lnmultinomsuff(obsrvd,expect,nspec);	free_dvector(expect);	diff=fabs(bestS-supportup[abs(bestR-r)-1]);	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=1.0;		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=1.0;		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=1.0;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_mul_geos - routine to put error bars on richness given a geometric series & a multinomial distribution *****************************************************************************************/double **support_bars_mul_geos (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double evlo[1000];			/* evenness maximizing likelihood of richness values below ML richness	*/double evup[1000];			/* evenness maximizing likelihood of richness values above ML richness	*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double x;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(1/((double) nspec));if (iei==0)	iei=-0.00001f;bep[0]=bestS;for (r=bestR-1; fabs(bestS-bep[0])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate Geometric distribution with richness r and log-decay of ev */		fitdist = proportional_geos_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportlo[abs(bestR-r)-1]=bep[0];	evlo[abs(bestR-r)-1]=bep[1];	rlb=r;	}ein=bestM;iei=(2/((double) nspec));if (iei==0)	iei=0.00001f;bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_geos_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportup[abs(bestR-r)-1]=bep[0];	evup[abs(bestR-r)-1]=bep[1];	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=evlo[abs(bestR-r)-1];		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=evup[abs(bestR-r)-1];		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=bestM;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_mul_zipf - routine to put error bars on richness given a Zipf series & a multinomial distribution *****************************************************************************************/double **support_bars_mul_zipf (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double evlo[1000];			/* evenness maximizing likelihood of richness values below ML richness	*/double evup[1000];			/* evenness maximizing likelihood of richness values above ML richness	*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double x;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(2/((double) nspec));if (iei==0)	iei=-0.00001f;bep[0]=bestS;for (r=bestR-1; fabs(bestS-bep[0])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportlo[abs(bestR-r)-1]=bep[0];	evlo[abs(bestR-r)-1]=bep[1];	rlb=r;	}ein=bestM;iei=(2/((double) nspec));if (iei==0)	iei=0.00001f;bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportup[abs(bestR-r)-1]=bep[0];	evup[abs(bestR-r)-1]=bep[1];	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=evlo[abs(bestR-r)-1];		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=evup[abs(bestR-r)-1];		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=bestM;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_mul_lgn - routine to put error bars on richness given a log-normal & a multinomial distribution *******************************************************************************************************************/double **support_bars_mul_lgn (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int counter=0;int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double evlo[1000];			/* evenness maximizing likelihood of richness values below ML richness	*/double evup[1000];			/* evenness maximizing likelihood of richness values above ML richness	*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double x;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(1/((double) nspec));if (iei==0)	iei=-0.00001f;bep[0]=bestS;for (r=bestR-1; fabs(bestS-bep[0])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate lognormal distribution with richness r and magnitude of increase ev */		fitdist = proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		counter=expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (es[0]-es[1] < (1/10000))	++counter;				else							counter=0;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4					if (es[0]>es[2])	ei/=2;*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2				*/												else				ei*=-1;					}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		if (counter==10)	ei=mei;		}	supportlo[abs(bestR-r)-1]=bep[0];	ein=evlo[abs(bestR-r)-1]=bep[1];	rlb=r;	}ein=bestM;iei=(2/((double) nspec));if (iei==0)	iei=0.00001f;bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportup[abs(bestR-r)-1]=bep[0];	ein=evup[abs(bestR-r)-1]=bep[1];	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=evlo[abs(bestR-r)-1];		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=evup[abs(bestR-r)-1];		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=bestM;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_mul_zsm - routine to put error bars on richness given a geometric series & a multinomial distribution /* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- bestS (log likelihood of best geometric)	- bestM (slope of best geometric)	- ntaxa (size of array)	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- bars (number of support units)RETURNS:	- sbars[0]: slope parameter	- sbars[1]: support of sbars[0] given dataCOMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double **support_bars_mul_zsm (double besttheta, double bestm, double bestS, int ntaxa, int *empdist, double bar){int i=0, j=0, k=0;			/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int nspec;					/* number of specimens													*/int theospc;				/* theoretical number of total specimens								*/double *expind;				/* expected number of species with 0Émax individuals					*/double *expsamp;			/* expected number of species with 0Émax finds							*/double theta = 0.000f;		/* LOOP SLOPE 															*/double lth = 0.000f;		/* LOOP SLOPE 															*/double uth = 0.000f;		/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment theta in each loop								*/double es;					/* previous log likelihoods (cell number = num previous).				*/double mmn = 0.000001f;		/* minimum m															*/double mmx = 0.99999f;		/* minimum m															*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double	x;double bmp[3];				/* BEST m parameters - return array											*/double ms[3];				/* previous m log likelihoods (cell number = num previous).					*/double lmi[2];				/* previous m increment														*/double min=0.75f;			/* initial m to use in each search (begins as ntaxa)						*/double imi=0.25f;			/* initial m increment each loop											*/double m=0.0f;				/* m for loop																*/double mi=0.25f;			/* m increment																*/double pbms;				/* previous best support for m												*/int	 mt;			/* loop busters	*/double	**dummy;		/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);theospc=5*nspec;ein=besttheta;rlb=rub=0;es=bestS;ei=besttheta/100;min=bestm;/* do right bound first	*/dummy=dmatrix(10000,4);for (theta=lth=besttheta; (theta>=emin && (bestS-es)<bar); theta-=ei) {	/* generate zero sum distribution with theta and m */	mt=0;	if (min<0.5)	imi=mi=min;	else			imi=mi=(1-min)/2;	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	pbms=bmp[0]=bmp[1]=bmp[2]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	for (m=min; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expind=zerosum(theta,m,theospc);		x=sumdvector(expind,theospc);		k=x;		if ((x-k)>0.5)	++k;		/* if too few taxa, then increment m until you get enough taxa	*/		if (ms[0]==-1.0*DBL_MAX && k<ntaxa)	{			while (k<ntaxa && (mi>0 && m<=mmx))	{				m=m+(mi/2);				expind=zerosum(theta,m,theospc);				x=sumdvector(expind,theospc);				k=x;				if ((x-k)>0.5)	++k;				}	/**/			}		if (k>=ntaxa)	{			for (j=1; expind[j]>0 && j<theospc; j=j)	++j;			expsamp=expfindsfromexpindprop(expind,j,nspec);			free_dvector(expind);			ms[0]=lnmultinomsuff(obsrvd,expsamp,empdist[0]+1);				free_dvector(expsamp);			}		else	{			ms[0]=-1*DBL_MAX;			free_dvector(expind);			}		/* if this m is better than the last */		if (ms[0] >= bmp[0] && ms[0]>-1*DBL_MAX) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			bmp[0]=ms[0];								/* STORE FIT 				*/			bmp[1]=m;									/* STORE SLOPE 				*/			bmp[2]=x;									/* store richness			*/						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;/*				if (mi==imi)						mi=(mmn-mmx)/2;				else if (m+mi<mmn || m+mi>mmx)		mi/=-2;	*/				if (m+mi<mmn || m+mi>mmx)			mi/=2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)	{				if (min>=0.5)	mi*=-1;				else			mi/=-2;				}			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*///		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))		else if ((bmp[1]==mmx || bmp[1]==mmn) && fabs(mi)<fabs(imi)/32)			mi=0;					/* if it is trying to get past the maximum, then kill it	*///		else if ((bmp[1]==mmx && (bmp[0]<btp[0] && btp[1]>mmx)) && (bmp[0]>ms[0] && (bmp[0]>ms[1] && bmp[0]>ms[2])))//			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*///		else if (bmp[0]<1.25*btp[0] && (mt>=mtb && mtb>5))//			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		++mt;				if (theta==besttheta)	mi=0;		}	/* end search for m */	dummy[rlb][0]=es=bmp[0];	/* best support for this theta found	*/	dummy[rlb][1]=lth=theta;	dummy[rlb][2]=min=bmp[1];	/* start with a new m					*/	dummy[rlb][3]=bmp[2];		/* start with a new m					*/	++rlb;	}es=bestS;mmx=bestm;ei=besttheta/10;min=bestm;for (theta=uth=besttheta+ei; (bestS-es)<bar; theta+=ei) 	{	/* generate zero sum distribution with theta and m */	mt=0;	if (min<0.5)	imi=mi=min;	else			imi=mi=(1-min)/2;	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	pbms=bmp[0]=bmp[1]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	for (m=min; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expind=zerosum(theta,m,theospc);		x=sumdvector(expind,theospc);		k=x;		if ((x-k)>0.5)	++k;		if (k>=ntaxa)	{			for (j=1; expind[j]>0 && j<theospc; j=j)	++j;			expsamp=expfindsfromexpindprop(expind,j,nspec);			free_dvector(expind);			ms[0]=lnmultinomsuff(obsrvd,expsamp,empdist[0]+1);				free_dvector(expsamp);			}		else	{			ms[0]=-1*DBL_MAX;			free_dvector(expind);			}		/* if this m is better than the last */		if (ms[0] >= bmp[0] && ms[0]>-1*DBL_MAX) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			bmp[0]=ms[0];								/* STORE FIT 				*/			bmp[1]=m;									/* STORE SLOPE 				*/			bmp[2]=x;									/* store richness			*/						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;/*				if (mi==imi)						mi=(mmn-mmx)/2;				else if (m+mi<mmn || m+mi>mmx)		mi/=-2;	*/				if (m+mi<mmn || m+mi>mmx)			mi/=2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)	{				if (min>=0.5)	mi*=-1;				else			mi/=-2;				}			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*///		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))		else if ((bmp[1]==mmx || bmp[1]==mmn) && fabs(mi)<fabs(imi)/32)			mi=0;					/* if it is trying to get past the maximum, then kill it	*///		else if ((bmp[1]==mmx && (bmp[0]<btp[0] && btp[1]>mmx)) && (bmp[0]>ms[0] && (bmp[0]>ms[1] && bmp[0]>ms[2])))//			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*///		else if (bmp[0]<1.25*btp[0] && (mt>=mtb && mtb>5))//			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		++mt;				if (theta==besttheta)	mi=0;		}	/* end search for m */	dummy[rlb+rub][0]=es=bmp[0];	/* best support for this theta found	*/	dummy[rlb+rub][1]=uth=theta;	dummy[rlb+rub][2]=min=bmp[1];	/* start with a new m					*/	dummy[rlb+rub][3]=bmp[2];	/* start with a new m					*/	++rub;	}sbars=dmatrix(rub+rlb+2,4);/* sbars[0] = ln likelihood   sbars[1] = theta   sbars[2] = m   sbars[3] = richness	*/   for (j=rlb-1; j>0; --j)	{	sbars[(rlb-1)-j][0]=dummy[j][0];	sbars[(rlb-1)-j][1]=dummy[j][1];	sbars[(rlb-1)-j][2]=dummy[j][2];	sbars[(rlb-1)-j][3]=dummy[j][3];	}for (j=rlb; j<(rub+rlb); ++j)	{	sbars[j][0]=dummy[j][0];	sbars[j][1]=dummy[j][1];	sbars[j][2]=dummy[j][2];	sbars[j][3]=dummy[j][3];	}free_dmatrix(dummy,10000,4);return sbars;}double *count_fit_poi_uni(int *empdist, int ntaxa, int nspec){int i = 0;					/* LOOP VARIABLE													*/int r = 0;					/* LOOP RICHNESS													*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rin;					/* initial slope													*/int ri;						/* how much to increment ev in each loop							*/int lri[2];					/* last two slope increments										*/int iri;					/* initial slope increment at each richness							*/double rs[3];				/* previous log likelihoods (cell number = num previous).			*/double *brp;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist;			/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbes;				/* previous best support for decay rate								*/brp=dvector(2);for (i=0; i<2; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */rin=chao2(empdist,ntaxa);/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/pbes = 0.0f;/*	ei = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) brp[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) rs[i] = 0.0f;lri[0]=lri[1]=0.0f;ri=iri=rin/2;while (ri+rin<= ntaxa)	ri/=2;for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	obsrvd[0]=r-ntaxa;		fitdist=dvector(r);	for (i=0; i<r; ++i)	fitdist[i]=1/((double) r);	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	rs[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	free_dvector(expect);	if (rs[0] >= brp[0]) {					/* IF BETTER THAN BEST FIT */		pbes = brp[0];						/* save last best ssq for evenness */		brp[0] = rs[0];						/* STORE FIT */		brp[1] = r;							/* STORE SLOPE */				/* while we are getting better on the initial increment, just ride with it			*/		if (ri==iri)	{			lri[1]=lri[0];			lri[0]=ri;			}		else if ((r-ri)>=ntaxa)	{			lri[1]=lri[0];			lri[0]=ri;			ri*=-1;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lri[1]=lri[0];			lri[0]=ri;			ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		}	/* if this richness is better than the last		*/	/* optimal richness is overshot 				*/	else {		r=brp[1];				/* step back to best richness	 */				/* if we start off going downhill, then cut the increment in half */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (ri%2==0 || abs(ri)==1)	ri/=2;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(ri)==1)				ri=0;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;/*			if (rs[1]>rs[0])	{				if (				if (ri%2==0 || abs(ri)==1)	ri/=-2;				else						ri=(ri/abs(ri))*(abs(ri)+1)/-2;				}			else	{				if (ri%2==0 || abs(ri)==1)	ri/=2;				else						ri=(ri/abs(ri))*(abs(ri)+1)/2;				}	*/			}		/* if this increment is half of the last, then reverse it - unless that goes too low! */		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)			ri*=-1;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		else	{			if (ri%2==0 || abs(ri)==1)	ri/=2;			else						ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		}		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! */	while ((r+ri)< ntaxa)	ri=(ri/abs(ri))*(abs(ri)+1)/2;		rs[2] = rs[1];	rs[1] = brp[0];		if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A POISSON DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *count_fit_poi_geo(int *empdist, int ntaxa, int nspec) {int i = 0;					/* LOOP VARIABLE													*/int r = 0;					/* LOOP RICHNESS													*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double es[3];				/* previous log likelihoods (cell number = num previous).			*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist;			/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbes;				/* previous best support for decay rate								*/bep=dvector(2);for (i=0; i<2; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */if (empdist[ntaxa-1]>=1)	ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));else	ein=pow(empdist[0],1/((double) ntaxa));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/iei=ein-1;if (ei==0)	ei=0.00001f;pbes = 0.0f;/*	ei = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;lei[0]=lei[1]=0.0f;ei=iei;while (ei+ein<= emin)	ei/=2;for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {			/* generate geometric distribution with richness r and decay of ev */	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION */	for (r=1; ((1-(1/ev))*pow((1/ev),(r-1)))>pow(10,-9); r=r)	++r;	/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	free_dvector(expect);	/*Debugging line */	if (ev<=emin) printf("\nDANGER: Geo R=%d, ev=%f, S=%f ",r,ev,es[0]);	if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */		pbes = bep[0];								/* save last best ssq for evenness */		bep[0] = es[0];								/* STORE FIT */		bep[1] = ev;								/* STORE SLOPE */				/* while we are getting better on the initial increment, just ride with it			*/		if (ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that	*/				if (es[0]>es[2])	ei/=2;				else				ei/=-2;				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*/				if (es[0]>es[1])	ei/=2;				else				ei/=-2;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || (2*fabs(ei)==fabs(lei[0])))	{			lei[1]=lei[0];			lei[0]=ei;			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/			if (es[0]>es[2])	ei/=2;			/* otherwise go to ev-x/2									*/			else				ei*=-1;			}		ev=bep[1];		}	/* make sure that ei does not take ev below 1.0 */	while (ev+ei<= emin)	{		if (fabs(lei[0])==fabs(lei[1]))	ei*=-1;		else							ei=-1*lei[0];		}	es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}free_dvector(obsrvd);return bep;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A POISSON DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *count_fit_poi_geos(int *empdist, int ntaxa, int nspec) {int i = 0;					/* LOOP VARIABLE													*/int r = 0;					/* LOOP RICHNESS													*/int ri;						/* richness increment												*/int iri;					/* initial richness increment each loop								*/int lri[2];					/* last two richness increments										*/int rin;					/* initial richness													*/int mxr=5000;				/* this is as long as we can make an array							*//*int lri[2];					/* last two richness increments									*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double es[3];				/* previous log likelihoods (cell number = num previous).			*/double rs[3];				/* previous log likelihoods (cell number = num previous).			*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array		*/double *fitdist;			/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbes;				/* previous best support for decay rate								*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */if (empdist[ntaxa-1]>=1)	ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));else	ein=pow(empdist[0],1/((double) ntaxa));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);if (rin<ntaxa)	rin=ntaxa;/*if ((rin-ntaxa)%2==1)	++rin;	*/iri=ri=ntaxa/4;if (ri<2)	iri=ri=2;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/iei=ein-1;if (ei==0)	ei=0.00001f;for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;/*	ei = (double) FITINC / 10;	*/	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/		for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate geometric distribution with richness r and decay of ev */		fitdist = proportional_geos_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei/=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (fabs(ei)==fabs(iei))	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei/=-2;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}	/* end case where ei is no the original */				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			else	{				lei[1]=lei[0];				lei[0]=ei;				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* reset evenness incrementer */	if (r!=rin)		iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */	else if (r==rin || ei==0)		iei=bep[1]-ein;		/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* optimal richness is overshot */	else {		r=brp[2];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! */	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	{				if (abs(ri)==1)	ri=0;			else			ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		}		/* geometric might go on and on forever with miniscule increases when it is a very poor fit */	if (ri==iri && ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC))))	ri=0;			if (ei<0)	iei*=-1;	if (ei<mei)	iei=100*mei;		rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A POISSON DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_poi_zipf(int *empdist, int ntaxa, int nspec){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;					/* initial richness increment each loop									*/int	lri[2];					/* recent changes in richness											*/int mxr=10000;				/* this is as long as we can make an array								*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rin;					/* initial richness 													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 0.00000f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double rs[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array			*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the Zipf-Mandelbrot, based on the log-log slopes between the initial taxa */if (empdist[0]>empdist[2])	ein=(log(empdist[0])/log(empdist[2]));if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;if (ntaxa>=10)	{	ev=((double) empdist[9])/((double) empdist[0]);	ein=-1*log(ev)/log(10);	}if (ein<emin)/*	ein=pow((log(empdist[0])/log(empdist[6])),0.5);	*/		if (empdist[2]==1 && empdist[0]>empdist[1])		ein=pow((log(empdist[0])/log(empdist[1])),2);if (ein<emin)	ein=0.50f;/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);iri=ri=ntaxa/4;if (ri<2)	iri=ri=2;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/iei=ein/2;						/*changed*/if (iei==0)	iei=0.00001f;		/*changed*/for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein< emin)	ei/=2;			/* changed	*/	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei/=-1;				}			}	/* end case where likelihood is improved	*/							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (fabs(ei)==fabs(iei))	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei/=-2;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}	/* end case where ei is no the original */				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;								if (ev+ei<= emin)	{					if (fabs(lei[0])==fabs(lei[1]))	ei/=-2;					else							ei/=-1;					}				}			ev=bep[1];			}	/* end case where likelihood is not improved	*/		/* make sure that ei does not take ev below 1.0 *//*		if (ev+ei<= emin)	ei/=2;	*/		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* reset evenness incrementer */	if (r!=rin)		iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */	else if (r==rin || ei==0)		iei=bep[1]-ein;		/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* optimal richness is overshot */		else {		r=brp[2];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}	/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! 	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	ri/=2;		}				*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;	/*	if (abs(ri)%2==1 && abs(ri)>1)	{		if (ri>0)	++ri;		else		--ri;		}	*/	if (ei<0)	iei*=-1;	if (ei<mei)	iei=100*mei;		rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* FIND THE MOST-LIKELY UNTRUNCATED LOG-NORMAL SERIES, VARYING MAGNITUDE OF INCREASE AMONG OCTAVES. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: magnitude of increase per octave	- result[2]: optimal richnessCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_poi_lgn(int *empdist, int ntaxa, int nspec) {int i=0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;					/* initial richness increment each loop									*/int lri[2];					/* previous richness increment											*/int rin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxr=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double rs[3];				/* previous richness log likelihoods (cell number = num previous).		*/double bep[2];				/* BEST decay for hypothesized evenness at given S - return array format */double *brp;				/* BEST richness parameters - return array								*/double pbes;				/* previous best support for modal decay								*/double pbrs;				/* previous best support for richness									*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *fitdist;			/* fit distribution												*/double mdmx;brp=dvector(3);for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);iri=ri=ntaxa/4;if (ri<2)	ri=2;lri[0]=lri[1]=0;	if (2*rin<10)			mdmx=1.5;else if (2*rin<20)		mdmx=2.0;else if (2*rin<75)		mdmx=2.5;else if (2*rin<350)		mdmx=3.0;else if (2*rin<2000)	mdmx=3.5;else if (2*rin<15000)	mdmx=4.0;else 					mdmx=4.5;if (rin%2==1)				r=empdist[rin/2];else						r=(((double) empdist[rin/2])+((double) empdist[(rin/2)-1]))/2;if (rin/2 < ntaxa)			ein = pow(e,(log(((double) empdist[0])/((double) empdist[rin/2]))/mdmx));else	{	if (empdist[ntaxa-1]>0)	ein = pow(e,(log(((double) empdist[0])/((double) empdist[ntaxa-1]))/mdmx));	else					ein = pow(e,log(((double) empdist[0])/mdmx));	}if (ein==1)	ein=1.20f;iei=ein-1;pbrs=0.0f;for (i=0; i<3; i++) brp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	rs[i]= -1.0*DBL_MAX;/* adjust true richness until that fails to improve likelihood	*/for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	/* generally speaking, if you decrease richness, then you increase the probability of observation	*/	/* 		by increasing evenness, which means looking at lower values of ev.							*/	if (r!=rin && r<brp[2])			if (ei>0)	ei*=-1;	else if (r!=rin && r>brp[2])	if (ei<0)	ei*=-1;		/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate log-normal distribution with richness r and decay of magnitude of increase ev */		fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */						/* while we are getting better on the initial increment, or its negative, just ride with it			*/			if (fabs(ei)==fabs(iei))	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei*=-1;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/		if ((ev+ei)<=emin)	{			if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/			else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/			}		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* end cases of improved richness parameter */	/* optimal richness is overshot */	else {		r=brp[2];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! 	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	ri/=2;		}	*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;	/*	if (abs(ri)%2==1 && abs(ri)>1)	{		if (ri>0)	++ri;		else		--ri;		}	*/	rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* FIND THE MOST-LIKELY LOG-NORMAL SERIES, VARYING INTIAL AND MODAL SLOPE AND THE MODE. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood (truncated)	- result[1]: magnitude of increase per octave (truncated)	- result[2]: optimal richness (truncated)	- result[3]: mode (truncated)	- result[4]: log likelihood (untruncated)	- result[5]: magnitude of increase per octave (untruncated)	- result[6]: optimal richness (untruncated)		- result[7]: mode of untruncated is 0COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_poi_lnt(int *empdist, int ntaxa, int nspec) {int j=0,i=0;			/* LOOP VARIABLE															*/int r = 0;				/* LOOP RICHNESS															*/int ri;					/* richness increment														*/int iri;				/* initial richness increment each loop										*/int lri[2];				/* previous richness increment												*/int rin=0;				/* initial richness to use in each search (begins as ntaxa)					*/int mxr=5000;			/* this is as long as we can make an array									*/int unqfnd=0;			/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double mode;			/* mode of log-normal, given as a taxon number								*/double x=1.0f;			/* x is the absolute value of the mode - cannot do abs(double)				*/double y=1.0f;double z=1.0f;double mi=-1.0f;		/* how much to increment the mode											*/double imi=-1.0f;double lmi[2];			/* prior increment															*/double mimin=0.125;		/* minimum mode change													*/double mdmx=1.5f;double mdmn=-2.5f;double tr;double ev = 0.000f;		/* LOOP SLOPE 																*/double emin = 1.00f;	/* min slope																*/double mxev=75.0f;		/* maximum magnitude change to consider										*/double ein = 0.000f;	/* initial slope															*/double ei = 0.000f;		/* how much to increment ev in each loop									*/double iei;				/* initial slope increment at each richness								*/double aei=0.00f;		/* absolute evenness increment											*/double mei=0.000001f;	/* minimum evenness increment											*/double es[3];			/* previous modal decay log likelihoods (cell number = num previous).		*/double rs[3];			/* previous richness log likelihoods (cell number = num previous).			*/double ms[3];			/* previous mode log likelihoods (cell number = num previous).				*/double bep[2];			/* BEST modal decay parameters - return array format 						*/double brp[3];			/* BEST richness parameters - return array									*/double pbes;			/* previous best support for modal decay									*/double pbrs;			/* previous best support for richness										*/double pbms;			/* previous best support for mode location									*/double *expect;			/* expected number of species with 0Émax finds								*/double *obsrvd;			/* observed number of species with 0Émax finds								*/double *fitdist;		/* fit distribution															*/double *bmp;			/* Best mode parameters - return array format								*/double lei[2];			/* last evenness increment													*/bmp=dvector(8);for (i=0; i<8; i++) bmp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);if (rin<100)			j=4;else					j=5;if (2*rin<75)			mdmx=2.5;else if (2*rin<350)		mdmx=3.0;else if (2*rin<2000)	mdmx=3.5;else if (2*rin<15000)	mdmx=4.0;else 					mdmx=4.5;if (rin/2 < ntaxa)	ein = pow(e,log(empdist[0]/empdist[rin/2])/mdmx);else				ein = pow(e,log(empdist[0]/empdist[ntaxa-1])/mdmx);aei=iei=ein-1;mdmn=-1*mdmx;/*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/for (i=0; i<3; ++i)	ms[i]=-1.0*DBL_MAX;pbms=0.0f;/* adjust mode until that fails to improve likelihood	*/	/* for some reason the program is disobeying the second part of the conditional */imi=mi;for (mode=0; x>=mimin && (mode>=mdmn && mode<=mdmx)/* && ((pbms == 0.0f) || (bmp[0] > (pbms + SUPINC)))*/; mode+=mi)	{	if (mode==0)	{/*		ei = ein-0.95;	*/		tr=0;		}	else	{/*		ei = ein/10;	*/		tr=1;		}		iei=-1*(ein-1.05);		pbrs=0.0f;	for (i=0; i<3; i++) brp[i]=-1.0*DBL_MAX;	for (i=0; i<3; ++i)	rs[i]= -1.0*DBL_MAX;	/* adjust true richness until that fails to improve likelihood	*/	lri[0]=ri=rin;	if (ri<2)	ri=2;			iri=ri;	for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{		obsrvd[0]=r-ntaxa;		pbes = 0.0f;		/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/		for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;		for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;		lei[0]=lei[1]=0.0f;		ei=iei;		/* increment slope until that fails to improve likelihood or resolution limit reached */		for (ev = ein; ((ev>=emin && aei>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {							/* generate log-normal distribution with richness r and decay of magnitude of increase ev */			fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */			/* find the expected proportions of taxa with 0Éx finds */			expect=expfinds(fitdist,r,nspec,nspec);			free_dvector(fitdist);			es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);			free_dvector(expect);			/*Debugging line */			if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);			if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */				pbes = bep[0];								/* save last best ssq for evenness */				rs[0]=bep[0] = es[0];						/* STORE FIT */				bep[1] = ev;								/* STORE SLOPE */								/* while we are getting better on the initial increment, just ride with it			*/				if (ei==iei)	{					lei[1]=lei[0];					lei[0]=ei;					}				/* if we have a later improvement, wander halfway back to the last improvement 	*/				/* (remember, we always start at the most likely slope up to that point			*/				else	{					lei[1]=lei[0];					lei[0]=ei;					ei/=-2;					}				}									/* If likelihood has not increased, then reset and change the increment  value	*/			else	{				/* if we went from x -> -x, then we want to cut the increment in half */				if (ei==-1*lei[0] || ei==iei)	{					lei[1]=lei[0];					lei[0]=ei;					if (ei==iei)	{						/* determine whether es[0] or es[2] is the second best - move towards that	*/						if (es[0]>es[2])	ei/=2;						else				ei/=-2;						}					else	{						/* determine whether es[0] or es[1] is the second best - move towards that	*/						if (es[0]>es[1])	ei/=2;						else				ei/=-2;						}					}				/* if we just divided in half, then we want to reverse the increment */				else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{					lei[1]=lei[0];					lei[0]=ei;					/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/					if (es[0]>es[2])	ei/=2;					/* otherwise go to ev-x/2									*/					else				ei*=-1;					}				ev=bep[1];				}			/* make sure that ei does not take ev below 1.0 */			while (ev+ei<= emin)	ei/=2;			es[2] = es[1];									/* Store last 2 attempts to identify	*/			es[1] = es[0];									/* when the peak is past 				*/			aei=ei;											/* tally absolute evenness increment	*/			if (aei<0)	aei*=-1;			}		/* reset evenness incrementer */		if (r!=rin)			aei=iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */		else if (r==rin || ei==0)			aei=iei=bep[1]-ein;				/* if this richness is better than the last */		if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */			brp[2] = r;			for (i=0; i<2; i++)				brp[i] = bep[i];			ein=bep[1];										/* set initial decay to best decay found so far */ 			/* if we are past the initial ri, then we want to use it only once	*/			/* otherwise, we repeat r's											*/			if (r!=rin)	{				lri[1]=lri[0];				lri[0]=ri;				}			if (ri!=iri && ri!=(-1*iri))		ri/=2;			}		/* optimal richness is overshot */		else {			r=brp[2];				/* step back to best richness	 */					/* if we start off going downhill, then go the other way */			if (ri==iri && r==rin)	{				lri[1]=lri[0];				lri[0]=ri;				ri*=-1;				while ((r+ri)<ntaxa)		ri/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (abs(ri)==abs(lri[0]))	{				lri[1]=lri[0];				lri[0]=ri;				/* go towards the one with the higher likelihood */				if (rs[1]>rs[0])			ri/=-2;				else						ri/=2;				}			/* if this increment is less then the last, then */			else if (abs(ri)<abs(lri[0]))	{				lri[1]=lri[0];				lri[0]=ri;				ri*=-1;				}			}				/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */		/* do not bother going for r < observed! */		while ((r+ri)>mxr || (r+ri)< ntaxa)	{			if (r==mxr)	ri*=-1;			else	ri/=2;			}				if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;				if (abs(ri)%2==1 && abs(ri)>1)	{			if (ri>0)	++ri;			else		--ri;			}		if (ei<0)	iei*=-1;		if (ei<mei)	iei=100*mei;		aei=iei;		if (aei<0)	aei*=-1;				rs[2] = rs[1];		rs[1] = bep[0];		}	/* if this mode is better than the last */	if (brp[0] >= bmp[0]) {								/* IF BETTER THAN BEST FIT */		pbms=bmp[0];		for (i=0; i<3; i++)			bmp[i] = brp[i];		bmp[3] = mode;		/* save the best untruncated log-normal separately */		if (mode==0)	{			for (i=0; i<3; ++i)	bmp[i+4]=brp[i];			bmp[7]=0;			}		/* if we are truncating the log-normal, then we want to use the mode shift only once */		else {			lmi[1]=lmi[0];			lmi[0]=mi;			}		if (mi!=imi && mi!=(-1*imi))	mi/=2;		}	/* optimal mode is overshot */	else	{		mode=bmp[3];		if (mi==imi && mode==0)	{			lmi[1]=lmi[0];			lmi[0]=mi;			mi*=-1;			}		else if (mi==(-1*lmi[0]) || mi==lmi[0])	{			lmi[1]=lmi[0];			lmi[0]=mi;			if (ms[1]>ms[0])	mi/=-2;			else				mi/=2;			} 		else if (abs(mi)<abs(lmi[0]))	{			lmi[1]=lmi[0];			lmi[0]=mi;			mi*=-1;			}		}	/* it might go on and on forever with miniscule increases when it is a very poor fit */	if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))	ri=0;	ms[2] = ms[1];	ms[1] = brp[0];/*	if (msw>=2 && mrn==1)	{		mi/=2;		if (mi<1)	x=-1*mi;		mrn=0;		}	*/		/* do not overshoot mode limits! */	while ((mode+mi<mdmn || mode+mi>mdmx) && x>mimin)	{		mi/=2;		if (mi<1)	x=-1*mi;		}			ein=bmp[1];										/* set initial modal decay to best modal decay found so far 	*/ 	rin=bmp[2];										/* set initial richness to best richness found so far			*/	x=mi;	if (x<0)	x*=-1;	}free_dvector(obsrvd);return bmp;}/* FIND THE MOST-LIKELY ZERO-SUM MULTINOMIAL, VARYING m and theta. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: most likely m	- result[2]: most likely thetaCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *count_fit_poi_zsm(int *empdist, int ntaxa, int nspec){int i=0, j=0;					/* LOOP VARIABLE															*/int	 mt, tt, mtb;				/* loop busters	*/int theospc=5*nspec;			/* theoretical number of total specimens									*//*int	r=0;					/* richness (calculated from distribution									*/double m=0.0f;					/* m for loop																*/double mi=0.25f;				/* m increment																*/double imi=0.25f;				/* initial m increment each loop											*/double lmi[2];					/* previous m increment														*/double min=0.75f;				/* initial m to use in each search (begins as ntaxa)						*/long double mmx=0.999999f;		/* maximum m to consider													*/long double mmn=0.000001f;		/* minimum m																*/double lti[2];					/* last two theta incrementers												*/double iti;						/* initial slope increment at each m										*/double theta=0.000f;			/* LOOP theta 																*/double tin=10.000f;				/* initial theta															*/double tmin=0.01f;				/* min theta slope															*/double ti=10.000f;				/* how much to increment theta in each loop									*/double mti=0.0001f;				/* minimum theta increment													*/double ts[11];					/* previous modal decay log likelihoods (cell number = num previous).		*/double ms[3];					/* previous m log likelihoods (cell number = num previous).					*/double *btp;					/* BEST decay for hypothesized theta at given S - return array format 		*/double bmp[2];					/* BEST m parameters - return array											*/double pbms;					/* previous best support for m												*/double pbts=-1*DBL_MAX;			/* previous best support for theta											*//*double *expect;				/* expected number of species with 0Émax finds								*/double *expind;				/* expected number of species with 0Émax individuals						*/double *expsamp;			/* expected number of species with 0Émax finds								*/double *obsrvd;				/* observed number of species with 0Émax finds								*/double x,y,z;					/* dummy															*/btp=dvector(3);for (i=0; i<3; i++) btp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ts[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);tin=chao2(empdist,ntaxa);tin*=0.3;ti=iti=tin/4;mti=0.0001*iti;lti[0]=tin;lti[1]=0.0f;	/*min=(mmx+mmn)/2;		/* it seems that m's on either side of 0.85 repeat each other....	*//*imi=(1-min)/2;	*//* adjust true m until that fails to improve likelihood	*/mtb=tt=0;for (theta = tin; ((theta>=tmin && fabs(ti)>mti) || pbts == -1*DBL_MAX); theta += ti) {		/*Debugging line */	if (theta<=tmin) printf("\nDANGER: theta=%f, m=%f ",theta, m);	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	bmp[0]=bmp[1]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	mi=imi;		pbms=-1*DBL_MAX;	min=0.9999999f;	mi=imi=-2;	mt=0;	/* find the best theta for this m */	for (m=mmx; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expind=zerosum(theta,m,theospc);				x=sumdvector(expind,theospc);		if (x>=ntaxa)	{			for (j=1; expind[j]>0 && j<theospc; j=j)	++j;			expsamp=expfindsfromexpind(expind,j,nspec);			free_dvector(expind);						obsrvd[0]=x-ntaxa;			ms[0] = lnPoisson_vector_part(expsamp,obsrvd,empdist[0],1);			free_dvector(expsamp);			}		else	{			ms[0]=-1*DBL_MAX;			free_dvector(expind);			}		/* if this m is better than the last */		if (ms[0] >= bmp[0] && ms[0]>-1*DBL_MAX) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			bmp[0]=ms[0];								/* STORE FIT */			bmp[1]=m;									/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;				if (mi==imi)						mi=(mmn-mmx)/2;				else if (m+mi<mmn || m+mi>mmx)		mi/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)						mi*=-1;			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*///		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))		else if ((bmp[1]==mmx || bmp[1]==mmn) && fabs(mi)<fabs(imi)/32)			mi=0;					/* if it is trying to get past the maximum, then kill it	*/		else if ((bmp[1]==mmx && (bmp[0]<btp[0] && btp[1]>mmx)) && (bmp[0]>ms[0] && (bmp[0]>ms[1] && bmp[0]>ms[2])))			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*/		else if (bmp[0]<1.25*btp[0] && (mt>=mtb && mtb>5))			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		++mt;		}	/* end search for m */	ts[0]=bmp[0];	if (ts[0] >= btp[0] && ts[0]>-1*DBL_MAX) {							/* IF BETTER THAN BEST FIT */		pbts = btp[0];								/* save last best ssq for theta */		btp[0] = ts[0];								/* STORE FIT */		btp[1] = bmp[1];							/* STORE m */		btp[2] = theta;								/* STORE m */				mtb=mt;										/* number of tries to find the best m	*/		/* while we are getting better on the initial increment, just ride with it			*/		if (fabs(ti)==fabs(iti))	{			lti[1]=lti[0];			lti[0]=ti;			if (theta+ti<tmin)				ti/=-2;						/* to avoid local optima, at least on intial search */			else if (btp[0] <= (pbts + SUPINC))	{				/* return to prior theta	*/				if (theta==(tin+iti))	{					theta=tin;					ti*=-1;					pbts-=1.0f;					}				else if (theta==(tin-iti))	{					theta=tin;					ti/=2;					pbts-=1.0f;					}				}	/* end case where we had trivial improvement within one step of initial theta */			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lti[1]=lti[0];			lti[0]=ti;			ti/=2;			if (theta+ti<tmin)				ti/=-1;			}		}	/* end case where likelihood has improved	*/					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		lti[1]=lti[0];		lti[0]=ti;		if (fabs(ti)==fabs(iti))	{			/* if the first increment does not help, then reverse direction	*/			if (theta==tin+iti)				ti*=-1;			/* if an increment after the first stops helping, then go half way	*/			else							ti/=2;			if (theta+ti<tmin)				ti/=-2;			}		else	{			if (fabs(lti[0])==fabs(lti[1]))	ti/=2;			else							ti*=-1;			if (theta+ti<tmin)				ti/=-2;			}/*			if (ti==-1*lti[0] || ti==iti)	{			if (ti==iti)	{				/* determine whether ts[0] or ts[2] is the second best - move towards that	/				if (ts[0]>ts[2])	ti/=2;				else				ti/=-2;				}			else	{				/* determine whether ts[0] or ts[1] is the second best - move towards that	/				if (ts[0]>ts[1])	ti/=2;				else				ti/=-2;				}			}		/* if we just divided in half, then we want to reverse the increment /		else if (ti==-1*iti || (2*ti==lti[0] || -2*ti==lti[0]))	{			/* if theta+x/2 got closer than theta-x, back up and go to theta+x/4	/			if (fabs(ti)==fabs(lti[0]))	ti/=2;			else						ti*=-1;			} */		theta=btp[2];		}			/* start the next m at the best m so far *//*	if (btp[1]>0.5)	imi=(mmx-btp[1])/2;	*//*	else			imi=(btp[1]-mmn)/2;	*//*	min=btp[1];		*/	/* make sure that imi is not too small */	if (fabs(imi)<0.0001)	{		if (imi<0)						imi=-0.0001;		else							imi=0.0001;		}	/* make sure that imi does not take m out of bounds */	if (min+imi>mmx || min+imi<mmn)		imi*=-1;	/* make sure that ti does not take theta below 1.0 */	if (theta+ti<= tmin)	{		if (fabs(lti[0])==fabs(ti))			ti/=-2;		else								ti/=-1;		}	if (ts[0]>-1*DBL_MAX)	{		for (i=10; i>0; --i)	 ts[i] = ts[i-1];				/* Store last 2 attempts to identify	*/		++tt;		}	if (tt>5)	{		y=maxdarray(ts,6);		z=mindarray(ts,6);		if (y-z<0.1)	ti=0.0f;		}		if (btp[0] < (pbts + SUPINC) && fabs(ti)<((fabs(iti)/20)))	ti=0.0f;	}	/* end search for theta */free_dvector(obsrvd);return btp;}double *count_fit_poi_zsm_test(int *empdist, int ntaxa, int nspec){int i=0;					/* LOOP VARIABLE															*//*int	r=0;					/* richness (calculated from distribution									*/int theospc=5*nspec;double m=0.0f;				/* m for loop																*/double mi=0.25f;			/* m increment																*/double imi=0.25f;			/* initial m increment each loop											*/double lmi[2];				/* previous m increment														*/double min=0.75f;			/* initial m to use in each search (begins as ntaxa)						*/long double mmx=0.999999f;	/* maximum m to consider													*/double mmn=0.85f;			/* minimum m																*/double lti[2];				/* last two theta incrementers												*/double iti;					/* initial slope increment at each m										*/double theta=0.000f;		/* LOOP theta 																*/double tmin=0.01f;			/* min theta slope															*/double tin=10.000f;			/* initial theta															*/double ti=10.000f;			/* how much to increment theta in each loop									*/double mti=0.0001f;			/* minimum theta increment													*/double ts[3];				/* previous modal decay log likelihoods (cell number = num previous).		*/double ms[3];				/* previous m log likelihoods (cell number = num previous).					*/double *btp;				/* BEST decay for hypothesized theta at given S - return array format 		*/double bmp[2];				/* BEST m parameters - return array											*/double pbms;				/* previous best support for m												*/double pbts=-1*DBL_MAX;		/* previous best support for theta											*/double *expect;				/* expected number of species with 0Émax finds								*/double *obsrvd;				/* observed number of species with 0Émax finds								*//*double *fitdist;			/* fit distribution															*/FILE	*fopen();	FILE 	*outfile;btp=dvector(3);for (i=0; i<3; i++) btp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ts[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);tin=chao2(empdist,ntaxa);tin*=0.3;ti=iti=tin/4;mti=0.0001*iti;lti[0]=tin;lti[1]=0.0f;	min=(mmx+mmn)/2;		/* it seems that m's on either side of 0.85 repeat each other....	*/outfile=fopen("zerosumtest.txt","w");fprintf(outfile,"theta\tÆtheta\tm\tÆm\tlnL\ttime\n");/*imi=(1-min)/2;	*/imi=mmx-min;/* adjust true m until that fails to improve likelihood	*/for (theta = tin; ((theta>=tmin && fabs(ti)>mti) || pbts == -1*DBL_MAX); theta += ti) {		/*Debugging line */	if (theta<=tmin) printf("\nDANGER: theta=%f, m=%f ",theta, m);	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	bmp[0]=bmp[1]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	mi=imi;		pbms=-1*DBL_MAX;	/* find the best theta for this m */	for (m=min; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expect=zerosum(theta,m,theospc);						ms[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		i=time((time_t *)NULL);		fprintf(outfile,"%7.6f\t%7.6f\t%7.6f\t%7.6f\t%7.6f\t%d\n",theta,ti,m,mi,ms[0],i);/*		fflush(stdout);	*/		fclose(outfile);		outfile=fopen("zerosumtest.txt","a");		/* if this m is better than the last */		if (ms[0] >= bmp[0]) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			ts[0]=bmp[0]=ms[0];							/* STORE FIT */			bmp[1]=m;									/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;				if (m+mi<mmn || m+mi>mmx)				mi/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)						mi*=-1;			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*/		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))			mi=0;					/* if it is trying to get past the maximum, then kill it	*/		else if ((bmp[1]==mmx && (bmp[0]<btp[0] && btp[1]>mmx)) && (bmp[0]>ms[0] && (bmp[0]>ms[1] && bmp[0]>ms[2])))			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*/		else if (bmp[0]<1.25*btp[0])			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		}	/* end search for m */	if (ts[0] >= btp[0]) {							/* IF BETTER THAN BEST FIT */		pbts = btp[0];								/* save last best ssq for theta */		btp[0] = ts[0];								/* STORE FIT */		btp[1] = bmp[1];							/* STORE m */		btp[2] = theta;								/* STORE m */				/* while we are getting better on the initial increment, just ride with it			*/		if (fabs(ti)==fabs(iti))	{			lti[1]=lti[0];			lti[0]=ti;			if (theta+ti<tmin)				ti/=-2;						/* to avoid local optima, at least on intial search */			else if (btp[0] <= (pbts + SUPINC))	{				/* return to prior theta	*/				if (theta==(tin+iti))	{					theta=tin;					ti*=-1;					pbts-=1.0f;					}				else if (theta==(tin-iti))	{					theta=tin;					ti/=2;					pbts-=1.0f;					}				}	/* end case where we had trivial improvement within one step of initial theta */			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lti[1]=lti[0];			lti[0]=ti;			ti/=2;			if (theta+ti<tmin)				ti/=-1;			}		}	/* end case where likelihood has improved	*/					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		lti[1]=lti[0];		lti[0]=ti;		if (fabs(ti)==fabs(iti))	{			/* if the first increment does not help, then reverse direction	*/			if (theta==tin+iti)				ti*=-1;			/* if an increment after the first stops helping, then go half way	*/			else							ti/=2;			if (theta+ti<tmin)				ti/=-2;			}		else	{			if (fabs(lti[0])==fabs(lti[1]))	ti/=2;			else							ti*=-1;			if (theta+ti<tmin)				ti/=-2;			}/*			if (ti==-1*lti[0] || ti==iti)	{			if (ti==iti)	{				/* determine whether ts[0] or ts[2] is the second best - move towards that	/				if (ts[0]>ts[2])	ti/=2;				else				ti/=-2;				}			else	{				/* determine whether ts[0] or ts[1] is the second best - move towards that	/				if (ts[0]>ts[1])	ti/=2;				else				ti/=-2;				}			}		/* if we just divided in half, then we want to reverse the increment /		else if (ti==-1*iti || (2*ti==lti[0] || -2*ti==lti[0]))	{			/* if theta+x/2 got closer than theta-x, back up and go to theta+x/4	/			if (fabs(ti)==fabs(lti[0]))	ti/=2;			else						ti*=-1;			} */		theta=btp[2];		}			/* start the next m at the best m so far *//*	if (btp[1]>0.5)	imi=(mmx-btp[1])/2;	*//*	else			imi=(btp[1]-mmn)/2;	*//*	min=btp[1];							*/	/* make sure that imi is not too small */	if (fabs(imi)<0.0001)	{		if (imi<0)						imi=-0.0001;		else							imi=0.0001;		}	/* make sure that imi does not take m out of bounds */	if (min+imi>mmx || min+imi<mmn)		imi*=-1;	/* make sure that ti does not take theta below 1.0 */	if (theta+ti<= tmin)	{		if (fabs(lti[0])==fabs(ti))			ti/=-2;		else								ti/=-1;		}	ts[2] = ts[1];									/* Store last 2 attempts to identify	*/	ts[1] = ts[0];									/* when the peak is past 				*/		if (btp[0] < (pbts + SUPINC) && fabs(ti)<((fabs(iti)/20)))	ti=0.0f;	}	/* end search for theta */tin=btp[2];ti=iti=tin/4;mti=0.0001*iti;mmn=0.0001f;mmx=0.85;lti[0]=tin;lti[1]=0.0f;	min=(mmx+mmn)/2;		/* it seems that m's on either side of 0.85 repeat each other....	*/imi=mmx-min;for (theta = tin; ((theta>=tmin && fabs(ti)>mti) || pbts == -1*DBL_MAX); theta += ti) {		/*Debugging line */	if (theta<=tmin) printf("\nDANGER: theta=%f, m=%f ",theta, m);	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) ms[i] = -1.0*DBL_MAX;	bmp[0]=bmp[1]= -1.0*DBL_MAX;	lmi[0]=lmi[1]=0.0f;	mi=imi;		pbms=-1*DBL_MAX;	/* find the best theta for this m */	for (m=min; ((mi!=0 && (m>=mmn && m<=mmx))  && (pbms==-1*DBL_MAX || bmp[0]>pbms +SUPINC)); m+=mi)	{		obsrvd[0]=0;		expect=zerosum(theta,m,theospc);						ms[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		i=time((time_t *)NULL);		fprintf(outfile,"%7.6f\t%7.6f\t%7.6f\t%7.6f\t%7.6f\t%d\n",theta,ti,m,mi,ms[0],i);/*		fflush(stdout);	*/		fclose(outfile);		outfile=fopen("zerosumtest.txt","a");		/* if this m is better than the last */		if (ms[0] >= bmp[0]) {							/* IF BETTER THAN BEST FIT */			pbms = bmp[0];								/* save last best ssq for m */			ts[0]=bmp[0]=ms[0];							/* STORE FIT */			bmp[1]=m;									/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(mi)==fabs(imi))	{				lmi[1]=lmi[0];				lmi[0]=mi;				if (m+mi<mmn || m+mi>mmx)				mi/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi<mmn || m+mi>mmx)				mi/=-1;				}			}		/* optimal m is overshot */		else {			m=bmp[1];				/* step back to best m	 */					/* if we start off going downhill, then go the other way */						if (mi==imi)						mi*=-1;			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi/=2;				if (m+mi>mmx || m+mi<mmn)	{					if (fabs(mi)==fabs(lmi[0]))	mi/=-2;					else						mi/=-1;					}				}			else if (mi==lmi[0]/2)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			else if (mi==imi && m==min)	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			/* if this increment is opposite of the last, then cut it in half */			else if (fabs(mi)==fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				/* go towards the one with the higher likelihood */				if (ms[1]>ms[0])				mi/=-2;				else							mi/=2;				if (m+mi>mmx || m+mi<mmn)		mi/=-1;				}			/* if this increment is less then the last, then */			else if (fabs(mi)<fabs(lmi[0]))	{				lmi[1]=lmi[0];				lmi[0]=mi;				mi*=-1;				if (m+mi>mmx || m+mi<mmn)		mi/=-2;				}			}				if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))				mi=0;				/* if we basically are running into improvement up to the min/max, then just take the min/max	*/		else if ((bmp[1]==mmx || bmp[1]==mmn) && (bmp[0]<(ms[0]+0.1) && (bmp[0]<(ms[1]+0.1) && bmp[0]<(ms[2]+0.1))))			mi=0;		/* if log likelihood is hopelessly low for this theta, then skip to the next	*/		else if (bmp[0]<1.75*btp[0])			mi=0;		else if ((fabs(mi)<fabs(imi)/16) && bmp[0]<1.25*btp[0])			mi=0;				ms[2] = ms[1];		ms[1] = ms[0];		}	/* end search for m */	if (ts[0] >= btp[0]) {							/* IF BETTER THAN BEST FIT */		pbts = btp[0];								/* save last best ssq for theta */		btp[0] = ts[0];								/* STORE FIT */		btp[1] = bmp[1];							/* STORE m */		btp[2] = theta;								/* STORE m */				/* while we are getting better on the initial increment, just ride with it			*/		if (fabs(ti)==fabs(iti))	{			lti[1]=lti[0];			lti[0]=ti;			if (theta+ti<tmin)				ti/=-2;						/* to avoid local optima, at least on intial search */			else if (btp[0] <= (pbts + SUPINC))	{				/* return to prior theta	*/				if (theta==(tin+iti))	{					theta=tin;					ti*=-1;					pbts-=1.0f;					}				else if (theta==(tin-iti))	{					theta=tin;					ti/=2;					pbts-=1.0f;					}				}	/* end case where we had trivial improvement within one step of initial theta */			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lti[1]=lti[0];			lti[0]=ti;			ti/=2;			if (theta+ti<tmin)				ti/=-1;			}		}	/* end case where likelihood has improved	*/					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		lti[1]=lti[0];		lti[0]=ti;		if (fabs(ti)==fabs(iti))	{			/* if the first increment does not help, then reverse direction	*/			if (theta==tin+iti)				ti*=-1;			/* if an increment after the first stops helping, then go half way	*/			else							ti/=2;			if (theta+ti<tmin)				ti/=-2;			}		else	{			if (fabs(lti[0])==fabs(lti[1]))	ti/=2;			else							ti*=-1;			if (theta+ti<tmin)				ti/=-2;			}/*			if (ti==-1*lti[0] || ti==iti)	{			if (ti==iti)	{				/* determine whether ts[0] or ts[2] is the second best - move towards that	/				if (ts[0]>ts[2])	ti/=2;				else				ti/=-2;				}			else	{				/* determine whether ts[0] or ts[1] is the second best - move towards that	/				if (ts[0]>ts[1])	ti/=2;				else				ti/=-2;				}			}		/* if we just divided in half, then we want to reverse the increment /		else if (ti==-1*iti || (2*ti==lti[0] || -2*ti==lti[0]))	{			/* if theta+x/2 got closer than theta-x, back up and go to theta+x/4	/			if (fabs(ti)==fabs(lti[0]))	ti/=2;			else						ti*=-1;			} */		theta=btp[2];		}			/* start the next m at the best m so far *//*	if (btp[1]>0.5)	imi=(mmx-btp[1])/2;	*//*	else			imi=(btp[1]-mmn)/2;	*//*	min=btp[1];		*/	/* make sure that imi is not too small */	if (fabs(imi)<0.0001)	{		if (imi<0)						imi=-0.0001;		else							imi=0.0001;		}	/* make sure that imi does not take m out of bounds */	if (min+imi>mmx || min+imi<mmn)		imi*=-1;	/* make sure that ti does not take theta below 1.0 */	if (theta+ti<= tmin)	{		if (fabs(lti[0])==fabs(ti))			ti/=-2;		else								ti/=-1;		}	ts[2] = ts[1];									/* Store last 2 attempts to identify	*/	ts[1] = ts[0];									/* when the peak is past 				*/		if (btp[0] < (pbts + SUPINC) && fabs(ti)<((fabs(iti)/20)))	ti=0.0f;	}	/* end search for theta */free_dvector(obsrvd);fclose(outfile);return btp;}double count_fit_poi_best(int *empdist, int ntaxa){double es=0.0f;				/* m for loop																*/double *obsrvd;				/* observed number of species with 0Émax finds								*//*double *fitdist;			/* fit distribution															*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);es = lnPoisson_vector_part(obsrvd,obsrvd,empdist[0],1);free_dvector(obsrvd);return es;}/*support_bars_poi_unif - routine to put support ÒerrorÓ bars on richness given a uniform series & a Poisson distribution *******************************************************************************************************************/double **support_bars_poi_unif (double bestS, int ntaxa, int bestR, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double diff;				/* difference in log-likelihoods										*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double **sbars;				/* support and slopes for richness values within bar units of support	*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);supportlo[0]=bestS;diff=0;rub=rlb=bestR;for (r=bestR-1; diff<=bar && r>=ntaxa; --r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	fitdist=dvector(r);	for (i=0; i<r; ++i)	fitdist[i]=1/((double) r);	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	supportlo[abs(bestR-r)-1] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	free_dvector(expect);		diff=fabs(bestS-supportlo[abs(bestR-r)-1]);	rlb=r;	}diff=0;for (r=bestR+1; diff<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	fitdist=dvector(r);	for (i=0; i<r; ++i)	fitdist[i]=1/((double) r);	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	supportup[abs(bestR-r)-1] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	free_dvector(expect);	diff=fabs(bestS-supportup[abs(bestR-r)-1]);	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=1.0;		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=1.0;		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=1.0;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_poi_geo - routine to put error bars on richness given a geometric series & a Poisson distribution NEEDS:	- bestS (log likelihood of best geometric)	- bestM (slope of best geometric)	- ntaxa (size of array)	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- bars (number of support units)RETURNS:	- sbars[0]: slope parameter	- sbars[1]: support of sbars[0] given dataCOMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double **support_bars_poi_geo (double bestS, double bestM, int ntaxa, int *empdist, double bar){int i=0, j=0;				/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double lev = 0.000f;			/* LOOP SLOPE 															*/double uev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double es;				/* previous log likelihoods (cell number = num previous).				*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double	x;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;rlb=rub=1;es=bestS;ei=bestM/100;for (ev=lev=bestM; (ev>=emin && (bestS-es)<bar); ev-=ei) {		/* generate Geometric distribution with richness r and log-decay of ev */	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION */	for (r=1; ((1-(1/ev))*pow((1/ev),(r-1)))>pow(10,-9); r=r)	++r;	/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	expect[0]=0;	x=sumdvector(expect,nspec);	for (i=1; i<nspec; ++i)	expect[i]/=x;	es=lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	free_dvector(expect);	lev=ev;	++rlb;	}es=bestS;for (ev=uev=bestM+ei; (ev>=emin && (bestS-es)<bar); ev+=ei) {		/* generate Geometric distribution with richness r and log-decay of ev */	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION */	for (r=1; ((1-(1/ev))*pow((1/ev),(r-1)))>pow(10,-9); r=r)	++r;	/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	expect[0]=0;	x=sumdvector(expect,nspec);	for (i=1; i<nspec; ++i)	expect[i]/=x;	es=lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	free_dvector(expect);	uev=ev;	++rub;	}sbars=dmatrix(rub+rlb+2,2);j=0;for (ev=lev; ev<=uev; ev+=ei)	{	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));	/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);		expect[0]=0;	x=sumdvector(expect,nspec);	for (i=1; i<nspec; ++i)	expect[i]/=x;	sbars[j][0]=ev;	sbars[j][1]=lnPoisson_vector_part(expect,obsrvd,empdist[0],1);	free_dvector(expect);		++j;	}return sbars;}/*support_bars_poi_geos - routine to put support ÒerrorÓ bars on richness given a geometric series & a Poisson distribution *******************************************************************************************************************/double **support_bars_poi_geos (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double evlo[1000];			/* evenness maximizing likelihood of richness values below ML richness	*/double evup[1000];			/* evenness maximizing likelihood of richness values above ML richness	*/double **sbars;				/* support and slopes for richness values within bar units of support	*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(1/((double) nspec));if (iei==0)	iei=-0.00001f;bep[0]=bestS;for (r=bestR-1; fabs(bestS-bep[0])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate Geometric distribution with richness r and log-decay of ev */		fitdist = proportional_geos_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			else	{				lei[1]=lei[0];				lei[0]=ei;				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportlo[abs(bestR-r)-1]=bep[0];	evlo[abs(bestR-r)-1]=bep[1];	rlb=r;	}ein=bestM;iei=(2/((double) nspec));if (iei==0)	iei=0.00001f;bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_geos_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportup[abs(bestR-r)-1]=bep[0];	evup[abs(bestR-r)-1]=bep[1];	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=evlo[abs(bestR-r)-1];		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=evup[abs(bestR-r)-1];		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=bestM;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_poi_zipf - routine to put support ÒerrorÓ bars on richness given a Zipf series & a Poisson distribution *******************************************************************************************************************/double **support_bars_poi_zipf (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double evlo[1000];			/* evenness maximizing likelihood of richness values below ML richness	*/double evup[1000];			/* evenness maximizing likelihood of richness values above ML richness	*/double **sbars;				/* support and slopes for richness values within bar units of support	*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(2/((double) nspec));if (iei==0)	iei=-0.00001f;bep[0]=bestS;for (r=bestR-1; fabs(bestS-bep[0])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportlo[abs(bestR-r)-1]=bep[0];	evlo[abs(bestR-r)-1]=bep[1];	rlb=r;	}ein=bestM;iei=(2/((double) nspec));if (iei==0)	iei=0.00001f;bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportup[abs(bestR-r)-1]=bep[0];	evup[abs(bestR-r)-1]=bep[1];	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=evlo[abs(bestR-r)-1];		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=evup[abs(bestR-r)-1];		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=bestM;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_poi_lgn - routine to put support ÒerrorÓ bars on richness given a log-normal series & a Poisson distribution *******************************************************************************************************************/double **support_bars_poi_lgn (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double supportlo[1000];		/* support for richness values below the ML value						*/double supportup[1000];		/* support for richness values above the ML value						*/double evlo[1000];			/* evenness maximizing likelihood of richness values below ML richness	*/double evup[1000];			/* evenness maximizing likelihood of richness values above ML richness	*/double **sbars;				/* support and slopes for richness values within bar units of support	*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(1/((double) nspec));if (iei==0)	iei=-0.00001f;bep[0]=bestS;for (r=bestR-1; fabs(bestS-bep[0])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4					if (es[0]>es[2])	ei/=2;*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2				*/												else				ei*=-1;					}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportlo[abs(bestR-r)-1]=bep[0];	evlo[abs(bestR-r)-1]=bep[1];	rlb=r;	}ein=bestM;iei=(2/((double) nspec));if (iei==0)	iei=0.00001f;bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r<=mtaxa; ++r)	{	obsrvd[0]=r-ntaxa;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein<= emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + (SUPINC/100))))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		es[0] = lnPoisson_vector_part(expect,obsrvd,empdist[0],1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];						/* save last best ssq for evenness */			bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;						/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that	*/					if (es[0]>es[2])	ei/=2;					else				ei/=-2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/					if (es[0]>es[1])	ei/=2;					else				ei/=-2;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || (2*ei==lei[0] || -2*ei==lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*/				if (es[0]>es[2])	ei/=2;				/* otherwise go to ev-x/2									*/				else				ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 */		while (ev+ei<= emin)	ei/=2;		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	supportup[abs(bestR-r)-1]=bep[0];	evup[abs(bestR-r)-1]=bep[1];	rub=r;	}free_dvector(obsrvd);sbars=dmatrix(2+(rub-rlb),3);for (r=rlb; r<=rub; ++r)	{	sbars[r-rlb][0]=r;	if (r<bestR)	{		sbars[r-rlb][1]=evlo[abs(bestR-r)-1];		sbars[r-rlb][2]=supportlo[abs(bestR-r)-1];		}	else if (r>bestR)	{		sbars[r-rlb][1]=evup[abs(bestR-r)-1];		sbars[r-rlb][2]=supportup[abs(bestR-r)-1];		}	else	{		sbars[r-rlb][1]=bestM;		sbars[r-rlb][2]=bestS;		}	}sbars[(rub-rlb)+1][0]=sbars[(rub-rlb)+1][1]=sbars[(rub-rlb)+1][2]=100;return sbars;}/*support_bars_poi_zsm - routine to put error bars on richness given a geometric series & a multinomial distribution /* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- bestS (log likelihood of best geometric)	- bestM (slope of best geometric)	- ntaxa (size of array)	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- bars (number of support units)RETURNS:	- sbars[0]: slope parameter	- sbars[1]: support of sbars[0] given dataCOMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double **support_bars_poi_zsm (double besttheta, double bestm, double bestS, int ntaxa, int *empdist, double bar, double omega){int i=0, j=0;				/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int rlb;					/* lower bound for richness												*/int rub;					/* upper bound for richness												*/int nspec;					/* number of specimens													*/int theospc;				/* theoretical number of total specimens								*/double *expind;				/* expected number of species with 0Émax individuals					*/double *expsamp;			/* expected number of species with 0Émax finds							*/double theta = 0.000f;		/* LOOP SLOPE 															*/double lth = 0.000f;		/* LOOP SLOPE 															*/double uth = 0.000f;		/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment theta in each loop								*/double es;					/* previous log likelihoods (cell number = num previous).				*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double	x, y;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);theospc=5*nspec;ein=besttheta;rlb=rub=1;es=bestS;ei=besttheta/100;for (theta=lth=besttheta; (theta>=emin && (bestS-es)<bar); theta-=ei) {		/* generate zero sum distribution at theta and m */	expind=zerosum(theta,bestm,theospc);	x=sumdvector(expind,nspec);	if (x>=ntaxa)	{		for (j=1; expind[j]>0 && j<nspec; j=j)	++j;		expsamp=expfindsfromexpindprop(expind,j,nspec);		free_dvector(expind);		es=lnPoisson_vector_part(expind,obsrvd,empdist[0],1);		free_dvector(expsamp);		}	else	{		es=-1*DBL_MAX;		free_dvector(expind);		}	lth=theta;	++rlb;	}es=bestS;for (theta=uth=besttheta+ei; (bestS-es)<bar; theta+=ei) 	{	/* generate Geometric distribution with richness r and log-decay of theta */	expind=zerosum(theta,bestm,theospc);	x=sumdvector(expind,nspec);	if (x>=ntaxa)	{		for (j=1; expind[j]>0 && j<nspec; j=j)	++j;		expsamp=expfindsfromexpindprop(expind,j,nspec);		free_dvector(expind);		es=lnmultinomsuff(obsrvd,expsamp,empdist[0]+1);			free_dvector(expsamp);		}	else	{		es=-1*DBL_MAX;		free_dvector(expind);		}	uth=theta;	++rub;	}sbars=dmatrix(rub+rlb+2,3);/* sbars[0] = ln likelihood   sbars[1] = theta   sbars[2] = richness	*/j=0;for (theta=lth; theta<=uth; theta+=ei)	{	expind=zerosum(theta,bestm,theospc);	x=sumdvector(expind,nspec);									/* estimate richness	*/	y=0;	for (i=1; i<theospc; ++i)	{		if ((((float) i)/theospc) < omega)	{			y+=expind[i];			}		else	{			i=theospc;			}		}	expsamp=expfindsfromexpindprop(expind,j,nspec);	free_dvector(expind);	sbars[j][0]=lnmultinomsuff(obsrvd,expsamp,empdist[0]+1);	/* log likelihood	*/	free_dvector(expsamp);	sbars[j][1]=theta;											/* theta			*/	sbars[j][2]=x;												/* richness			*/	++j;	}return sbars;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES GIVEN ITÕS RANK ABUNDANCE. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *wht_fit_gs(int *empdist, int ntaxa, int nspec) {int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int	rin=ntaxa;				/* initial seed richness 												*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0f;			/* min slope															*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double rs[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array			*/double *fitdist;			/* fit distribution														*/double pbes;				/* previous best support for decay rate									*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);ri=ntaxa/2;if (ri<2)	ri=2;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	pbes = 0.0f;	ei = (double) FITINC / 10;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/		for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; (ev>=emin && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate geometric distribution with richness r and decay of ev */		fitdist = proportional_geos_distribution(ev,r);				/* MAKE DISTRIBUTION */		es[0] = calc_likelihood_Foote(fitdist, empdist, nspec);		/* CALCULATE SUPPORTt */		free_dvector(fitdist);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */			}		else if ((es[2] > es[1]) && (es[0] > es[1]) && ((ev-ei)>emin)) {/* TOO FAR: THE PEAK HAS BEEN PASSED */			ev -= ei;									/* STEP BACK ONE UNIT */			ei *= -1;									/* STEP BACKWARD TO FIND PEAK */			es[1] = es[2];								/* SET PREVIOUS S TO IGNORE OVER STEP */			}		else {											/* NOT IMPROVING TRY SMALLER INCREMENT */			ev -= ei;									/* STEP BACK ONE UNIT */			ei /= 10;									/* SET SMALLER UNIT */			}				while (ev+ei<= emin)	ei/=2;				es[2] = es[1];									/* Store last 2 attempts to identify */		es[1] = es[0];									/* when the peak is past */		}	/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		}	/* optimal richness is overshot */	else if ((rs[2]>rs[1] && (rs[0]>rs[1])) && (abs(ri)>1))	{		r-=ri;				/* step back one unit	 */		ri*=-1;				/* step backwards to peak */		rs[1]=rs[2];		/* set to prior ln L to ignore over step */		}	else	{		r-=ri;		if (abs(ri)>1)	ri/=2;		else			ri=0;		}		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;		rs[2] = rs[1];	rs[1] = bep[0];	}return brp;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE ZIPF-MANDELBROT SERIES GIVEN RANK ABUNDANCES. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file***********************************************************************/double *wht_fit_zm(int *empdist, int ntaxa, int nspec){int i = 0;				/* LOOP VARIABLE	*/int r = 0;					/* LOOP RICHNESS	*/int ri;						/* richness increment	*/int	rin=ntaxa;				/* initial seed richness */int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 		*/double emin = 1.0f;			/* min slope		*/double ein = 1.000f;		/* initial slope	*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double es[3];				/* previous log likelihoods (cell number = num previous).		*/double rs[3];				/* previous log likelihoods (cell number = num previous).		*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array	*/double *fitdist;			/* fit distribution												*/double pbes;				/* previous best support for decay rate							*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */ein=log(ntaxa-1)/(log(empdist[0])-log(empdist[ntaxa-1]));/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);ri=ntaxa/2;if (ri<2)	ri=2;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	pbes = 0.0f;	ei = (double) FITINC / 10;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/		for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; (ev>=emin && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/*Debugging line */		if (ev<=emin)	printf("\nDANGER: ZM R=%d, ev=%f, S=%f ",r,ev,es[0]);		/* generate Zipf-Mandelbrot distribution with richnes r and decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		es[0] = calc_likelihood_Foote(fitdist, empdist, nspec);	/* CALCULATE SUPPORTt */		free_dvector(fitdist);		if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */			}		else if ((es[2] > es[1]) && (es[0] > es[1]) && ((ev-ei)>emin)) {/* TOO FAR: THE PEAK HAS BEEN PASSED */			ev -= ei;									/* STEP BACK ONE UNIT */			ei *= -1;									/* STEP BACKWARD TO FIND PEAK */			es[1] = es[2];								/* SET PREVIOUS S TO IGNORE OVER STEP */			}		else {											/* NOT IMPROVING TRY SMALLER INCREMENT */			ev -= ei;									/* STEP BACK ONE UNIT */			ei /= 10;									/* SET SMALLER UNIT */			}		es[2] = es[1];									/* Store last 2 attempts to identify */		es[1] = es[0];									/* when the peak is past */		}	/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		}	/* optimal richness is overshot */	else if ((rs[2]>rs[1] && (rs[0]>rs[1])) && (abs(ri)>1))	{		r-=ri;				/* step back one unit	 */		ri*=-1;				/* step backwards to peak */		rs[1]=rs[2];		/* set to prior ln L to ignore over step */		}	else	{		r-=ri;		if (abs(ri)>1)	ri/=2;		else			ri=0;		}	rs[2] = rs[1];	rs[1] = bep[0];	}return brp;}/* FIND THE MOST-LIKELY FAUX-LOG-NORMAL SERIES, VARYING INTIAL AND MODAL SLOPE AND THE MODE. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- nspec (sum of array)RETURNS:	- result[0]: log likelihood (truncated)	- result[1]: magnitude of increase per octave (truncated)	- result[2]: optimal richness (truncated)	- result[3]: mode (truncated)	- result[4]: log likelihood (untruncated)	- result[5]: magnitude of increase per octave (untruncated)	- result[6]: optimal richness (untruncated)		- result[7]: mode of untruncated is 0COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *wht_fit_lnt(int *empdist, int ntaxa, int nspec) {int j=0,i=0;				/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;						/* initial richness increment each loop								*/int lri;					/* previous richness increment											*/int rin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxr=5000;				/* this is as long as we can make an array								*/double mode;				/* mode of log-normal, given as a taxon number							*/double x=1.0f;				/* x is the absolute value of the mode - cannot do abs(double)			*/double y=1.0f;double z=1.0f;double mi=-1.0f;			/* how much to increment the mode										*/double lmi=2.0f;			/* prior increment														*/double mimin=0.125;			/* minimum mode change													*/double mdmx=1.5f;double mdmn=-2.5f;double tr;int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double rs[3];				/* previous richness log likelihoods (cell number = num previous).		*/double ms[3];				/* previous mode log likelihoods (cell number = num previous).			*/double bep[2];				/* BEST modal decay parameters - return array format 					*/double brp[3];				/* BEST richness parameters - return array								*/double pbes;				/* previous best support for modal decay								*/double pbrs;				/* previous best support for richness									*/double pbms;				/* previous best support for mode location								*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *fitdist;			/* fit distribution														*/double *bmp;				/* Best mode parameters - return array format							*/bmp=dvector(8);for (i=0; i<8; i++) bmp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);if (rin<100)			j=4;else					j=5;ein=pow(empdist[0],1/((double) j));if (2*rin<75)			mdmx=2.5;else if (2*rin<350)		mdmx=3.0;else if (2*rin<2000)	mdmx=3.5;else if (2*rin<15000)	mdmx=4.0;else 					mdmx=4.5;mdmn=-1*mdmx;/*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/for (i=0; i<3; ++i)	ms[i]=-1.0*DBL_MAX;pbms=0.0f;/* adjust mode until that fails to improve likelihood	*/	/* for some reason the program is disobeying the second part of the conditional */for (mode=0; x>=mimin && (mode>=mdmn && mode<=mdmx)/* && ((pbms == 0.0f) || (bmp[0] > (pbms + SUPINC)))*/; mode+=mi)	{	if (mode==0)	{		ei = ein-1;		tr=0;		}	else	{		ei = ein/10;		tr=1;		}		pbrs=0.0f;	for (i=0; i<3; i++) brp[i]=-1.0*DBL_MAX;	for (i=0; i<3; ++i)	rs[i]= -1.0*DBL_MAX;	/* adjust true richness until that fails to improve likelihood	*/	lri=ri=rin;	if (ri<2)	ri=2;			iri=ri;	for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{		/* make sure that mode starts between beginning and end */		while (abs(mode/2)>r)	++r;				obsrvd[0]=r-ntaxa;		pbes = 0.0f;		/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/				for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;		for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;		if (ein+ei>=mxev)	ei*=-1;		/* increment slope until that fails to improve likelihood or resolution limit reached */		for (ev=ein; ev<=mxev && ((pbes==0.0f) || (bep[0]>(pbes+SUPINC))); ev+=ei)	{						/* generate Log-Normal distribution with richness r with each octave increasing ev times *//*			fitdist = proportional_lgn_distributionN(ev,mode,ocs,r);		/* MAKE DISTRIBUTION */			fitdist=proportional_lgn_distribution(ev,r);			es[0] = calc_likelihood_Foote(fitdist, empdist, nspec);	/* CALCULATE SUPPORTt */			free_dvector(fitdist);			if (es[0] >= bep[0]) {					/* IF BETTER THAN BEST FIT */				pbes = bep[0];						/* save last best likelihood for evenness */				rs[0] = bep[0] = es[0];				/* STORE FIT */				bep[1] = ev;						/* STORE SLOPE */				}			/* check to make sure that this is correct elsewhere */			else if ((es[2] > es[1]) && (es[0] > es[1]) && ((ev-ei)>=emin)) {/* TOO FAR: THE PEAK HAS BEEN PASSED */				ev = bep[1];						/* step back to best magnitude */				ei *= -1;							/* STEP BACKWARD TO FIND PEAK */				es[1] = es[2];						/* SET PREVIOUS S TO IGNORE OVER STEP */				}			else {									/* NOT IMPROVING TRY SMALLER INCREMENT */				ev = bep[1];						/* step back to best magnitude */				ei /= 2;							/* SET SMALLER UNIT */				}			/* it might go on and on forever with miniscule increases when it is a very poor fit */			if ((es[0]>=es[1] && es[0]<(es[1]+SUPINC)) && (es[1]>=es[2] && es[1]<(es[2]+SUPINC)))	break;			es[2] = es[1];							/* Store last 2 attempts to identify */			es[1] = es[0];							/* when the peak is past */			}		/* reset evenness incrementer */		if (r!=rin)			ei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */		else if (r==rin)			ei=bep[1]-ein;				if (ei==0)	ei=bep[1]/10;		/* if this richness is better than the last */		if (bep[0]>=brp[0]) {						/* IF BETTER THAN BEST FIT */			pbrs=brp[0];			brp[2] = r;			for (i=0; i<2; i++)				brp[i] = bep[i];			ms[0]=brp[0];			ein=bep[1];								/* set initial decay to best decay found so far */ 						/* if we are past the initial ri, then we want to use it only once	*/			/* otherwise, we repeat r's											*/			if (ri!=iri && ri!=(-1*iri))	ri/=2;			lri=ri;			}		/* optimal richness is overshot - back up */		else if (abs(ri)==abs(lri))	{			r=brp[2];				/* step back to best richness	 */			lri=ri;			ri/=2;			}		/* two tries in this direction produced poorer results - try the other direction */		else if (abs(lri)>abs(ri))	{			r=brp[2];				/* step back to best richness	 */			lri=ri;			/* do not look at values lower than observed richness */			if ((r-ri)>=ntaxa)	ri*=-1;			else				ri/=2;			}		/* optimal richness is overshot */		else if (rs[2]>rs[1] && rs[0]>rs[1])	{				r=brp[2];				/* step back to best richness	 */			ri*=-1;				/* step backwards to peak */			while ((r+ri)<ntaxa && abs(ri)>0)	ri/=2;			rs[1]=rs[2];		/* set to prior ln L to ignore over step */			}		else	{			r=brp[2];				/* step back to best richness	 */			if (abs(ri)>1)	ri/=2;			else			ri=0;			while ((r+ri)<=ntaxa && abs(ri)>0)	ri/=2;			}		/* it might go on and on forever with miniscule increases when it is a very poor fit */		if ((ri==iri || ri==(-1*iri)) && ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC))))	ri=0;		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */		/* do not bother going for r < observed! */		while ((r+ri)>mxr)	{			if (r==mxr)	{				ri*=-1;				ri/=2;				}			else	ri=mxr-r;			}				while ((r+ri)< ntaxa)	{			if (r==ntaxa)	{				ri*=-1;				ri/=2;				}			else	ri=ntaxa-r;			}		rs[2] = rs[1];		rs[1] = bep[0];		}	/* if this mode is better than the last */	if (brp[0] >= bmp[0]) {								/* IF BETTER THAN BEST FIT */		pbms=bmp[0];		for (i=0; i<3; i++)			bmp[i] = brp[i];		bmp[3] = mode;		/* save the best untruncated log-normal separately */		if (mode==0)	{			for (i=0; i<3; ++i)	bmp[i+4]=brp[i];			bmp[7]=0;			}		/* once we drop to half a mode, then we do not want to go two steps in the same direction */		if (lmi>-1 && lmi<1)	{			lmi=mi;			mi/=2;			}		else lmi=mi;		}	else	{		y=mi;		if (y<0)	y*=-1;		z=lmi;		if (z<0)	z*=-1;				if (mode==mdmx)			mdmx-=mimin;		else if (mode==mdmn)	mdmn+=mimin;				mode-=mi;		lmi=mi;		if (y==z)	/* this means we'll go twice in the same direction - that is bad... */			mi/=2;					else if (z>y)		/* if we've stepped down, then we want to step opposite */			mi*=-1;		/* optimal richness is overshot */		else if (ms[2]>ms[1] && ms[0]>ms[1])	{			mode-=mi;				/* step back one unit	 */			mi*=-1;					/* step backwards to peak */			ms[1]=ms[2];		/* set to prior ln L to ignore over step */			}		else	{			mode-=mi;			mi/=2;			}		}	/* it might go on and on forever with miniscule increases when it is a very poor fit */	if ((ms[0]>=ms[1] && ms[0]<(ms[1]+SUPINC)) && (ms[1]>=ms[2] && ms[1]<(ms[2]+SUPINC)))	ri=0;	ms[2] = ms[1];	ms[1] = brp[0];/*	if (msw>=2 && mrn==1)	{		mi/=2;		if (mi<1)	x=-1*mi;		mrn=0;		}	*/		/* do not overshoot mode limits! */	while ((mode+mi<mdmn || mode+mi>mdmx) && x>mimin)	{		mi/=2;		if (mi<1)	x=-1*mi;		}			ein=bmp[1];										/* set initial modal decay to best modal decay found so far 	*/ 	rin=bmp[2];										/* set initial richness to best richness found so far			*/	x=mi;	if (x<0)	x*=-1;	}free_dvector(obsrvd);return bmp;}/* expectedfinds - finds the expected number of taxa with 0...max finds given binomial probabilities, total finds and distribution/* Requires:		dist - an array giving relative abundances of S taxa (must sum to 1.0);		S - the length of dist (i.e., richness);		mxfds - the number of unique sample numbers - this equals S+1 if all species have a unique number of samples, 2 if all are sampled 				X times (I am considering 0 to be one of the number of times sampled for likely unsampled species		ttl - the total number sampled/* Returns:		expected - an array in which e[x] gives the expected number of species sampled x times	NOTE: sometimes this is really slow - if the maximum number of finds is really high, then use expectedfindspart and modify		routines accordingly.  ******************************************************************************************************************************************/double *expfinds (double *dist, int S, int mxfds, int ttl){int n, m, sp;double *expected, *sumln;double	lp=0.0000000f, lnc=0.0000000f, y=0.0000000f;expected=dvector(mxfds+1);/*                                    N         n       N-n/* the log of a combinatoric (N n) is ·ln(x) - (·ln(y) + ·ln(z))	*/sumln=dvector(ttl+1);for (n=1; n<=ttl; ++n)	sumln[n]+=sumln[n-1]+log(n);/* For each possible number of finds (i.e., 0 to the maximum observed) calculate the expected number of species with n finds */for (n=0; n<=mxfds; ++n)	{	expected[n]=0;	/* calculate combinations in logarithms */	lnc=sumln[ttl]-(sumln[n]+sumln[m=ttl-n]);	for (sp=0; sp<S; ++sp)	{		y=1-dist[sp];		lp=lnc+((double)n)*log(dist[sp])+((double)(ttl-n)*log(y));		expected[n]=expected[n]+pow(e,lp);		}	if (expected[n]==0)	expected[n]=pow(10,-323);	/* this is about as low as you can go */	}free_dvector(sumln);return expected;}/* expectedoccurences - finds the expected number of taxa with 0...max finds given binomial probabilities, total finds and distribution/* Requires:		dist - an array giving relative abundances of S taxa (must sum to 1.0);		S - the length of dist (i.e., richness);		mxfds - the number of unique sample numbers - this equals S+1 if all species have a unique number of samples, 2 if all are sampled 				X times (I am considering 0 to be one of the number of times sampled for likely unsampled species		ttl - the total number sampled/* Returns:		expected - an array in which e[x] gives the expected number of species sampled x times	NOTE: sometimes this is really slow - if the maximum number of finds is really high, then use expectedfindspart and modify		routines accordingly.  ******************************************************************************************************************************************/double *expoccurrences (double *dist, int S, int possfinds){int n;double *expected;double *binomps;expected=dvector(possfinds+1);for (n=0; n<S; ++n)	{	binomps=binomialvector(possfinds, dist[n]);	adddvectors(expected,binomps,possfinds+1);	free_dvector(binomps);	}return expected;}/* expectedfindspart - finds the expected number of taxa with observed numbers finds given binomial probabilities, total finds and distribution/* Requires:		dist - an array giving relative abundances of S taxa (must sum to 1.0);		S - the length of dist (i.e., richness);		nofds - an array giving the sample numbers		unfds - the number of unique sample numbers - this equals S+1 if all species have a unique number of samples, 2 if all are sampled 				X times (I am considering 0 to be one of the number of times sampled for likely unsampled species		ttl - the total number sampled/* Returns:		expected - an array in which e[x] gives the expected number of species sampled x times	NOTE: this is done only for observed numbers of samples because it was too slow to do them all for some reason.....******************************************************************************************************************************************/double *expfindspart (double *dist, int S, long *nofds, int unfds, int ttl){int i, n, m, sp;double *expected, *sumln;double	lp=0.0000000f, lnc=0.0000000f, y=0.0000000f;expected=dvector(unfds);/*                                    N         n       N-n/* the log of a combinatoric (N n) is ·ln(x) - (·ln(y) + ·ln(z))	*/sumln=dvector(ttl+1);for (n=1; n<=ttl; ++n)	sumln[n]+=sumln[n-1]+log(n);/* For each possible number of finds (i.e., 0 to the maximum observed) calculate the expected number of species with n finds */for (i=0; i<unfds; ++i)	{	n=nofds[i];	expected[n]=0;	/* calculate combinations in logarithms */	lnc=sumln[ttl]-(sumln[n]+sumln[m=ttl-n]);	for (sp=0; sp<S; ++sp)	{		y=1-dist[sp];		lp=lnc+((double)n)*log(dist[sp])+((double)(m)*log(y));		expected[i]=expected[i]+pow(e,lp);		}	}free_dvector(sumln);return expected;}/* expectedfindsprop - finds the expected proportion of sampled taxa with 0...max finds given binomial probabilities, total finds and distribution/* Requires:		dist - an array giving relative abundances of S taxa (must sum to 1.0);		S - the length of dist (i.e., richness);		mxfds - the number of unique sample numbers - this equals S+1 if all species have a unique number of samples, 2 if all are sampled 				X times (I am considering 0 to be one of the number of times sampled for likely unsampled species		ttl - the total number sampled/* Returns:		expected - an array in which e[x] gives the expected number of species sampled x times	NOTE: sometimes this is really slow - if the maximum number of finds is really high, then use expectedfindspart and modify		routines accordingly.  ******************************************************************************************************************************************/double *expfindsprop (double *dist, int S, int mxfds, int ttl){int n, m, sp;double *expected, *sumln;double	lp=0.0000000f, lnc=0.0000000f, y=0.0000000f;expected=dvector(mxfds+1);/*                                    N         n       N-n/* the log of a combinatoric (N n) is ·ln(x) - (·ln(y) + ·ln(z))	*/sumln=dvector(ttl+1);for (n=1; n<=ttl; ++n)	sumln[n]+=sumln[n-1]+log(n);/* For each possible number of finds (i.e., 0 to the maximum observed) calculate the expected number of species with n finds */for (n=0; n<=mxfds; ++n)	{	expected[n]=0;	/* calculate combinations in logarithms */	lnc=sumln[ttl]-(sumln[n]+sumln[m=ttl-n]);		for (sp=0; sp<S; ++sp)	{		y=1-dist[sp];		lp=lnc+((double)n)*log(dist[sp])+((double)(m)*log(y));		expected[n]=expected[n]+pow(e,lp);		}	if (expected[n]==0)	expected[n]=pow(10,-323);	/* this is about as low as you can go */		if (n>0)	expected[n]/=(((double) S) - expected[0]);	}free_dvector(sumln);return expected;}/* expectedfindsprop - finds the expected proportion of sampled taxa with 0...max finds given binomial probabilities, total finds and distribution/* Requires:		oct - an array giving the expected number of species with 1Én finds, with oct[1] giving E[species with 1 specimen];		S - the length of dist (i.e., richness);		mxfnds - the finds for the most common taxon; 		ttl - the number of unique sample numbers - this equals S+1 if all species have a unique number of samples, 2 if all are sampled 				X times (I am considering 0 to be one of the number of times sampled for likely unsampled species/* Returns:		expected - an array in which e[x] gives the expected number of species sampled x times	NOTE: sometimes this is really slow - if the maximum number of finds is really high, then use expectedfindspart and modify		routines accordingly.  ******************************************************************************************************************************************/double *expfindsfromexpind (double *exp, int inmx, int nspc){int n, m, t;double	nspcraw=0.0f, S=0.000f;double *expected, *sumln, *expinit;double	lp=0.0000000f, lnc=0.0000000f, pr=0.0000000f, ppr=0.00000000f, y=0.0000000f;/* find the total number of individuals - this is n x E[# of taxa with n specimens] summed over all specimen numbers	*/for (n=1; n<=inmx; ++n)	nspcraw+=((double) n) * exp[n];if (nspcraw<inmx)			inmx=nspcraw;expected=dvector(nspc+1);	/* expected number of species with 0Énspc specimens	*//*                           /N\    N         n       N-n/* the log of a combinatoric \n/ is ·ln(x) - (·ln(y) + ·ln(z))	*/sumln=dvector(nspc+1);for (n=1; n<=nspc; ++n)	sumln[n]+=sumln[n-1]+log(n);expinit=dvector(inmx+1);		/* expected individuals from initial distribution *//* calculate expected frequencies for species with 1, 2, 3 É nspc specimens	*/for (n=1; n<=inmx; ++n)	expinit[n]=((double) n)/nspcraw;/* For each possible number of finds (i.e., 0 to the maximum observed) calculate the expected number of species with n finds */for (n=0; n<=nspc; ++n)	{	expected[n]=0;	/* calculate the log of nspc choose n */		lnc=sumln[nspc]-(sumln[n]+sumln[m=nspc-n]);		/* go through species with init. abund 1Éinmx to find their contribution to expected	*/	/* 		species with n sampled specimens												*/ 	ppr=0.0f;	for (t=1; t<=inmx; ++t)	{		y=1-expinit[t];		lp=lnc+((double)n)*log(expinit[t])+((double)(m)*log(y));		pr=pow(e,lp);		/* because we add probabilities, we need to de-log the log-probabilities		*/		pr*=exp[t];			/* multiply this times the expected number of species with this many specimens	*/		expected[n]+=pr;	/* add to the total			*/			/*		if (pr<ppr && pr<pow(10,-10))	{			t=inmx;			}	*/		ppr=pr;		}	if (expected[n]==0)	expected[n]=pow(10,-323);	/* this is about as low as you can go */	}free_dvector(sumln);free_dvector(expinit);return expected;}/* expectedfindsprop - finds the expected proportion of sampled taxa with 0...max finds given binomial probabilities, total finds and distribution/* Requires:		exp - an array giving the expected number of species with 1Én finds, with exp[1] giving E[species with 1 specimen];		S - the length of dist (i.e., richness);		inmx - the finds for the most common taxon; 		ttl - the number of unique sample numbers - this equals S+1 if all species have a unique number of samples, 2 if all are sampled 				X times (I am considering 0 to be one of the number of times sampled for likely unsampled species/* Returns:		expected - an array in which e[x] gives the expected number of species sampled x times	NOTE: sometimes this is really slow - if the maximum number of finds is really high, then use expectedfindspart and modify		routines accordingly.  ******************************************************************************************************************************************/double *expfindsfromexpindprop (double *exp, int inmx, int nspc){int n, m, t;double	nspcraw=0.0f, S=0.000f;double *expected, *sumln, *expinit;double	lp=0.0000000f, lnc=0.0000000f, pr=0.0000000f, y=0.0000000f;/* find the total number of individuals - this is n x E[# of taxa with n specimens] summed over all specimen numbers	*/for (n=1; n<=inmx; ++n)	nspcraw+=((double) n) * exp[n];expected=dvector(nspc+1);	/* expected number of species with 0Énspc specimens	*//*                           /N\    N         n       N-n/* the log of a combinatoric \n/ is ·ln(x) - (·ln(y) + ·ln(z))	*/sumln=dvector(nspc+1);for (n=1; n<=nspc; ++n)	{	sumln[n]+=sumln[n-1]+log(n);	}expinit=dvector(inmx+1);		/* expected individuals from initial distribution *//* calculate expected frequencies for species with 1, 2, 3 É nspc specimens	*/for (n=1; n<=inmx; ++n)	{	expinit[n]=((double) n)/nspcraw;	}/* For each possible number of finds (i.e., 0 to the maximum observed) calculate the expected number of species with n finds */for (n=0; n<=nspc; ++n)	{	expected[n]=0;	/* calculate the log of nspc choose n */		lnc=sumln[nspc]-(sumln[n]+sumln[m=nspc-n]);		/* go through species with init. abund 1Éinmx to find their contribution to expected	*/	/* 		species with n sampled specimens												*/ 	for (t=1; t<=inmx; ++t)	{		y=1-expinit[t];		lp=lnc+((double)n)*log(expinit[t])+((double)(m)*log(y));		if (lp>-725)	{			pr=pow(e,lp);		/* because we add probabilities, we need to de-log the log-probabilities		*/			pr*=exp[t];			/* multiply this times the expected number of species with this many specimens	*/			expected[n]+=pr;	/* add to the total			*/			}	/* added 3/11/2009 to prevent overly low numbers	*/		}	if (expected[n]==0)	expected[n]=pow(10,-323);	/* this is about as low as you can go */	}S=sumdvector(expected,nspc+1);S-=expected[0];for (n=1; n<=nspc; ++n)	expected[n]/=S;free_dvector(sumln);free_dvector(expinit);return expected;}/* expectedfindsln - finds the expected number of taxa with 0...max finds given binomial probabilities for a lognormal distribution/* Requires:		mag - an magnitude of increase for each octave;		mode - where the mode is, given as a taxon number (median of 1ÉS if untruncated);		S - where the mode is, given as a taxon number (median of 1ÉS if untruncated);		mxfds - maximum finds with which to bother/* Returns:		expected - an array in which e[x] gives the expected number of species sampled x times	NOTE: sometimes this is really slow - if the maximum number of finds is really high, then use expectedfindspart and modify		routines accordingly.  ******************************************************************************************************************************************/double *expfindsln (double mag, int S, int mxfds, int t){int		j, m, n, sp, mxsp=0;double	oct, moct, x, rnd=0.0f, ttl=0.0f;double	lp=0.0000000f, lnc=0.0000000f, y=0.0000000f;double	*fn;double	*expected;expected=dvector(mxfds+1);x=S;for (n=1; x>=normheight(0,0,1); ++n)	{	x=S*normheight(n,0,1);	}	/* make sure that mxsp>=mxfds *//* if S<100, then there are 5 octaves that should have species */if (S<100)	{	mxsp=pow(mag,5);/*	moct=mode + (((double) n) - 0.5);	*/	moct=2.5;	}/* if S>100, then there are 6 octaves that should have species *//* if S>1000, then there are 7 octaves that should have species - however, that 		blows out memory, so we have to get by on 6 */else	{	mxsp=pow(mag,6);	moct=3.0f;	}if (mxsp<mxfds)	mxsp=mxfds;fn=dvector(mxsp+1);/* find the probability of species beginning with n specimens*/for (n=1; n<=mxsp; ++n)	{	/* calculate how far along the x-axis we are given that the axis really is in a log-scale */	oct=log(n)/log(mag);	x=0.5+n;	/* find the area within the histogram centred on n - that is the expected frequency of species with n specimens */	if (n>1)	{		fn[n]=((double) S)*normheight(oct,moct,1)*((log(x)/log(mag))-(log(x-1)/log(mag)));		}	else	{		fn[n]=((double) S)*normheight(oct,moct,1)*(log(x)/log(mag));		}	/* estimate the total number of expected individuals */	ttl+=fn[n]*((double) n);	}/* now calculate the expected number of species with n specimens 	*//* this is P[n | fn] x E[fn]										*/for (n=0; n<=mxfds; ++n)	{	expected[n]=0;	/* calculate combinations in logarithms */	lnc=0.0000000f;	m=n;	if (m>(t-n))	m=t-n;	for (j=(t-m)+1; j<=t; ++j)		lnc=lnc+log(j);	for (j=2; j<=m; ++j)			lnc=lnc-log(j);	for (sp=1; sp<=mxsp; ++sp)	{		y=1-(((double) sp)/ttl);	/* y = probability of not sampling the taxon */		lp=lnc+((double)n)*log(((double) sp)/ttl)+((double)(t-n)*log(y));		/* add a conditional probability because we do not expect simply one species */		lp+=log(fn[sp]);		expected[n]=expected[n]+pow(e,lp);		}	rnd+=expected[n];	}for (n=0; n<=mxfds; ++n)	expected[n]*=((double) S)/rnd;free_dvector(fn);return expected;}double **richness_support_bars_mul_geo(double ubS, double lbS, double inc, double minf, int ntaxa, int *empdist){int i=0, j=0, k=0;			/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int nspec;					/* number of specimens													*/int bars;					/* number of values														*/double ev = 0.000f;			/* LOOP SLOPE 															*/double ein = 1.00001f;		/* initial slope														*/double mS;double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double **sbars;				/* support and slopes for richness values within bar units of support	*/double	rich, x, y;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);rich=10*ubS;/* find the slope for the upper bound first	*/ein=1.0001;for (ev=ein; rich>ubS; ev+=0.0001)	{	rich=1+((log(minf)-log(1-(1/ev)))/log(1/ev));	}ein=ev-0.0001;bars=1+((ubS-lbS)/inc);sbars=dmatrix(bars,4);i=0;for (ev=ein; rich>=(lbS-inc); ev=ev)	{	/* generate Geometric distribution with richness r and log-decay of ev */	fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION */	x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	r=x;	if ((x-r)>=0.5)	++r;	/* find the expected proportions of taxa with 0Éx finds */	expect=expfinds(fitdist,r,nspec,nspec);	free_dvector(fitdist);	sbars[i][0]=rich;	expect[0]=0;	x=sumdvector(expect,nspec);	for (j=1; j<nspec; ++j)	expect[j]/=x;	sbars[i][1]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	if (i==0)	mS=sbars[0][1];	else		if (sbars[i][1]>mS)	mS=sbars[i][1];	free_dvector(expect);	sbars[i][2]=ev;	sbars[i][3]=1/ev;		y=rich;	for (ev=ev; y>(rich-inc); ev+=0.0001)	{		y=1+((log(minf)-log(1-(1/ev)))/log(1/ev));		}	rich=y;	ev-=0.0001;	++i;	}for (j=0; j<i; ++j)	sbars[j][1]-=mS;return sbars;}/* fuzz_fit_mul_uniforms: determine best single rate from "fuzzy" estimate of numbers of events with alpha=betainput:	dist: number of times we see 0, 1, 2, etc.	obsr: observed entities;	mxstp: maximum number of times that we might see something;	base: average "rate" around which gamma is centered	pts: number of partitions output:	bdel[0]: maximum likelihood of uniform model;	bals[1]: ml single rate;	bals[2]: ml "richness";*****************************************************************************************************/double *fuzz_fit_mul_uniform(double *dist, int obsr, int mxstp){int i,j;					/* LOOP VARIABLE														*/double dl = 0.000f;			/* LOOP SLOPE 															*/double dmin = 0.000000001f;	/* min slope															*/double din = 1.000f;		/* initial slope														*/double di = 0.000f;			/* how much to increment ev in each loop								*/double ldi[2];				/* last two slope increments											*/double idi;					/* initial slope increment at each richness								*/double mpsteps=0.0f;		/* most probable number of steps										*/double mdi=0.000001f;		/* minimum evenness increment											*/double dls[3];				/* previous log likelihoods (cell number = num previous).				*/double *bdel;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double pdel;				/* previous best support for decay rate									*/double *steps;				/* number of characters with X steps 									*///double *expsamp				/* proportion of characters in each partition that should change	*/double x, y, z, rich;for (i=1; i<=mxstp; ++i)	mpsteps+=((double) i)*(dist[i]);din=mpsteps/((double) obsr);bdel=dvector(3);for (i=0; i<2; i++) bdel[i]= -1.0*DBL_MAX;di=idi=din/10;if (di==0)	di=0.00001f;pdel = 0.0f;/*	di = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bdel[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) dls[i] = -1.0*DBL_MAX;ldi[0]=ldi[1]=0.0f;steps=dvector(mxstp+1);//expsamp=dvector(4);/* run while:	 delta (dl) is greater than the minimum dl;	 absolute incrementation of delta (di) is greater than some minimum (mdi);	 best support (bdel[0] is sufficiently greater than previous best support (pblas+SUPINC)******************************************************************************************************/for (dl = din; ((dl>=dmin && fabs(di)>mdi) && ((pdel == 0.0f) || (bdel[0] > (pdel + SUPINC)))); dl += di) {		/* now, find the number of total entities that predict the "base": i.e., true richness given observed	*/	x=1-(exp(-1*dl));							/* expected proportion that will be sampled zero times	*/	rich=((double) obsr)/x;		/* get the expected sampled distribution */	z=0.0f;	cleardvector(steps,mxstp+1,0);	for (j=1; j<mxstp; ++j)	{		y=lnPoisson(dl,1,j);					/* get the probability of j changes given expected change parts[i]*base	*/		y=pow(e,y);								/* convert log probability to probability			*/		steps[j]+=y;							/* gets the expected number of observations with j	*/		z+=y;									/* gets area under curve to get pdf					*/		}	/* go from 0 -> maxsteps so that we can standardize to 1.0 in the end	*///	z=0.0f;	/* the df is incomplete; so, rescale to area to get pdf	*///	for (j=1; j<=mxstp; ++j)	z+=steps[j];	/* z = area under df	*/	/* calculate likelihood of uniform distribution with rate dl	*/	dls[0]=0;	for (j=1; j<mxstp; ++j)	{//		x=0.0f;									/* get sum of conditional probabilities given rates	*///		x+=steps[j];							/* this gives the expected proportion with j steps	*///		x/=z;									/* rescale so that pdf = 1.0						*///		dls[0]+=dist[j]*log(x);					/* this gives log probability of the observation	*///		dls[0]+=dist[j]*log(steps[j]/z);		/* this gives log probability of the observation	*/		steps[j]/=z;		dls[0]+=dist[j]*log(steps[j]);		/* this gives log probability of the observation	*/		}	/*Debugging line */	if (dl<=dmin) printf("\nDANGER: gamma alpha=%f, S=%f ",dl,dls[0]);	if (dls[0] >= bdel[0]) {						/* IF BETTER THAN BEST FIT */		pdel = bdel[0];								/* save last best ssq for evenness */		bdel[0] = dls[0];							/* STORE FIT */		bdel[1] = dl;								/* STORE RATE */		bdel[2] = rich;								/* STORE RATE */				/* while we are getting better on the initial increment, just ride with it			*/		if (fabs(di)==fabs(idi))	{			ldi[1]=ldi[0];			ldi[0]=di;			while ((dl+di)<0)	di/2;				/* don't let this go to negatives	*/			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			ldi[1]=ldi[0];			ldi[0]=di;			di/=-2;			if ((dl+di)<=dmin)	di*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half *///		ldi[1]=ldi[0];//		ldi[0]=di;		if (di==-1*ldi[0] || di==idi)	{			ldi[1]=ldi[0];			ldi[0]=di;			/* if we go up one and it doesn't work out, then go down 1	*/			if (dl==(din+idi))	{				di/=-1;				}			/* if we already have incremented successfully, then try again with increment cut in half	*/			else if (di==idi)	{				/* determine whether dls[0] or dls[2] is the second best - move towards that	*//*				if (dls[0]>dls[2])	di/=2;				else				di/=-2;	*/				di/=2;							/* redone 20.03.2009 to get this to search properly	*/				}			else	{				/* determine whether dls[0] or dls[1] is the second best - move towards that	*//*				if (dls[0]>dls[1])	di/=2;				else				di/=-2;	*/				if (fabs(ldi[0])==fabs(di))	di/=2;				else						di*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (di==-1*idi || (2*fabs(di)==fabs(ldi[0])))	{			/* if dl+x/2 got closer than dl-x, back up and go to dl+x/4				if (dls[0]>dls[2])	di/=2;			/* otherwise go to dl-x/2												else				di*=-1;	*/			/* if we are dealing with the initial absolute value, then cut in half	*///			if (fabs(ldi[0])==fabs(di) || fabs(ldi[0])==fabs(ldi[1]))		{			if (fabs(ldi[0])==fabs(di))		{				ldi[1]=ldi[0];				ldi[0]=di;				di/=2;					}			/* if we just decremented, then reverse course instead	*/			else	{				ldi[1]=ldi[0];				ldi[0]=di;				di*=-1;				}			}		dl=bdel[1];		}	/* make sure that di does not take dl below 1.0 */	while (dl+di<= dmin)	{		if (fabs(ldi[0])==fabs(ldi[1]))	di/=2;		else							di=-1*ldi[0];		}			dls[2] = dls[1];									/* Store last 2 attempts to identify	*/	dls[1] = dls[0];									/* when the peak is past 				*/	}free_dvector(steps);				/* number of characters with X steps								*/return bdel;}/* fuzz_fit_mul_onepgamma: determine gamma distributiuon from "fuzzy" estimate of numbers of events with alpha=betainput:	dist: number of times we see 0, 1, 2, etc.	obsr: observed entities;	mxstp: maximum number of times that we might see something;	base: average "rate" around which gamma is centered	pts: number of partitions output:	bals[0]: maximum likelihood of gamma model;	bals[1]: ml alpha;*****************************************************************************************************/double *fuzz_fit_mul_onepgamma(double *dist, int obsr, int mxstp, double base, int pts){int i,j;					/* LOOP VARIABLE													*/double al = 0.000f;			/* LOOP SLOPE 														*/double amin = 0.000000001f;	/* min slope														*/double ain = 1.000f;		/* initial slope													*/double ai = 0.000f;			/* how much to increment ev in each loop							*/double lai[2];				/* last two slope increments										*/double iai;					/* initial slope increment at each richness							*/double mpsteps=0.0f;		/* most probable number of steps									*/double mai=0.000001f;		/* minimum evenness increment										*/double als[3];				/* previous log likelihoods (cell number = num previous).			*/double *bals;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double pbals;				/* previous best support for decay rate								*/double *parts;				/* partitions of gamma distribution									*/double **steps;				/* number of characters with X steps from each part of gamma		*///double *expsamp				/* proportion of characters in each partition that should change	*/double x, y, z, rich;for (i=1; i<=mxstp; ++i)	mpsteps+=((double) i)*(dist[i]);bals=dvector(2);for (i=0; i<2; i++) bals[i]= -1.0*DBL_MAX;ain=1.0f;ai=iai=1.0f;if (ai==0)	ai=0.00001f;pbals = 0.0f;/*	ai = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bals[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) als[i] = -1.0*DBL_MAX;lai[0]=lai[1]=0.0f;steps=dmatrix(pts,mxstp+1);//expsamp=dvector(4);/* run while:	 alpha (al) is greater than the minimum al;	 absolute incrementation of alpha (ai) is greater than some minimum (mai);	 best support (bals[0] is sufficiently greater than previous best support (pblas+SUPINC)******************************************************************************************************/for (al = ain; ((al>=amin && fabs(ai)>mai) && ((pbals == 0.0f) || (bals[0] > (pbals + SUPINC)))); al += ai) {			/* calculate gamma distribution	with alpha=beta=al	*/	parts=gammapartitionmids(al,al,pts);	x=sumdvector(parts,pts);	x/=((double) pts);								/* x now is the average of the vector	*/	for (i=0; i<pts; ++i)	parts[i]/=x;			/* this centers partitions around 1.0	*/		/* now, find the number of total entities that predict the "base": i.e., true richness given observed	*/	y=0;	for (i=0; i<4; ++i)	{		y+=1-(exp(-1*parts[i]*base));		}	rich=4*((double) obsr)/y;		/* get the expected sampled distribution */	cleardmatrix(steps,4,mxstp+1,0);	for (i=0; i<pts; ++i)	{		x=0;		for (j=0; j<=mxstp; ++j)	{			y=lnPoisson(base*parts[i],1,j);		/* get the probability of j changes given expected change parts[i]*base	*/			y=pow(e,y);								/* convert log probability to probability			*/			steps[i][j]+=y;							/* gets the expected number of observations with j	*/			x+=y;									/* gets area under curve to get pdf					*/			}	/* go from 0 -> maxsteps so that we can standardize to 1.0 in the end	*/		for (j=0; j<=mxstp; ++j)	steps[i][j]/=(4*x);		}	z=0.0f;	/* the df is incomplete; so, rescale to area to get pdf	*/	for (i=0; i<pts; ++i)	for (j=1; j<=mxstp; ++j)	z+=steps[i][j];	/* z = area under df	*/	/* calculate likelihood of gamma distribution	*/	als[0]=0;	for (j=1; j<mxstp; ++j)	{		x=0.0f;									/* get sum of conditional probabilities given rates	*/		for (i=0; i<4; ++i)	x+=steps[i][j];		/* this gives the expected proportion with j steps	*/		x/=z;									/* rescale so that pdf = 1.0						*/		als[0]+=dist[j]*log(x);					/* this gives log probability of the observation	*/		}	/*Debugging line */	if (al<=amin) printf("\nDANGER: gamma alpha=%f, S=%f ",al,als[0]);	if (als[0] >= bals[0]) {							/* IF BETTER THAN BEST FIT */		pbals = bals[0];								/* save last best ssq for evenness */		bals[0] = als[0];								/* STORE FIT */		bals[1] = al;								/* STORE SLOPE */				/* while we are getting better on the initial increment, just ride with it			*/		if (ai==iai)	{			lai[1]=lai[0];			lai[0]=ai;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lai[1]=lai[0];			lai[0]=ai;			ai/=-2;			if ((al+ai)<=amin)	ai*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ai==-1*lai[0] || ai==iai)	{			lai[1]=lai[0];			lai[0]=ai;			if (al==(ain+iai))	{				ai/=-2;				}			else if (ai==iai)	{				/* determine whether als[0] or als[2] is the second best - move towards that	*//*				if (als[0]>als[2])	ai/=2;				else				ai/=-2;	*/				ai/=2;							/* redone 20.03.2009 to get this to search properly	*/				}			else	{				/* determine whether als[0] or als[1] is the second best - move towards that	*//*				if (als[0]>als[1])	ai/=2;				else				ai/=-2;	*/				if (fabs(lai[0])==ai)	ai/=2;				else					ai*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ai==-1*iai || (2*fabs(ai)==fabs(lai[0])))	{			/* if al+x/2 got closer than al-x, back up and go to al+x/4				if (als[0]>als[2])	ai/=2;			/* otherwise go to al-x/2												else				ai*=-1;	*/			if (fabs(lai[0])==ai)		{				lai[1]=lai[0];				lai[0]=ai;				ai/=2;					}			else	{				lai[1]=lai[0];				lai[0]=ai;				ai*=-1;				}			}		al=bals[1];		}	/* make sure that ai does not take al below 1.0 */	while (al+ai<= amin)	{		if (fabs(lai[0])==fabs(lai[1]))	ai/=2;		else							ai=-1*lai[0];		}			als[2] = als[1];									/* Store last 2 attempts to identify	*/	als[1] = als[0];									/* when the peak is past 				*/	}free_dvector(parts);			/* partitions of gamma distribution									*/free_dmatrix(steps,4,mxstp+1);				/* number of characters with X steps								*/return bals;}/* fuzz_fit_mul_twopgamma: determine gamma distributiuon & average rate from "fuzzy" estimate of numbers of events with alpha=betainput:	dist: number of times we see 0, 1, 2, etc.	obsr: observed entities;	mxstp: maximum number of times that we might see something;	din: initial average rate, d, around which gamma is centered	pts: number of partitions output:	bgam[0]: maximum likelihood of gamma model;	bgam[1]: ml average rate;	bgam[2]: ml alpha;	bgam[3]: ml "richness";*****************************************************************************************************/double *fuzz_fit_mul_twopgamma(double *dist, int obsr, int mxstp, double din, int pts){int i,j;					/* LOOP VARIABLE													*/double al = 0.000f;			/* LOOP SLOPE 														*/double amin = 0.000000001f;	/* min alpha														*/double amax = 100.0f;		/* max alpha														*/double ain = 1.000f;		/* initial slope													*/double ai = 0.000f;			/* how much to increment ev in each loop							*/double lai[2];				/* last two slope increments										*/double iai;					/* initial slope increment at each richness							*/double mai=0.000001f;		/* minimum evenness increment										*/double als[3];				/* previous log likelihoods (cell number = num previous).			*/double *bals;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double pbals;				/* previous best support for decay rate								*/double *parts;				/* partitions of gamma distribution									*/double **steps;				/* number of characters with X steps from each part of gamma		*/double x, y, z, rich;double dl = 0.000f;			/* LOOP SLOPE 															*/double dmin = 0.000000001f;	/* min slope															*/double di = 0.000f;			/* how much to increment ev in each loop								*/double ldi[2];				/* last two slope increments											*/double idi;					/* initial slope increment at each richness								*/double mdi=0.000001f;		/* minimum evenness increment											*/double dls[3];				/* previous log likelihoods (cell number = num previous).				*/double *bgam;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double pdel;				/* previous best support for decay rate									*///for (i=1; i<=mxstp; ++i)	mpsteps+=((double) i)*(dist[i]);//din=mpsteps/((double) obsr);bals=dvector(2);bgam=dvector(4);cleardvector(bgam,3,-1.0*DBL_MAX);di=idi=din/10;			/* increment base rate by one tenths	*/if (di==0)	di=0.00001f;pdel = 0.0f;/*	di = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bgam[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) dls[i] = -1.0*DBL_MAX;ldi[0]=ldi[1]=0.0f;steps=dmatrix(pts,mxstp+1);//expsamp=dvector(4);/* run while:	 delta (dl) is greater than the minimum dl;	 absolute incrementation of delta (di) is greater than some minimum (mdi);	 best support (bgam[0] is sufficiently greater than previous best support (pblas+SUPINC)******************************************************************************************************/ain=1.0f;for (dl = din; ((dl>=dmin && fabs(di)>mdi) && ((pdel == 0.0f) || (bgam[0] > (pdel + SUPINC)))); dl += di) {		/* now, find the number of total entities that predict the "base": i.e., true richness given observed	*/		ai=iai=(ain/2);	if (ai==0)	ai=0.00001f;	pbals = 0.0f;	cleardvector(bals,2,-1.0*DBL_MAX);	for (al = ain; ((al>=amin && fabs(ai)>mai) && ((pbals == 0.0f) || (bals[0] > (pbals + SUPINC)))); al += ai) {					/* calculate gamma distribution	with alpha=beta=al	*/		parts=gammapartitionmids(al,al,pts);		x=sumdvector(parts,pts);		x/=((double) pts);								/* x now is the average of the vector	*/		for (i=0; i<pts; ++i)	parts[i]/=x;			/* this centers partitions around 1.0	*/				/* now, find the number of total entities that predict the "base": i.e., true richness given observed	*/		y=0;		for (i=0; i<4; ++i)	{			y+=1-(exp(-1*parts[i]*dl));					/* this is the probability of being found given expected finds parts[i]*dl	*/			}		rich=4*((double) obsr)/y;						/* this gives the true richness that would produce the observed richness	*/				/* get the expected sampled distribution */		cleardmatrix(steps,4,mxstp+1,0);		for (i=0; i<pts; ++i)	{			x=0.0f;			/* NOTE: Start at zero to get initial distribution; the final distribution will use only 1Émxstp;						However, we still need to take into account that low rates will contribute few observed chars	*/			for (j=0; j<mxstp; ++j)	{				y=lnPoisson(dl*parts[i],1,j);		/* get the probability of j changes given expected change parts[i]*base	*/				y=pow(e,y);								/* convert log probability to probability			*/				steps[i][j]+=y;							/* gets the expected number of observations with j	*/				x+=y;									/* gets area under curve to get pdf					*/				}	/* go from 0 -> maxsteps so that we can standardize to 1.0 in the end	*/			for (j=1; j<mxstp; ++j)	steps[i][j]/=(4*x);			}		z=0.0f;	/* the df is incomplete; so, rescale to area to get pdf	*/		for (i=0; i<pts; ++i)	for (j=1; j<mxstp; ++j)	z+=steps[i][j];	/* z = area under df	*/		/* calculate likelihood of gamma distribution	*/		als[0]=0;		for (j=1; j<mxstp; ++j)	{			x=0.0f;									/* get sum of conditional probabilities given rates	*/			for (i=0; i<4; ++i)	x+=steps[i][j];		/* this gives the expected proportion with j steps	*/			x/=z;									/* rescale so that pdf = 1.0						*/			als[0]+=dist[j]*log(x);					/* this gives log probability of the observation	*/			}		/*Debugging line */		if (al<=amin) printf("\nDANGER: gamma alpha=%f, S=%f ",al,als[0]);		if (als[0] >= bals[0]) {							/* IF BETTER THAN BEST FIT */			pbals = bals[0];								/* save last best ssq for evenness */			bals[0] = als[0];								/* STORE FIT */			bals[1] = al;									/* STORE new best alpha */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(ai)==fabs(iai))	{				lai[1]=lai[0];				lai[0]=ai;				if ((x=al+ai)>=amax)					while ((al+ai)>=amax)	ai/=2;		/* 2010-02-09 Added to prevent blow ups!	*/				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lai[1]=lai[0];				lai[0]=ai;				if ((al+ai)<amin)	ai/=-2;				else					while ((al+ai)>=amax)	ai/=2;		/* 2010-02-09 Added to prevent blow ups!	*/				if ((al+ai)<=amin)	ai*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ai==iai)	{				lai[1]=lai[0];				lai[0]=ai;				/* if stepping the opposite direction does not drop to a negative alpha, then simply flip the sign	*/				if ((bals[1]-ai)>=amin)	ai*=-1;				else					ai/=2;				}			else if (ai==-1*lai[0])	{//			if (ai==-1*lai[0] || ai==iai)	{				lai[1]=lai[0];				lai[0]=ai;				/* step halfway into the direction that improved the score	*/				if (als[0]>als[1])	ai/=2;				else				ai/=-2;//				if (al==(ain+iai))	{//					ai/=-2;					/* shouldn't this be -1? 2011-02-18	*///					}//				else if (fabs(ai)==fabs(iai))	{					/* determine whether als[0] or als[2] is the second best - move towards that	*/	/*				if (als[0]>als[2])	ai/=2;/*					else				ai/=-2;	*///					ai/=2;							/* redone 20.03.2009 to get this to search properly	*///					}//				else	{					/* determine whether als[0] or als[1] is the second best - move towards that	*/	/*				if (als[0]>als[1])	ai/=2;/*					else				ai/=-2;	*///					if (fabs(lai[0])==ai)	ai/=2;//					else					ai*=-1;//					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ai==-1*iai || (2*fabs(ai)==fabs(lai[0])))	{				/* if al+x/2 got closer than al-x, back up and go to al+x/4					if (als[0]>als[2])	ai/=2;				/* otherwise go to al-x/2													else				ai*=-1;	*/				if (fabs(lai[0])==fabs(ai))		{					lai[1]=lai[0];					lai[0]=ai;					ai/=2;						}				else	{					lai[1]=lai[0];					lai[0]=ai;					ai*=-1;					}				}			/* if we have overshot amax on initial run!	*/			else if (lai[0]==(ain/2) && ((ain+lai[0])>=amax))	{				lai[1]=lai[0];				lai[0]=ai;				ai/=2;					}							/* this is a kluge	*/			else if (ai==lai[0] && als[0]==als[1])	{				ai*=-1;				/* do not bother with the usual alterations: we repeated ourselves somehow	*/				}			al=bals[1];			}		/* make sure that ai does not take al below 1.0 */		while (al+ai<= amin)	{			if (fabs(lai[0])==fabs(lai[1]))	ai/=2;			else							ai=-1*lai[0];			}		while (al+ai>= amax)	{			ai/=2;			}					als[2] = als[1];									/* Store last 2 attempts to identify	*/		als[1] = als[0];									/* when the peak is past 				*/		}		/* 	/* get the expected sampled distribution */	/* IF BEST FIT YET!!!	*/	if (bals[0] >= bgam[0]) {								pdel = bgam[0];								/* save best fit for comparison		*/		bgam[0] = bals[0];							/* STORE FIT 						*/		bgam[1] = dl;								/* store rate						*/		ain=bgam[2]=bals[1];						/* store best alpha = beta			*/		bgam[3] = rich;								/* store "richness"					*/		/* while we are getting better on the initial increment, just ride with it		*/		if (fabs(di)==fabs(idi))	{			ldi[1]=ldi[0];			ldi[0]=di;			while ((dl+di)<0)	di/2;				/* don't let this go to negatives	*/			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			ldi[1]=ldi[0];			ldi[0]=di;			di/=-2;			if ((dl+di)<=dmin)	di*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (di==-1*ldi[0] || di==idi)	{			ldi[1]=ldi[0];			ldi[0]=di;			/* if we go up one and it doesn't work out, then go down 1	*/			if (dl==(din+idi))	{				di/=-1;				}			/* if we already have incremented successfully, then try again with increment cut in half	*/			else if (fabs(di)==fabs(idi))	{				/* determine whether dls[0] or dls[2] is the second best - move towards that	*/				di/=2;							/* redone 20.03.2009 to get this to search properly	*/				}			else	{				/* determine whether dls[0] or dls[1] is the second best - move towards that	*/				if (fabs(ldi[0])==fabs(di))	di/=2;				else						di*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (di==-1*idi || (2*fabs(di)==fabs(ldi[0])))	{			/* if we are dealing with the initial absolute value, then cut in half	*/			if (fabs(ldi[0])==fabs(di))		{				ldi[1]=ldi[0];				ldi[0]=di;				di/=2;					}			/* if we just decremented, then reverse course instead	*/			else	{				ldi[1]=ldi[0];				ldi[0]=di;				di*=-1;				}			}		dl=bgam[1];		/* reset to best rate	*/		}	/* make sure that di does not take dl below 1.0 */	while (dl+di<= dmin)	{		if (fabs(ldi[0])==fabs(ldi[1]))	di/=2;		else							di=-1*ldi[0];		}			dls[2] = dls[1];									/* Store last 2 attempts to identify	*/	dls[1] = dls[0];									/* when the peak is past 				*/	}free_dmatrix(steps,pts,mxstp+1);				/* number of characters with X steps								*/return bgam;}double *fuzz_fit_mul_lognormal(double *dist, int obsr, int mxstp, double base, int pts) {int i,j;					/* LOOP VARIABLE													*/double oc = 0.000f;			/* LOOP SLOPE 														*/double omin = 1.000000001f;	/* min slope														*/double oin = 1.000f;		/* initial slope													*/double oi = 0.000f;			/* how much to increment ev in each loop							*/double loi[2];				/* last two slope increments										*/double ioi;					/* initial slope increment at each richness							*/double moi=0.000001f;		/* minimum evenness increment										*/double ocs[3];				/* previous log likelihoods (cell number = num previous).			*/double *bocs;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double pbocs;				/* previous best support for decay rate								*/double *parts;				/* partitions of lognormal distribution									*/double **steps;				/* number of characters with X steps								*/double x, y, z, rich;bocs=dvector(2);for (i=0; i<2; i++) bocs[i]= -1.0*DBL_MAX;oin=2.0f;oi=ioi=1.0f;if (oi==0)	oi=0.00001f;pbocs = 0.0f;/*	oi = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bocs[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) ocs[i] = -1.0*DBL_MAX;loi[0]=loi[1]=0.0f;steps=dmatrix(4,mxstp+1);for (oc = oin; ((oc>=omin && fabs(oi)>moi) && ((pbocs == 0.0f) || (bocs[0] > (pbocs + SUPINC)))); oc += oi) {			/* calculate lognormal distribution	with µ=0 & sd=1	*///	for (i=0; i<pts; ++i)	parts[i]=pow(oc,iparts[i]);	parts=lgnormpartitionmids(oc, 4);	x=sumdvector(parts,pts);	x/=((double) pts);								/* x now is the average of the vector	*/	for (i=0; i<pts; ++i)	parts[i]/=x;			/* this centers partitions around 1.0	*/		/* now, find the number of total entities that predict the "base": i.e., true richness given observed	*/	y=0;	for (i=0; i<4; ++i)	{		y+=1-(exp(-1*parts[i]*base));		}	rich=4*((double) obsr)/y;		/* get the expected sampled distribution */	cleardmatrix(steps,4,mxstp+1,0);	for (i=0; i<pts; ++i)	{		x=0;		for (j=0; j<=mxstp; ++j)	{			y=lnPoisson(base*parts[i],1,j);		/* get the probability of j changes given expected change parts[i]*base	*/			y=pow(e,y);								/* convert log probability to probability			*/			steps[i][j]+=y;							/* gets the expected number of observations with j	*/			x+=y;									/* gets area under curve to get pdf					*/			}	/* go from 0 -> maxsteps so that we can standardize to 1.0 in the end	*/		for (j=0; j<=mxstp; ++j)	steps[i][j]/=(4*x);		}	z=0.0f;	/* the df is incomplete; so, rescale to area to get pdf	*/	for (i=0; i<pts; ++i)	for (j=1; j<=mxstp; ++j)	z+=steps[i][j];	/* z = area under df	*/	/* calculate likelihood of gamma distribution	*/	ocs[0]=0;	for (j=1; j<mxstp; ++j)	{		x=0.0f;									/* get sum of conditional probabilities given rates	*/		for (i=0; i<4; ++i)	x+=steps[i][j];		/* this gives the expected proportion with j steps	*/		x/=z;									/* rescale by area under df to get a pdf			*/		ocs[0]+=dist[j]*log(x);					/* this gives log probability of the observation	*/		}	/*Debugging line */	if (oc<=omin) printf("\nDANGER: lognormal octave=%f, S=%f ",oc,ocs[0]);	if (ocs[0] >= bocs[0]) {							/* IF BETTER THAN BEST FIT */		pbocs = bocs[0];								/* save last best ssq for evenness */		bocs[0] = ocs[0];								/* STORE FIT */		bocs[1] = oc;								/* STORE SLOPE */				/* while we are getting better on the initial increment, just ride with it			*/		if (oi==ioi)	{			loi[1]=loi[0];			loi[0]=oi;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			loi[1]=loi[0];			loi[0]=oi;			oi/=-2;			if ((oc+oi)<=omin)	oi*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (oi==-1*loi[0] || oi==ioi)	{			loi[1]=loi[0];			loi[0]=oi;			if (oc==(oin+ioi))	{				oi/=-2;				}			else if (oi==ioi)	{				/* determine whether ocs[0] or ocs[2] is the second best - move towards that	*//*				if (ocs[0]>ocs[2])	oi/=2;				else				oi/=-2;	*/				oi/=2;							/* redone 20.03.2009 to get this to search properly	*/				}			else	{				/* determine whether ocs[0] or ocs[1] is the second best - move towards that	*//*				if (ocs[0]>ocs[1])	oi/=2;				else				oi/=-2;	*/				if (fabs(loi[0])==oi)	oi/=2;				else					oi*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (oi==-1*ioi || (2*fabs(oi)==fabs(loi[0])))	{			/* if oc+x/2 got closer than oc-x, back up and go to oc+x/4				if (ocs[0]>ocs[2])	oi/=2;			/* otherwise go to oc-x/2												else				oi*=-1;	*/			if (fabs(loi[0])==oi)		{				loi[1]=loi[0];				loi[0]=oi;				oi/=2;					}			else	{				loi[1]=loi[0];				loi[0]=oi;				oi*=-1;				}			}		oc=bocs[1];		}	/* make sure that oi does not take oc below 1.0 */	while (oc+oi<= omin)	{		if (fabs(loi[0])==fabs(loi[1]))	oi/=2;		else							oi=-1*loi[0];		}			ocs[2] = ocs[1];									/* Store last 2 attempts to identify	*/	ocs[1] = ocs[0];									/* when the peak is past 				*/	}free_dvector(parts);			/* partitions of gamma distribution									*/free_dmatrix(steps,4,mxstp+1);				/* number of characters with X steps								*/return bocs;}/* fuzz_fit_mul_twoplgnorm: determine lognormal distributiuon & average rate from "fuzzy" estimate of numbers of events with alpha=betainput:	dist: number of times we see 0, 1, 2, etc.	obsr: observed entities;	din: initial average rate, d, around which lognormal is centered	pts: number of partitions output:	blgn[0]: maximum likelihood of gamma model;	blgn[1]: ml average rate;	blgn[2]: ml alpha;	blgn[3]: ml "richness";*****************************************************************************************************/double *fuzz_fit_mul_twoplgnorm(double *dist, int obsr, int mxstp, double din, int pts){int i,j;					/* LOOP VARIABLE													*/double oc = 0.000f;			/* LOOP SLOPE 														*/double omin = 1.000000001f;	/* min slope														*/double oin = 1.000f;		/* initial slope													*/double oi = 0.000f;			/* how much to increment ev in each loop							*/double loi[2];				/* last two slope increments										*/double ioi;					/* initial slope increment at each richness							*/double moi=0.000001f;		/* minimum evenness increment										*/double ocs[3];				/* previous log likelihoods (cell number = num previous).			*/double *bocs;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double pbocs;				/* previous best support for decay rate								*/double *parts;				/* partitions of gamma distribution									*/double **steps;				/* number of characters with X steps from each part of gamma		*/double x, y, z, rich;double dl = 0.000f;			/* LOOP SLOPE 															*/double dmin = 0.000000001f;	/* min slope															*/double di = 0.000f;			/* how much to increment ev in each loop								*/double ldi[2];				/* last two slope increments											*/double idi;					/* initial slope increment at each richness								*/double mdi=0.000001f;		/* minimum evenness increment											*/double dls[3];				/* previous log likelihoods (cell number = num previous).				*/double *blgn;				/* BEST lognormal parameters		*/double pdel;				/* previous best support for decay rate									*///for (i=1; i<=mxstp; ++i)	mpsteps+=((double) i)*(dist[i]);//din=mpsteps/((double) obsr);bocs=dvector(2);blgn=dvector(4);cleardvector(blgn,3,-1.0*DBL_MAX);di=idi=din/10;if (di==0)	di=0.00001f;pdel = 0.0f;/*	di = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) blgn[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) dls[i] = -1.0*DBL_MAX;ldi[0]=ldi[1]=0.0f;steps=dmatrix(pts,mxstp+1);//expsamp=dvector(4);/* run while:	 delta (dl) is greater than the minimum dl;	 absolute incrementation of delta (di) is greater than some minimum (mdi);	 best support (blgn[0] is sufficiently greater than previous best support (pblas+SUPINC)******************************************************************************************************/oin=2.0f;for (dl = din; ((dl>=dmin && fabs(di)>mdi) && ((pdel == 0.0f) || (blgn[0] > (pdel + SUPINC)))); dl += di) {		/* now, find the number of total entities that predict the "base": i.e., true richness given observed	*/		oi=ioi=(oin/2);	if (oi==0)	oi=0.00001f;	pbocs = 0.0f;	cleardvector(bocs,2,-1.0*DBL_MAX);	for (oc = oin; ((oc>=omin && fabs(oi)>moi) && ((pbocs == 0.0f) || (bocs[0] > (pbocs + SUPINC)))); oc += oi) {					/* calculate gamma distribution	with alpha=beta=oc	*/		parts=lgnormpartitionmids(oc,pts);		x=sumdvector(parts,pts);		x/=((double) pts);								/* x now is the average of the vector	*/		for (i=0; i<pts; ++i)	parts[i]/=x;			/* this centers partitions around 1.0	*/				/* now, find the number of total entities that predict the "base": i.e., true richness given observed	*/		y=0;		for (i=0; i<4; ++i)	{			y+=1-(exp(-1*parts[i]*dl));					/* this is the probability of being found given expected finds parts[i]*dl	*/			}		rich=4*((double) obsr)/y;						/* this gives the true richness that would produce the observed richness	*/				/* get the expected sampled distribution */		cleardmatrix(steps,4,mxstp+1,0);		for (i=0; i<pts; ++i)	{			x=0.0f;			/* NOTE: Start at zero to get initial distribution; the final distribution will use only 1Émxstp;						However, we still need to take into account that low rates will contribute few observed chars	*/			for (j=0; j<mxstp; ++j)	{				y=lnPoisson(dl*parts[i],1,j);		/* get the probability of j changes given expected change parts[i]*base	*/				y=pow(e,y);								/* convert log probability to probability			*/				steps[i][j]+=y;							/* gets the expected number of observations with j	*/				x+=y;									/* gets area under curve to get pdf					*/				}	/* go from 0 -> maxsteps so that we can standardize to 1.0 in the end	*/			for (j=0; j<mxstp; ++j)	steps[i][j]/=(4*x);	/* x is one quarter of the area in the end			*/			}		z=0.0f;	/* the df is incomplete; so, rescale to area to get pdf	*/		for (i=0; i<pts; ++i)	for (j=1; j<=mxstp; ++j)	z+=steps[i][j];	/* z = area under df	*/		/* note: NOW we are going from only 1Émaximum; the 0's fall out								*/		/* calculate likelihood of lognormal distribution	*/		ocs[0]=0;		for (j=1; j<mxstp; ++j)	{			x=0.0f;									/* get sum of conditional probabilities given rates	*/			for (i=0; i<4; ++i)	x+=steps[i][j];		/* this gives the expected proportion with j steps	*/			x/=z;									/* rescale so that pdf = 1.0						*/			ocs[0]+=dist[j]*log(x);					/* this gives log probability of the observation	*/			}		/*Debugging line */		if (oc<=omin) printf("\nDANGER: lognornal sd=%f, S=%f ",oc,ocs[0]);		if (ocs[0] >= bocs[0]) {							/* IF BETTER THAN BEST FIT */			pbocs = bocs[0];								/* save last best ssq for evenness */			bocs[0] = ocs[0];								/* STORE FIT */			bocs[1] = oc;								/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(oi)==fabs(ioi))	{				loi[1]=loi[0];				loi[0]=oi;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				loi[1]=loi[0];				loi[0]=oi;				oi/=-2;				if ((oc+oi)<=omin)	oi*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (oi==-1*loi[0] || oi==ioi)	{				loi[1]=loi[0];				loi[0]=oi;				if (oc==(oin+ioi))	{					oi/=-2;					}				else if (fabs(oi)==fabs(ioi))	{					/* determine whether ocs[0] or ocs[2] is the second best - move towards that	*/	/*				if (ocs[0]>ocs[2])	oi/=2;					else				oi/=-2;	*/					oi/=2;							/* redone 20.03.2009 to get this to search properly	*/					}				else	{					/* determine whether ocs[0] or ocs[1] is the second best - move towards that	*/	/*				if (ocs[0]>ocs[1])	oi/=2;					else				oi/=-2;	*/					if (fabs(loi[0])==oi)	oi/=2;					else					oi*=-1;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (oi==-1*ioi || (2*fabs(oi)==fabs(loi[0])))	{				/* if oc+x/2 got closer than oc-x, back up and go to oc+x/4					if (ocs[0]>ocs[2])	oi/=2;				/* otherwise go to oc-x/2													else				oi*=-1;	*/				if (fabs(loi[0])==fabs(oi))		{					loi[1]=loi[0];					loi[0]=oi;					oi/=2;						}				else	{					loi[1]=loi[0];					loi[0]=oi;					oi*=-1;					}				}			/* added 2011-02-09: prevents infinite loops when multiple contractions required to avoid going too low	*/			else	{				loi[1]=loi[0];				loi[0]=oi;				oi*=-1;				if (loi[0]==-1*loi[1])	oi/=2;				while ((oc+oi)<=omin)	oi/=2;				}			oc=bocs[1];			}		/* make sure that oi does not take oc below 1.0 */		while (oc+oi<=omin)	{//			if (fabs(loi[0])==fabs(loi[1]))	oi/=2;//			else							oi=-1*loi[0];			oi/=2;			}					ocs[2] = ocs[1];									/* Store last 2 attempts to identify	*/		ocs[1] = ocs[0];									/* when the peak is past 				*/		}		/* 	/* get the expected sampled distribution */	/* IF BEST FIT YET!!!	*/	if (bocs[0] >= blgn[0]) {								pdel = blgn[0];								/* save best fit for comparison		*/		blgn[0] = bocs[0];							/* STORE FIT 						*/		blgn[1] = dl;								/* store rate						*/		oin=blgn[2]=bocs[1];						/* store standard deviation			*/		blgn[3]=rich;								/* store implied "richness"			*/		/* while we are getting better on the initial increment, just ride with it		*/		if (fabs(di)==fabs(idi))	{			ldi[1]=ldi[0];			ldi[0]=di;			while ((dl+di)<0)	di/2;				/* don't let this go to negatives	*/			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			ldi[1]=ldi[0];			ldi[0]=di;			di/=-2;			if ((dl+di)<=dmin)	di*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (di==-1*ldi[0] || di==idi)	{			ldi[1]=ldi[0];			ldi[0]=di;			/* if we go up one and it doesn't work out, then go down 1	*/			if (dl==(din+idi))	{				di/=-1;				}			/* if we already have incremented successfully, then try again with increment cut in half	*/			else if (fabs(di)==fabs(idi))	{				/* determine whether dls[0] or dls[2] is the second best - move towards that	*/				di/=2;							/* redone 20.03.2009 to get this to search properly	*/				}			else	{				/* determine whether dls[0] or dls[1] is the second best - move towards that	*/				if (fabs(ldi[0])==fabs(di))	di/=2;				else						di*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (di==-1*idi || (2*fabs(di)==fabs(ldi[0])))	{			/* if we are dealing with the initial absolute value, then cut in half	*/			if (fabs(ldi[0])==fabs(di))		{				ldi[1]=ldi[0];				ldi[0]=di;				di/=2;					}			/* if we just decremented, then reverse course instead	*/			else	{				ldi[1]=ldi[0];				ldi[0]=di;				di*=-1;				}			}		dl=blgn[1];		/* reset to best rate	*/		}	/* make sure that di does not take dl below 1.0 */	while (dl+di<= dmin)	{		if (fabs(ldi[0])==fabs(ldi[1]))	di/=2;		else							di=-1*ldi[0];		}			dls[2]=dls[1];									/* Store last 2 attempts to identify	*/	dls[1]=dls[0];									/* when the peak is past 				*/	dls[0]=bocs[0];	}free_dmatrix(steps,pts,mxstp+1);				/* number of characters with X steps								*/return blgn;}/*support_bars_mul_zipf - routine to put error bars on richness given a Zipf series & a multinomial distribution *****************************************************************************************/double **support_bars_mul_zipf_full (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i=0, j;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/int lbr, ubr;				/* upper and lower bounds on richness									*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double **sbars, **sbarout;	/* support and slopes for richness values within bar units of support	*/double x;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(2/((double) nspec));if (iei==0)	iei=-0.00001f;bep=dvector(2*bestR);sbars=dmatrix(2*bestR,4);bep[bestR]=bep[bestR-1]=bep[bestR+1]=bestS;sbars[bestR][0]=bestR;sbars[bestR][1]=bestM;for (r=bestR; fabs(bestS-bep[r])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	/* Downwards Pass	*/	es[0]=bestS;	/* increment slope until that fails to improve likelihood or resolution limit reached */	sbars[r][0]=r;//	bep[r]= -1.0*DBL_MAX;		/* start with slope of prior r	*/	if (r!=bestR)	{		ein=sbars[r+1][2];		}	/* downwards slope pass	*/	for (ev = ein; (ev>=emin && es[0]>(bestS-bar)); ev -= ei) {			/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r-1]=bep[r]=es[0];			/* tally the maximum log likelihood	*/			}		//		else if (es[1]>=(bestS-bar) && es[0]<(bestS-bar))	{//			sbars[r][2]=lei[0];//			}		//		else	{		while ((ev+ei)<=emin)	{			ei/=2;			}//			}		lei[1]=lei[0];		lei[0]=ei;		}	sbars[r][2]=(ev+lei[1]);	/* Upwards Pass	*/	lei[1]=iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	es[0]=bestS;	for (ev=(ein+ei); es[0]>(bestS-bar); ev+=ei)	{				/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r+1]=bep[r]=es[0];			/* tally the maximum log likelihood	*/			}				lei[1]=lei[0];		lei[0]=ei;			}	sbars[r][3]=(ev-lei[1]);	lbr=r;	}/* Upwards Richness Pass	*/bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r>=ntaxa; ++r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=bestM;	iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	/* Downwards Pass	*/	es[0]=bestS;	/* increment slope until that fails to improve likelihood or resolution limit reached */	sbars[r][0]=r;//	bep[0]= -1.0*DBL_MAX;		/* start with slope of prior r	*/	if (r!=bestR)	{		ein=sbars[r-1][2];		}		/* downwards slope pass	*/	for (ev = ein; (ev>=emin && es[0]>(bestS-bar)); ev -= ei) {			/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r]=es[0];					/* tally the maximum log likelihood	*/			}				while ((ev+ei)<=emin)	{			ei/=2;			}		lei[1]=lei[0];		lei[0]=ei;		}	sbars[r][2]=(ev+lei[1]);	/* Upwards Pass	*/	lei[1]=iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	es[0]=bestS;	for (ev=(ein+ei); es[0]>(bestS-bar); ev+=ei)	{				/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r+1]=bep[r]=es[0];			/* tally the maximum log likelihood	*/			}				lei[1]=lei[0];		lei[0]=ei;			}	sbars[r][3]=(ev-lei[1]);	ubr=r;	}sbarout=dmatrix(1+(ubr-lbr),4);i=0;for (r=lbr; r<=ubr; ++r)	{	for (j=0; j<4; ++j)	sbarout[i][j]=sbars[r][j];	++i;	}return sbarout;}/*support_bars_mul_lgn_full - routine to put error bars on richness given a Zipf series & a multinomial distribution *****************************************************************************************/double **support_bars_mul_lgn_full (double bestS, int ntaxa, int bestR, double bestM, int *empdist, double bar){int i=0, j;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int unqfnd=0;				/* number of different counts (=nspec if all counts unique, =1 if all species have X finds )*/int mtaxa=2000;				/* maximum number of taxa to consider									*/int nspec;					/* number of specimens													*/int lbr, ubr;				/* upper and lower bounds on richness									*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.0000001f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double **sbars, **sbarout;	/* support and slopes for richness values within bar units of support	*/double x;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);nspec=sumivector(empdist,ntaxa);ein=bestM;iei=-1*(2/((double) nspec));if (iei==0)	iei=-0.00001f;bep=dvector(2*bestR);sbars=dmatrix(2*bestR,4);bep[bestR]=bep[bestR-1]=bep[bestR+1]=bestS;sbars[bestR][0]=bestR;sbars[bestR][1]=bestM;for (r=bestR; fabs(bestS-bep[r])<=bar && r>=ntaxa; --r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=bestM;	lei[1]=iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	/* Downwards Pass	*/	es[0]=bestS;	/* increment slope until that fails to improve likelihood or resolution limit reached */	sbars[r][0]=r;//	bep[r]= -1.0*DBL_MAX;		/* start with slope of prior r	*/	if (r!=bestR)	{		ein=sbars[r+1][2];		}	/* downwards slope pass	*/	for (ev = ein; (ev>=emin && es[0]>(bestS-bar)); ev -= ei) {			/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_lgn_distribution(ev,r);			/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r-1]=bep[r]=es[0];			/* tally the maximum log likelihood	*/			}		//		else if (es[1]>=(bestS-bar) && es[0]<(bestS-bar))	{//			sbars[r][2]=lei[0];//			}		//		else	{		while ((ev+ei)<=emin)	{			ei/=2;			}//			}		lei[1]=lei[0];		lei[0]=ei;		}	sbars[r][2]=(ev+lei[1]);	/* Upwards Pass	*/	lei[1]=iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	es[0]=bestS;	for (ev=(ein+ei); es[0]>(bestS-bar); ev+=ei)	{				/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r+1]=bep[r]=es[0];			/* tally the maximum log likelihood	*/			}				lei[1]=lei[0];		lei[0]=ei;			}	sbars[r][3]=(ev-lei[1]);	lbr=r;	}/* Upwards Richness Pass	*/bep[0]=bestS;for (r=bestR+1; fabs(bestS-bep[0])<=bar && r>=ntaxa; ++r)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	/* Downwards Pass	*/	es[0]=bestS;	/* increment slope until that fails to improve likelihood or resolution limit reached */	sbars[r][0]=r;//	bep[0]= -1.0*DBL_MAX;		/* start with slope of prior r	*/	if (r!=bestR)	{		ein=sbars[r-1][2];		}		/* downwards slope pass	*/	for (ev = ein; (ev>=emin && es[0]>(bestS-bar)); ev -= ei) {			/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r]=es[0];					/* tally the maximum log likelihood	*/			}				while ((ev+ei)<=emin)	{			ei/=2;			}		lei[1]=lei[0];		lei[0]=ei;		}	sbars[r][2]=(ev+lei[1]);	/* Upwards Pass	*/	lei[1]=iei=ei=(bestM-emin)/100;								/* set ei to (bestM-emin)/100		*/	es[0]=bestS;	for (ev=(ein+ei); es[0]>(bestS-bar); ev+=ei)	{				/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds */		expect=expfinds(fitdist,r,nspec,nspec);		free_dvector(fitdist);		expect[0]=0;		x=sumdvector(expect,nspec);		for (i=1; i<nspec; ++i)	expect[i]/=x;		es[0]=lnmultinomsuff(obsrvd,expect,nspec);		free_dvector(expect);				if (es[0]>sbars[r][1])	{			sbars[r][1]=ev;					/* tally the best slope	*/			bep[r+1]=bep[r]=es[0];			/* tally the maximum log likelihood	*/			}				lei[1]=lei[0];		lei[0]=ei;			}	sbars[r][3]=(ev-lei[1]);	ubr=r;	}sbarout=dmatrix(1+(ubr-lbr),4);i=0;for (r=lbr; r<=ubr; ++r)	{	for (j=0; j<4; ++j)	sbarout[i][j]=sbars[r][j];	++i;	}return sbarout;}/* fuzz_fit_mul_unif2param: determine best single rate from "fuzzy" estimate of numbers of events with alpha=betainput:	dist: number of times we see 0, 1, 2, etc.	obsr: observed entities;	mxstp: maximum number of times that we might see something;	base: average "rate" around which gamma is centered	pts: number of partitions output:	bdel[0]: maximum likelihood of uniform model;	bals[1]: ml single rate;	bals[2]: ml "richness";*****************************************************************************************************/double *fuzz_fit_mul_unif2param(double *dist, int obsr, int mxstp){int i,j;					/* LOOP VARIABLE														*/int rich, ri, iri;			/* richness parameters													*/int	lri[3];					/* previous richness incrementers										*/double dl = 0.000f;			/* LOOP SLOPE 															*/double dmin = 0.000000001f;	/* min slope															*/double din = 1.000f;		/* initial slope														*/double di = 0.000f;			/* how much to increment ev in each loop								*/double ldi[2];				/* last two slope increments											*/double idi;					/* initial slope increment at each richness								*/double mpsteps=0.0f;		/* most probable number of steps										*/double mdi=0.000001f;		/* minimum evenness increment											*/double dls[3];				/* previous log likelihoods for deltas (cell number = num previous).	*/double rls[3];				/* previous log likelihoods for deltas & richness (cell number = num previous).				*/double *bdel;				/* best delta given some richness										*/double *bdri;				/* best delta and richness												*/double pdel, pdri;			/* previous best support for decay rate									*/double *steps;				/* number of characters with X steps 									*///double *expsamp			/* proportion of characters in each partition that should change	*/double x, y, z;for (i=1; i<=mxstp; ++i)	mpsteps+=((double) i)*(dist[i]);din=mpsteps/((double) obsr);bdel=dvector(2);for (i=0; i<2; i++) bdel[i]= -1.0*DBL_MAX;bdri=dvector(3);			/* best delta & richness		*/for (i=0; i<2; i++) bdel[i]= -1.0*DBL_MAX;di=idi=1.0f;if (di==0)	di=0.00001f;pdri=pdel = 0.0f;/*	di = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bdel[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) bdri[i]=rls[i]=dls[i] = -1.0*DBL_MAX;ldi[0]=ldi[1]=0.0f;steps=dvector(mxstp+1);//expsamp=dvector(4);/* run while:	 delta (dl) is greater than the minimum dl;	 absolute incrementation of delta (di) is greater than some minimum (mdi);	 best support (bdel[0] is sufficiently greater than previous best support (pblas+SUPINC)******************************************************************************************************/iri=lri[1]=lri[0]=ri=mxstp/4;	/* richness incrementer	*/rich=obsr;//for (rich=obsr; ((abs(ri)>0  && rich>=mxstp) && (pdri==0.0f || bdri[0]>(pdri+SUPINC))); rich+=ri)	{	for (dl = din; ((dl>=dmin && fabs(di)>mdi) && ((pdel == 0.0f) || (bdel[0] > (pdel + SUPINC)))); dl += di) {			/* get the expected sampled distribution */		z=0.0f;		cleardvector(steps,mxstp+1,0);		for (j=1; j<mxstp; ++j)	{			y=lnPoisson(dl,1,j);		/* get the probability of j changes given expected change parts[i]*base	*/			y=pow(e,y);								/* convert log probability to probability			*/			steps[j]+=y;							/* gets the expected number of observations with j	*/			z+=y;									/* gets area under curve to get pdf					*/			}	/* go from 0 -> maxsteps so that we can standardize to 1.0 in the end	*///		z=0.0f;	/* the df is incomplete; so, rescale to area to get pdf	*///		for (j=1; j<=mxstp; ++j)	z+=steps[j];	/* z = area under df	*/		/* calculate likelihood of uniform distribution with rate dl	*/		dls[0]=0;		for (j=1; j<mxstp; ++j)	{			x=0.0f;									/* get sum of conditional probabilities given rates	*/			x+=steps[j];							/* this gives the expected proportion with j steps	*/			x/=z;									/* rescale so that pdf = 1.0						*/			dls[0]+=dist[j]*log(x);					/* this gives log probability of the observation	*/			}		/*Debugging line */		if (dl<=dmin) printf("\nDANGER: gamma alpha=%f, S=%f ",dl,dls[0]);		if (dls[0] >= bdel[0]) {						/* IF BETTER THAN BEST FIT */			pdel = bdel[0];								/* save last best ssq for evenness */			bdel[0] = dls[0];							/* STORE FIT */			bdel[1] = dl;								/* STORE RATE */						/* while we are getting better on the initial increment, just ride with it			*/			if (fabs(di)==fabs(idi))	{				ldi[1]=ldi[0];				ldi[0]=di;				while ((dl+di)<0)	di/2;				/* don't let this go to negatives	*/				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				ldi[1]=ldi[0];				ldi[0]=di;				di/=-2;				if ((dl+di)<=dmin)	di*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (di==-1*ldi[0] || di==idi)	{				ldi[1]=ldi[0];				ldi[0]=di;				/* if we go up one and it doesn't work out, then go down 1	*/				if (dl==(din+idi))	{					di/=-1;					}				/* if we already have incremented successfully, then try again with increment cut in half	*/				else if (di==idi)	{					/* determine whether dls[0] or dls[2] is the second best - move towards that	*/	/*				if (dls[0]>dls[2])	di/=2;					else				di/=-2;	*/					di/=2;							/* redone 20.03.2009 to get this to search properly	*/					}				else	{					/* determine whether dls[0] or dls[1] is the second best - move towards that	*/	/*				if (dls[0]>dls[1])	di/=2;					else				di/=-2;	*/					if (fabs(ldi[0])==fabs(di))	di/=2;					else						di*=-1;					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (di==-1*idi || (2*fabs(di)==fabs(ldi[0])))	{				/* if dl+x/2 got closer than dl-x, back up and go to dl+x/4					if (dls[0]>dls[2])	di/=2;				/* otherwise go to dl-x/2													else				di*=-1;	*/				/* if we are dealing with the initial absolute value, then cut in half	*/	//			if (fabs(ldi[0])==fabs(di) || fabs(ldi[0])==fabs(ldi[1]))		{				if (fabs(ldi[0])==fabs(di))		{					ldi[1]=ldi[0];					ldi[0]=di;					di/=2;						}				/* if we just decremented, then reverse course instead	*/				else	{					ldi[1]=ldi[0];					ldi[0]=di;					di*=-1;					}				}			dl=bdel[1];			}		/* make sure that di does not take dl below 1.0 */		while (dl+di<= dmin)	{			if (fabs(ldi[0])==fabs(ldi[1]))	di/=2;			else							di=-1*ldi[0];			}					dls[2] = dls[1];									/* Store last 2 attempts to identify	*/		dls[1] = dls[0];									/* when the peak is past 				*/		}	/* if we've improved likelihood by changing richness, then ride with it	*/	if (bdel[0]>=bdri[0])	{		bdri[0]=bdel[0];			/* tally new maximum log-likelihood		*/		bdri[1]=bdel[1];			/* tally new ml uniform rate			*/		bdri[2]=rich;				/* tally new ml richness				*/				lri[1]=lri[0];		lri[0]=ri;				}	else	{		rich-=ri;							/* reset richness	*/		lri[1]=lri[0];						/* store prior ri	*/		lri[0]=ri;							/* store this ri	*/		if (ri==iri)	{			if (ri>1)	ri/=2;				/* if initial ri runs out of steam, then cut in half	*/			else		ri=0;				/* bail if it is below 1								*/			}		else if (abs(lri[1])==abs(lri[0]))	{			if (abs(lri[0])>1)	ri/=2;		/* cut increment in half				*/			else				ri=0;		/* if already at 1 & -1, then just stop */			}		else	ri*=-1;						/* reverse polarity						*/		if (abs(lri[0])==1 && lri[0]==-1*lri[1])	ri=0;		}		while ((rich+ri)<=rich)	{		if (ri>1)	ri/=2;		else		ri=0;		}	rls[2]=rls[1];	rls[1]=rls[0];//	}free_dvector(steps);				/* number of characters with X steps								*/free_dvector(bdel);					/* best parameters given any one richness							*/return bdri;}/* CALCULATES LIKELIHOOD OF AN AD HOC BEST-FIT DISTRIBUTION ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)RETURNS:	- es: log likelihoodCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double occurrence_fit_mul_best(int *empdist, int ntaxa){int		i;double 	es=0.0f;				/* m for loop																*/double 	*obsrvd;				/* observed number of species with 0Émax finds								*/double 	freq;				/* frequency of taxa with 0Émax finds										*//*double *fitdist;			/* fit distribution															*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);for (i=1; i<=empdist[0]; ++i)	{	freq=obsrvd[i]/((double) ntaxa);	if (obsrvd[i]>0)	es+=obsrvd[i]*log(freq);	}	free_dvector(obsrvd);return es;}/* CALCULATE LIKELIHOOD OF BEST UNIFORM RECOVERY RATE GIVEN FINDS AND POSSIBLE FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- bep[0]: log likelihood	- bep[1]: preservation rate	- bep[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *occurrence_fit_mul_uni(int *empdist, int ntaxa, int ncoll) {int i=0;					/* LOOP VARIABLE														*/int rin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxr=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emax = 1.00f;		/* maximum sampling														*/double emin=0.0000000001f;	/* minimum that we'll evaluate magnitude change to consider				*/double ein = 0.000f;		/* initial slope														*/double iei = 0.000f;		/* initial recovery rate												*/double ei = 0.000f;			/* how much to increment recovery rate in each loop						*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double r;					/* best richness														*/double *bep;				/* BEST richness parameters - return array								*/double pbes=0.0f;				/* previous best support for modal decay								*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double x;					/* sum of expected number of taxa									*///double smin=0.05f;			/* if we increment log-likelihood by only this much 3 times in a row, then quit	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.bep=dvector(3);for (i=0; i<3; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);x = sumivector(empdist,ntaxa);ein = (x/((double) rin))/((double) ncoll);iei=ei=ein/10;for (ev = ein; (((ev>=emin && ev<=emax) && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {			/* generate log-normal distribution with richness r and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */	//		cleardvector(fitdist,r,ev);	/* find the expected proportions of taxa with 0Éx finds */	expect=binomialvector(ncoll,ev);	x=1-expect[0];	r=((double) ntaxa)/x;	for (i=1; i<=ncoll; ++i)	expect[i]/=(1-expect[0]);	expect[0]=0;//	for (i=1; i<ncoll; ++i)	expect[i]*=r;//	es[0]=lnPoisson_vector_part(expect,obsrvd,ncoll,1);//	for (i=1; i<=ncoll; ++i)	expect[i]/=x;	es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	free_dvector(expect);	/*Debugging line */	if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",r,ev,es[0]);	if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */		pbes = bep[0];								/* save last best ssq for evenness */		bep[0] = es[0];								/* STORE FIT */		bep[1] = ev;								/* STORE UNIFORM RECOVERY */		bep[2] = r;									/* STORE INFERRED TAXA	*/			/* while we are getting better on the initial increment, or its negative, just ride with it			*/		if (fabs(ei)==fabs(iei))	{			lei[1]=lei[0];			lei[0]=ei;			if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			/* if we are using the original incrementer */			if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that					if (es[0]>es[2])	ei/=2;				else				ei/=-2;*/				if ((ev-ei)>emin)		ei*=-1;				else					ei/=2;				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*/			/*	if (es[0]>es[1])	ei/=2;	*/				if (fabs(lei[0])==fabs(lei[1]))	{					ei/=-2;					if ((ev+ei)<emin)	ei/=-1;					}				else	{					ei/=-1;					if ((ev+ei)<emin)	ei/=-2;					}				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{			lei[1]=lei[0];			lei[0]=ei;			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*			if (es[0]>es[2])	ei/=2;								*/			if (fabs(lei[0])==fabs(lei[1]))	ei/=2;			/* otherwise go to ev-x/2									*/			else							ei*=-1;			}		ev=bep[1];		}	/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/	if ((ev+ei)<=emin)	{		if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/		else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/		}	es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}free_dvector(obsrvd);return bep;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- ncoll (integer)RETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *occurrence_fit_mul_geo(int *empdist, int ntaxa, int ncoll) {int i = 0;					/* LOOP VARIABLE													*/int r = 0;					/* LOOP RICHNESS													*/int unqfnd=0;				/* number of different counts (=ncoll if all counts unique, =1 if all species have X finds )*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double es[3];				/* previous log likelihoods (cell number = num previous).			*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist;			/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbes;				/* previous best support for decay rate								*/double x;bep=dvector(2);for (i=0; i<2; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */if (empdist[ntaxa-1]>=1)/*	ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));	*/	ein=pow(10,(log10(empdist[0])-log10(empdist[ntaxa-1]))/((double) (ntaxa-1)));else/*	ein=pow(empdist[0],1/((double) ntaxa));	*/	ein=pow(10,(log10(empdist[0])-1)/((double) (ntaxa-1)));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;iei=ein-1;if (ei==0)	ei=0.00001f;pbes = 0.0f;/*	ei = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;lei[0]=lei[1]=0.0f;ei=iei;while (ei+ein<= emin)	ei/=2;for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {			x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	r=x;	if ((x-r)>0.5)	++r;	if (r>=ntaxa)	{		/* generate geometric distribution with richness r and decay of ev */		fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION */		expect=expoccurrences(fitdist,r,ncoll);/*		es[0]=lnPoisson_vector_part(expect,obsrvd,ncoll,1);	*/		expect[0]=0;//		x=sumdvector(expect,ncoll+1);//		for (i=1; i<=ncoll; ++i)	expect[i]/=x;		for (i=1; i<=ncoll; ++i)	expect[i]/=((double) ntaxa);		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	/**/		free_dvector(expect);		}			else	es[0]=-1*DBL_MAX;	/*Debugging line */	if (ev<=emin) printf("\nDANGER: Geo R=%d, ev=%f, S=%f ",r,ev,es[0]);	if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */		pbes = bep[0];								/* save last best ssq for evenness */		bep[0] = es[0];								/* STORE FIT */		bep[1] = ev;								/* STORE SLOPE */				/* while we are getting better on the initial increment, just ride with it			*/		if (ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			if (ev==(ein+iei))	{				ei/=-2;				}			else if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that	*//*				if (es[0]>es[2])	ei/=2;				else				ei/=-2;	*/				ei/=2;							/* redone 20.03.2009 to get this to search properly	*/				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*//*				if (es[0]>es[1])	ei/=2;				else				ei/=-2;	*/				if (fabs(lei[0])==ei)	ei/=2;				else					ei*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || (2*fabs(ei)==fabs(lei[0])))	{			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4				if (es[0]>es[2])	ei/=2;			/* otherwise go to ev-x/2												else				ei*=-1;	*/			if (fabs(lei[0])==ei)		{				lei[1]=lei[0];				lei[0]=ei;				ei/=2;					}			else	{				lei[1]=lei[0];				lei[0]=ei;				ei*=-1;				}			}		ev=bep[1];		}	/* make sure that ei does not take ev below 1.0 */	while (ev+ei<= emin)	{		if (fabs(lei[0])==fabs(lei[1]))	ei/=2;		else							ei=-1*lei[0];		}			es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}free_dvector(obsrvd);return bep;}/* CALCULATE LIKELIHOOD OF THE BEST UNTRUNCATED LOG-NORMAL SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- brp[0]: log likelihood	- brp[1]: magnitude of increase per octave	- brp[2]: median probability of find per locality	- brp[3]: optimal richnessCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *occurrence_fit_mul_lgn(int *empdist, int ntaxa, int ncoll) {int i=0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;					/* initial richness increment each loop									*/int lri[2];					/* previous richness increment											*/int rin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxr=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double rs[3];				/* previous richness log likelihoods (cell number = num previous).		*/double bep[3];				/* BEST decay for hypothesized evenness at given S - return array format */double *brp;				/* BEST richness parameters - return array								*/double pbes;				/* previous best support for modal decay								*/double pbrs;				/* previous best support for richness									*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *normhist;			/* gives S partitions along a normal curve where S will match richness	*/double *fitdist;			/* fit distribution												*/double mdmx;double spar;				/* area under lognormal curve										*///double x;					/* sum of expected number of taxa									*///double smin=0.05f;			/* if we increment log-likelihood by only this much 3 times in a row, then quit	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.brp=dvector(4);for (i=0; i<4; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);iri=ri=ntaxa/4;if (ri<2)	ri=2;lri[0]=lri[1]=0;if (2*rin<10)			mdmx=1.5;else if (2*rin<20)		mdmx=2.0;else if (2*rin<75)		mdmx=2.5;else if (2*rin<350)		mdmx=3.0;else if (2*rin<2000)	mdmx=3.5;else if (2*rin<15000)	mdmx=4.0;else 					mdmx=4.5;if (rin%2==1)				r=empdist[rin/2];else						r=(((double) empdist[rin/2])+((double) empdist[(rin/2)-1]))/2;if (rin/2 < ntaxa)			ein = pow(e,(log(((double) empdist[0])/((double) empdist[rin/2]))/mdmx));else	{	if (empdist[ntaxa-1]>0)	ein = pow(e,(log(((double) empdist[0])/((double) empdist[ntaxa-1]))/mdmx));	else					ein = pow(e,log(((double) empdist[0])/mdmx));	}if (ein==1)	ein=1.20f;iei=ein-1;pbrs=0.0f;for (i=0; i<4; i++) brp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	rs[i]= -1.0*DBL_MAX;/* adjust true richness until that fails to improve likelihood	*/for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	/* generally speaking, if you decrease richness, then you increase the probability of observation	*/	/* 		by increasing evenness, which means looking at lower values of ev.							*/	if (r!=rin && r<brp[3])			if (ei>0)	ei*=-1;	else if (r!=rin && r>brp[3])	if (ei<0)	ei*=-1;	/* added 2012-09-14: reduce the number of times you calculate a normal curve!	*/	normhist=normhistogram(r);	fitdist=dvector(r);	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate log-normal distribution with richness r and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */				/* added 2012-09-14 to reduce computation time	*/		spar=0.0f;		for (i=0; i<r; ++i)	{			fitdist[i]=pow(ev,normhist[i]);			spar+=fitdist[i];			}		for (i=0; i<r; ++i)	fitdist[i]/=spar;				/* find the expected proportions of taxa with 0Éx finds */		expect=expoccurrences(fitdist,r,ncoll);		expect[0]=0;//		x=sumdvector(expect,ncoll+1);				/* the distribution is truncated by 1 and the total number of localities	*///		for (i=1; i<=ncoll; ++i)	expect[i]/=x;		for (i=1; i<=ncoll; ++i)	expect[i]/=((double) ntaxa);		/*free_dvector(fitdist);	*/				es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */			if (r%2==1)				bep[2] = fitdist[r/2];							/* STORE SLOPE */			else				bep[2] = (fitdist[(r/2)-1]+fitdist[r/2])/2;						/* while we are getting better on the initial increment, or its negative, just ride with it			*/			if (fabs(ei)==fabs(iei))	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei*=-1;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/		if ((ev+ei)<=emin)	{			if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/			else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/			}		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}		/* 2012-09-14: added to reduce calcuations of normal curve	*/	free_dvector(normhist);	free_dvector(fitdist);	/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */				/* try to avoid long flat slopes	*///		if ((bep[0]-brp[0])<smin)	++flat;//		else						flat=0;				/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[3] = r;		for (i=0; i<3; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* end cases of improved richness parameter */	/* optimal richness is overshot */	else {		r=brp[3];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}		/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! 	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	ri/=2;		}	*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;		/*	if (abs(ri)%2==1 && abs(ri)>1)	{		if (ri>0)	++ri;		else		--ri;		}	*/	rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD OF BEST ZIPF SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- brp[0]: log likelihood	- brp[1]: magnitude of increase per octave	- brp[2]: median probability of find per locality	- brp[3]: optimal richnessCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *occurrence_fit_mul_zipf(int *empdist, int ntaxa, int ncoll){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;					/* initial richness increment each loop									*/int	lri[2];					/* recent changes in richness											*/int mxr=10000;				/* this is as long as we can make an array								*/int unqfnd=0;				/* number of different counts (=ncoll if all counts unique, =1 if all species have X finds )*/int rin;					/* initial richness 													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 0.000000f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double rs[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[3];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array			*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double x;					/* sum of expected number of taxa									*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<4; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the Zipf-Mandelbrot, based on the log-log slopes between the initial taxa */if (empdist[0]>empdist[1] && empdist[1]>1)	ein=(log(empdist[0])/log(empdist[1]));if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;if (ntaxa>=10)	{	ev=((double) empdist[9])/((double) empdist[0]);	ein=-1*log(ev)/log(10);	}if (ein<emin)/*	ein=pow((log(empdist[0])/log(empdist[6])),0.5);	*/		if (empdist[2]==1 && empdist[0]>empdist[1])		ein=pow((log(empdist[0])/log(empdist[1])),2);if (ein<emin)	ein=0.50f;/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);iri=ri=ntaxa/4;if (ri<2)	iri=ri=2;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/iei=ein/2;if (iei==0)	iei=0.00001f;obsrvd[0]=0;for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{/*	obsrvd[0]=r-ntaxa;	*/	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein< emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds *//*		expect=expfindsprop(fitdist,r,ncoll,ncoll);	*/		expect=expfinds(fitdist,r,ncoll,ncoll);		expect[0]=0;		x=sumdvector(expect,ncoll+1);		for (i=1; i<=ncoll; ++i)	expect[i]/=x;		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */			if (r%2==1)				bep[2] = fitdist[r/2];							/* STORE SLOPE */			else				bep[2] = (fitdist[(r/2)-1]+fitdist[r/2])/2;						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei/=-1;				}			}	/* end case where likelihood is improved	*/							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (fabs(ei)==fabs(iei))	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei/=-2;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}	/* end case where ei is no the original */				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;								if (ev+ei<= emin)	{					if (fabs(lei[0])==fabs(lei[1]))	ei/=-2;					else							ei/=-1;					}				}			ev=bep[1];			}	/* end case where likelihood is not improved	*/		/* make sure that ei does not take ev below 1.0 *//*		if (ev+ei<= emin)	ei/=2;	*/		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* reset evenness incrementer */	if (r!=rin)		iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */	else if (r==rin || ei==0)		iei=bep[1]-ein;		/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		for (i=0; i<3; i++)			brp[i] = bep[i];		brp[3] = r;		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* optimal richness is overshot */		else {		r=brp[3];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}	/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! 	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	ri/=2;		}				*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;	/*	if (abs(ri)%2==1 && abs(ri)>1)	{		if (ri>0)	++ri;		else		--ri;		}	*/	if (ei<0)	iei*=-1;	if (ei<mei)	iei=100*mei;		rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD OF BEST ZIPF SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- result[0]: log likelihood	- result[1]: slope of geometric series	- result[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *occurrence_fit_mul_onepgamma(int *empdist, int ntaxa, int ncoll){int i = 0;					/* LOOP VARIABLE														*/int r = 0;					/* LOOP RICHNESS														*/int ri;						/* richness increment													*/int iri;					/* initial richness increment each loop									*/int	lri[2];					/* recent changes in richness											*/int mxr=10000;				/* this is as long as we can make an array								*/int unqfnd=0;				/* number of different counts (=ncoll if all counts unique, =1 if all species have X finds )*/int rin;					/* initial richness 													*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 0.000000f;	/* min slope															*/double ein = 1.00001f;		/* initial slope														*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous log likelihoods (cell number = num previous).				*/double rs[3];				/* previous log likelihoods (cell number = num previous).				*/double bep[2];				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format		*/double *brp;				/* BEST r PARAMETERS (DISTRIBUTION RICHNESS) - returned array			*/double *fitdist;			/* fit distribution														*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double pbes;				/* previous best support for decay rate									*/double x;					/* sum of expected number of taxa									*/brp=dvector(3);for (i=0; i<3; i++) rs[i] = 0.0f;for (i=0; i<3; i++) brp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* find a good seed value for the Zipf-Mandelbrot, based on the log-log slopes between the initial taxa */if (empdist[0]>empdist[1] && empdist[1]>1)	ein=(log(empdist[0])/log(empdist[1]));if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;if (ntaxa>=10)	{	ev=((double) empdist[9])/((double) empdist[0]);	ein=-1*log(ev)/log(10);	}if (ein<emin)/*	ein=pow((log(empdist[0])/log(empdist[6])),0.5);	*/		if (empdist[2]==1 && empdist[0]>empdist[1])		ein=pow((log(empdist[0])/log(empdist[1])),2);if (ein<emin)	ein=0.50f;/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);iri=ri=ntaxa/4;if (ri<2)	iri=ri=2;/* increment true richness until that fails to improve likelihood *//*for (r = ntaxa; ((pbrs == 0.0f) || (brp[0] > (pbrs + SUPINC))); r += ri) {	*/iei=ein/2;if (iei==0)	iei=0.00001f;obsrvd[0]=0;for (r=rin; abs(ri)>0 && r>=ntaxa; r+=ri)	{/*	obsrvd[0]=r-ntaxa;	*/	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	while (ei+ein< emin)	ei/=2;	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {					/* generate zipf distribution with richness r and log-decay of ev */		fitdist = proportional_zipf_distribution(ev,r);				/* MAKE DISTRIBUTION */		/* find the expected proportions of taxa with 0Éx finds *//*		expect=expfindsprop(fitdist,r,ncoll,ncoll);	*/		expect=expfinds(fitdist,r,ncoll,ncoll);		expect[0]=0;		x=sumdvector(expect,ncoll+1);		for (i=1; i<=ncoll; ++i)	expect[i]/=x;		free_dvector(fitdist);		es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);		free_dvector(expect);		/*Debugging line */		if (ev<=emin) printf("\nDANGER: GS R=%d, ev=%f, S=%f ",r,ev,es[0]);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */			pbes = bep[0];								/* save last best ssq for evenness */			rs[0]=bep[0] = es[0];						/* STORE FIT */			bep[1] = ev;								/* STORE SLOPE */						/* while we are getting better on the initial increment, just ride with it			*/			if (ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei/=-1;				}			}	/* end case where likelihood is improved	*/							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (fabs(ei)==fabs(iei))	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei/=-2;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}	/* end case where ei is no the original */				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;								if (ev+ei<= emin)	{					if (fabs(lei[0])==fabs(lei[1]))	ei/=-2;					else							ei/=-1;					}				}			ev=bep[1];			}	/* end case where likelihood is not improved	*/		/* make sure that ei does not take ev below 1.0 *//*		if (ev+ei<= emin)	ei/=2;	*/		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* reset evenness incrementer */	if (r!=rin)		iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */	else if (r==rin || ei==0)		iei=bep[1]-ein;		/* if this richness is better than the last */	if (bep[0] >= brp[0]) {								/* IF BETTER THAN BEST FIT */		/* reset evenness incrementer */		if (r!=rin)	{			iei=bep[1]-brp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (r==rin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		brp[2] = r;		for (i=0; i<2; i++)			brp[i] = bep[i];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lri[1]=lri[0];		lri[0]=ri;		/* if we are past the initial ri, then we want to use it only once	*/		/* otherwise, we repeat r's											*/		if (abs(ri)!=abs(iri))	{			/* do not get stuck on 1!	*/			if (iri!=1 && (abs(lri[0])==1 && abs(ri)==1))	ri=0;			/* if proceeding ri/2 does not take you below ntaxa, then cut ri in half	*/			else if ((r+((ri/abs(ri))*(abs(ri)+1)/2))>=ntaxa)															ri=(ri/abs(ri))*(abs(ri)+1)/2;			/* if proceeding ri/2 does takes you below ntaxa, then reverse ri	*/			else											ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if on the absolute original ri, then go with it unless we are in danger of dropping below the minimum	*/		else if ((r+ri)<ntaxa)								ri/=-1*(ri/abs(ri))*(abs(ri)+1)/2;		}	/* optimal richness is overshot */		else {		r=brp[2];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (ri==iri && r==rin)	{			lri[1]=lri[0];			lri[0]=ri;			if (abs(lri[1])==1 && abs(lri[0])==1)	ri=0;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(ri)==abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			/* go towards the one with the higher likelihood */			if (abs(lri[0])==1 && abs(lri[1])==1)	ri=0;/*			else if (rs[1]>rs[0])						ri=(ri/abs(ri))*(abs(ri)+1)/-2;	*/			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(ri)<abs(lri[0]))	{			lri[1]=lri[0];			lri[0]=ri;			if ((r-ri)>=ntaxa)						ri*=-1;			else									ri=(ri/abs(ri))*(abs(ri)+1)/2;				}		}	/* do not let r exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for r < observed! 	while ((r+ri)>mxr || (r+ri)< ntaxa)	{		if (r==mxr)	ri*=-1;		else	ri/=2;		}				*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((rs[0]>=rs[1] && rs[0]<(rs[1]+SUPINC)) && (rs[1]>=rs[2] && rs[1]<(rs[2]+SUPINC)))	ri=0;	/*	if (abs(ri)%2==1 && abs(ri)>1)	{		if (ri>0)	++ri;		else		--ri;		}	*/	if (ei<0)	iei*=-1;	if (ei<mei)	iei=100*mei;		rs[2] = rs[1];	rs[1] = bep[0];	}free_dvector(obsrvd);return brp;}/* CALCULATE LIKELIHOOD OF BEST UNIFORM RECOVERY RATE GIVEN FINDS AND POSSIBLE FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- bep[0]: log likelihood	- bep[1]: preservation rate	- bep[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *rate_fit_mul_uni(int *empdist, int ntaxa, int ncoll) {int i=0;					/* LOOP VARIABLE														*/int rin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxr=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emax = 1.00f;		/* maximum sampling														*/double emin=0.0000000001f;	/* minimum that we'll evaluate magnitude change to consider				*/double ein = 0.000f;		/* initial slope														*/double iei = 0.000f;		/* initial recovery rate												*/double ei = 0.000f;			/* how much to increment recovery rate in each loop						*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double r;					/* best richness														*/double *bep;				/* BEST richness parameters - return array								*/double pbes=0.0f;				/* previous best support for modal decay								*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double x;					/* sum of expected number of taxa									*///double smin=0.05f;			/* if we increment log-likelihood by only this much 3 times in a row, then quit	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.bep=dvector(3);for (i=0; i<3; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogram(empdist,ntaxa);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);x = sumivector(empdist,ntaxa);ein = (x/((double) rin))/((double) ncoll);iei=ei=ein/10;for (ev = ein; (((ev>=emin && ev<=emax) && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {			/* generate log-normal distribution with richness r and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */	//		cleardvector(fitdist,r,ev);	/* find the expected proportions of taxa with 0Éx finds */	expect=binomialvector(ncoll,ev);	x=1-expect[0];	r=((double) ntaxa)/x;	expect[0]=0;//	for (i=1; i<=ncoll; ++i)	expect[i]/=((double) ntaxa);//	for (i=1; i<ncoll; ++i)	expect[i]*=r;//	es[0]=lnPoisson_vector_part(expect,obsrvd,ncoll,1);	for (i=1; i<=ncoll; ++i)	expect[i]/=x;			/* rescale to 1.0	*/	es[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	free_dvector(expect);	/*Debugging line */	if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",r,ev,es[0]);	if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */		pbes = bep[0];								/* save last best ssq for evenness */		bep[0] = es[0];								/* STORE FIT */		bep[1] = ev;								/* STORE UNIFORM RECOVERY */		bep[2] = r;									/* STORE INFERRED TAXA	*/			/* while we are getting better on the initial increment, or its negative, just ride with it			*/		if (fabs(ei)==fabs(iei))	{			lei[1]=lei[0];			lei[0]=ei;			if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			/* if we are using the original incrementer */			if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that					if (es[0]>es[2])	ei/=2;				else				ei/=-2;*/				if ((ev-ei)>emin)		ei*=-1;				else					ei/=2;				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*/			/*	if (es[0]>es[1])	ei/=2;	*/				if (fabs(lei[0])==fabs(lei[1]))	{					ei/=-2;					if ((ev+ei)<emin)	ei/=-1;					}				else	{					ei/=-1;					if ((ev+ei)<emin)	ei/=-2;					}				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{			lei[1]=lei[0];			lei[0]=ei;			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*			if (es[0]>es[2])	ei/=2;								*/			if (fabs(lei[0])==fabs(lei[1]))	ei/=2;			/* otherwise go to ev-x/2									*/			else							ei*=-1;			}		ev=bep[1];		}	/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/	if ((ev+ei)<=emin)	{		if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/		else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/		}	es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}free_dvector(obsrvd);return bep;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- ncoll (integer)RETURNS:	- bep[0]: log likelihood	- bep[1]: slope of geometric series	- bep[2]: rate modifier			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *rate_fit_mul_geo(int *empdist, int ntaxa, int ncoll){int i = 0;					/* LOOP VARIABLE													*/int s = 0;					/* LOOP RICHNESS													*/int unqfnd=0;				/* number of different counts (=ncoll if all counts unique, =1 if all species have X finds )*/double r = 0.000f;			/* "base" rate 												*/double rin = 0.001f;		/* initial "base" rate 												*/double rmin = 0.001f;		/* minimum "base" rate 												*/double rmax = 1.000f;		/* maximum "base" rate 												*/double rlast;				/* prior "base" rate 												*/double ri;					/* "base" rate alteration											*/double mri;					/* minimum "base" rate alteration									*/double lri;					/* prior alteration of base rate									*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double evlast = 0.000f;		/* prior ev															*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double rs[3];double brp[2];double es[3];				/* previous log likelihoods (cell number = num previous).			*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist, *fitdist2;	/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbrs;				/* previous best support for base rate								*/double pbes;				/* previous best support for decay rate								*/int smin;					/* do not let this get hung up on bad richnesses with good proportions	*/int	mxt;double x, y;//FILE	*fopen();//FILE 	*debugfile;//debugfile=fopen("fixinggeometric_mul.txt","w");/* use Chao 2 estimator to get seed richness */i=chao2(empdist,ntaxa);smin=i-(i/10);bep=dvector(3);for (i=0; i<2; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll+1);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */if (empdist[ntaxa-1]>=1)/*	ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));	*/	ein=pow(10,(log10(empdist[0])-log10(empdist[ntaxa-1]))/((double) (ntaxa-1)));else/*	ein=pow(empdist[0],1/((double) ntaxa));	*/	ein=pow(10,(log10(empdist[0])-1)/((double) (ntaxa-1)));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;iei=ein-1;if (ei==0)	ei=0.00001f;pbes = 0.0f;/*	ei = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;lei[0]=lei[1]=0.0f;ei=iei;while (ei+ein<= emin)	ei/=2;for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {		x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	s=x;	if ((x-s)>0.5)	++s;	//	fprintf(debugfile,"%10.9f\n",ev);	if (s>=smin)	{	//		fprintf(debugfile,"s ok for %10.9f\n",ev);		/* generate geometric distribution with richness s and decay of ev */		fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION *//*		rin=empdist[0]/((double) ncoll) / fitdist[0];	*/		/* set rescaling so that the median expected occurrences matches median observed	*/		if (ntaxa%2==1)			rin=empdist[ntaxa/2]/((double) ncoll)/fitdist[ntaxa/2];		else			rin=0.5*((empdist[ntaxa/2]/((double) ncoll)/fitdist[ntaxa/2])+(empdist[ntaxa/2]/((double) ncoll)/fitdist[(ntaxa/2)-1]));		rmax=1/fitdist[0];		if (rmax<rin)	rin=rmax/2;		rlast=1.0f;		ri=rin/10;		mri=rin/100;		pbrs=0.0f;		brp[0]=-1.0*DBL_MAX;		mxt=0;		fitdist2=dvector(s);//		fprintf(debugfile,"start at r=%10.9f\n",rin);		/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*/		for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{//			fprintf(debugfile,"ev=%10.9f, r=%10.9f",ev,r);						//rescaledvector(fitdist,s,(r/rlast));			proportionaldvector(fitdist,fitdist2,r,s);			expect=expoccurrences(fitdist2,s,ncoll);			expect[0]=0;			x=sumdvector(expect,ncoll+1);			for (i=1; i<=ncoll; ++i)	expect[i]/=x;			rs[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	/**///			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);			free_dvector(expect);						if (rs[0]>=brp[0])	{				pbrs=brp[0];				es[0]=brp[0]=rs[0];				brp[1]=r;				/* if we've reduced absolute ri, then we do not want to repeat an r	*/				if (ri!=fabs(rin/10))	ri/=2;				lri=ri;				}			else	{				r-=ri;						/* go back to prior r	*/				x=ri;						/* save this for lri	*/				y=fabs(lri);				/* for debugging		*/				if (ri==rin/10)	{					if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/					else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/					}				else if (fabs(ri)==fabs(lri))		/* we just flipped, so decrease the change			*/					ri/=2;				else						/* we probably went the wrong way: reverse direction	*/					ri*=-1;				lri=x;				}			rlast=r;				/* keep this here in case we start off well and don't want a full initial step up or down	*/			/* we might need to limit this routine!	*/			++mxt;			if (mxt==10)	r=rmax;			}		free_dvector(fitdist);		free_dvector(fitdist2);		}			else	es[0]=-1*DBL_MAX;//	fprintf(debugfile,"finished with ev=%10.9f\n",ev);	/*Debugging line *///	if (ev<=emin) printf("\nDANGER: Geo R=%d, ev=%f, S=%f ",s,ev,es[0]);	if (brp[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*///		fprintf(debugfile,"ev=%10.9f is better with lnL=%10.9f at r=%10.9f\n",ev,brp[0],brp[1]);		pbes = bep[0];								/* save last best ssq for evenness 	*/		bep[0] = brp[0];							/* STORE FIT 						*/		bep[1] = ev;								/* STORE SLOPE 						*/		bep[2] = brp[1];							/* store base rate modifier			*/				/* while we are getting better on the initial increment, just ride with it			*/		if (ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;						/* added 2012-10-16: it keeps weaseling out of reversing failed first alteration	*/			if (evlast==ein && ei==iei)				ei*=-1;			else if (ev==(ein+iei))	{				ei/=-2;				}			else if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that	*//*				if (es[0]>es[2])	ei/=2;				else				ei/=-2;	*/				ei/=2;						/* redone 2009.03.20 to get this to search properly	*/				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*//*				if (es[0]>es[1])	ei/=2;				else				ei/=-2;	*/				if (fabs(lei[0])==fabs(ei))	ei/=2;				else						ei*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || (2*fabs(ei)==fabs(lei[0])))	{			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4				if (es[0]>es[2])	ei/=2;			/* otherwise go to ev-x/2												else				ei*=-1;	*/			if (fabs(lei[0])==ei)		{				lei[1]=lei[0];				lei[0]=ei;				ei/=2;					}			else	{				lei[1]=lei[0];				lei[0]=ei;				ei*=-1;				}			}		ev=bep[1];		}			evlast=ev;	/* make sure that ei does not take ev below 1.0 */	while (ev+ei<= emin)	{		if (fabs(lei[0])==fabs(lei[1]))	ei/=2;		else							ei=-1*lei[0];		}			es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}//fclose(debugfile);free_dvector(obsrvd);return bep;}/* CALCULATE LIKELIHOOD OF THE BEST UNTRUNCATED LOG-NORMAL SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- bsp[0]: log likelihood	- bsp[1]: magnitude of increase per octave	- bsp[2]: distribution modifier	- bsp[3]: optimal richness	- bsp[4]: 1st quartile recovery rate	- bsp[5]: 2nd quartile recovery rate	- bsp[6]: 3rd quartile recovery rate	- bsp[7]: 4th quartile recovery rateCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *rate_fit_mul_lgn(int *empdist, int ntaxa, int ncoll){int i, j, k;				/* LOOP VARIABLE														*/int s = 0;					/* LOOP RICHNESS														*/int si;						/* richness increment													*/int isi;					/* initial richness increment each loop									*/int lsi[2];					/* previous richness increment											*/int sin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxs=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double r = 0.000f;			/* "base" rate 															*/double rin = 0.001f;		/* initial "base" rate 													*/double rmin = 0.001f;		/* minimum "base" rate 													*/double rmax = 1.000f;		/* maximum "base" rate 													*/double rlast;				/* prior "base" rate 													*/double ri;					/* "base" rate alteration												*/double mri;					/* minimum "base" rate alteration										*/double lri;					/* prior alteration of base rate										*/double rs[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double ss[3];				/* previous richness log likelihoods (cell number = num previous).		*/double brp[6];				/* BEST decay for hypothesized evenness at given S - return array format */double bep[7];				/* BEST decay for hypothesized evenness at given S - return array format */double *bsp;				/* BEST richness parameters - return array								*/double pbrs;				/* previous best support for base rate									*/double pbes;				/* previous best support for modal decay								*/double pbss;				/* previous best support for richness									*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *normhist;			/* gives S partitions along a normal curve where S will match richness	*/double *fitdist, *fitdist2;	/* fit distribution												*/double mdmx;double spar;				/* area under lognormal curve										*/double x, y;				/* sum of expected number of taxa									*/int	mxt;int smin;					/* do not let this get hung up on bad richnesses with good proportions	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.//FILE	*fopen();//FILE 	*debugfile;//debugfile=fopen("fixinglognormal_mul.txt","w");bsp=dvector(8);for (i=0; i<8; i++) bsp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll+1);/* use Chao 2 estimator to get seed richness */sin=chao2(empdist,ntaxa);smin=sin-(sin/10);isi=si=ntaxa/4;if (si<2)	si=2;lsi[0]=lsi[1]=0;if (2*sin<10)			mdmx=1.5;else if (2*sin<20)		mdmx=2.0;else if (2*sin<75)		mdmx=2.5;else if (2*sin<350)		mdmx=3.0;else if (2*sin<2000)	mdmx=3.5;else if (2*sin<15000)	mdmx=4.0;else 					mdmx=4.5;if (sin%2==1)				s=empdist[sin/2];				/* median taxon	*/else						s=(((double) empdist[sin/2])+((double) empdist[(sin/2)-1]))/2;//if (sin/2 < ntaxa)			ein = pow(e,(log(((double) empdist[0])/((double) empdist[sin/2]))/mdmx));if (sin/2 < ntaxa)	{	x=0;	for (i=0; i<(sin/2); ++i)	x+=(log(empdist[i])-log(s));	x*=2;	x/=((double) (sin-1));	y=pow(x,0.5);	ein=pow(e,y);	}else	{	if (empdist[ntaxa-1]>0)	ein = pow(e,(log(((double) empdist[0])/((double) empdist[ntaxa-1]))/mdmx));	else					ein = pow(e,log(((double) empdist[0])/mdmx));	}if (ein==1)	ein=1.20f;	/**/iei=ein-1;pbss=0.0f;for (i=0; i<4; i++) bsp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ss[i]= -1.0*DBL_MAX;/* adjust true richness until that fails to improve likelihood	*/for (s=sin; abs(si)>0 && s>=smin; s+=si)	{//	fprintf(debugfile,"starting s = %d\n",s);	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	/* generally speaking, if you decrease richness, then you increase the probability of observation	*/	/* 		by increasing evenness, which means looking at lower values of ev.							*/	if (s!=sin && s<bsp[3])			if (ei>0)	ei*=-1;	else if (s!=sin && s>bsp[3])	if (ei<0)	ei*=-1;	/* added 2012-09-14: reduce the number of times you calculate a normal curve!	*/	normhist=normhistogram(s);	fitdist=dvector(s);	fitdist2=dvector(s);	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {				/* generate log-normal distribution with richness s and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,s);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */				/* added 2012-09-14 to reduce computation time	*///		fprintf(debugfile,"%10.9f\n",ev);		spar=0.0f;		for (i=0; i<s; ++i)	{			fitdist[i]=pow(ev,normhist[i]);			spar+=fitdist[i];			}		for (i=0; i<s; ++i)	fitdist[i]/=spar;				mxt=0;				/* NOW, vary base r	*///		rin=empdist[0]/((double) ncoll) / fitdist[0];		rin=empdist[ntaxa-(((int) obsrvd[1])/2)]/((double) ncoll) / fitdist[ntaxa-(((int) obsrvd[1])/2)];		rmax=1/fitdist[0];		if (rmax<rin)	rin=rmax/2;		rlast=1.0f;		ri=rin/10;		mri=rin/100;		pbrs=0.0f;		brp[0]=-1.0*DBL_MAX;				/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*///		fprintf(debugfile,"start at r=%10.9f\n",rin);		for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{//			fprintf(debugfile,"s=%d, ev=%10.9f, r=%10.9f",s,ev,r);//			rescaledvector(fitdist,s,(r/rlast));			proportionaldvector(fitdist,fitdist2,r,s);			expect=expoccurrences(fitdist2,s,ncoll);			expect[0]=0;			x=sumdvector(expect,ncoll+1);			for (i=1; i<=ncoll; ++i)	expect[i]/=x;			rs[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	/**/			free_dvector(expect);//			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);						if (rs[0]>=brp[0])	{				pbrs=brp[0];				es[0]=brp[0]=rs[0];				brp[1]=r;		/* store modifier!	*/				x=0.875;				for (j=2; j<6; ++j)	{					k=x*s;					brp[j]=fitdist2[k];					x-=0.25;					}								/* if we've reduced absolute ri, then we do not want to repeat an r	*/				if (ri!=fabs(rin/10))	ri/=2;				lri=ri;				}			else	{				r-=ri;						/* go back to prior r	*/				x=ri;				if (ri==rin/10)	{					if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/					else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/					}				else if (ri==fabs(lri))		/* we just flipped, so decrease the change			*/					ri/=2;				else						/* we probably went the wrong way: reverse direction	*/					ri*=-1;				lri=x;				}			rlast=r;						/* we might need to limit this routine!	*/			++mxt;			if (mxt==10)	r=rmax;			}	/* finish varying base r	*/		/************* BEST BASE r found!!!!!  **************/		/*Debugging line */		if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",s,ev,es[0]);//		fprintf(debugfile,"finished with ev=%10.9f\n",ev);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*/			pbes = bep[0];								/* save last best ssq for evenness 	*/			ss[0]=bep[0] = es[0];						/* STORE FIT 						*/			bep[1] = ev;								/* STORE magnitude 					*/			for (j=2; j<7; ++j)				bep[j]=brp[j-1];						/* store rate modifier and quartiles	*//*			bep[2] = brp[1];							/* STORE rate modifier				*/ 			/* added 2012-10-16: store quartiles	*/						/* while we are getting better on the initial increment, or its negative, just ride with it			*/			if (fabs(ei)==fabs(iei))	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei*=-1;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/		if ((ev+ei)<=emin)	{			if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/			else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/			}		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* end search for best magnitude parameter	*/		/* 2012-09-14: added to reduce calcuations of normal curve	*/	free_dvector(normhist);	free_dvector(fitdist);	free_dvector(fitdist2);//	fprintf(debugfile,"finished with s=%d\n",s);	/* if this richness is better than the last */	if (bep[0] >= bsp[0]) {								/* IF BETTER THAN BEST FIT */				/* try to avoid long flat slopes	*///		if ((bep[0]-bsp[0])<smin)	++flat;//		else						flat=0;				/* reset evenness incrementer */		if (s!=sin)	{			iei=bep[1]-bsp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (s==sin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		for (i=0; i<3; i++)			bsp[i] = bep[i];		bsp[3] = s;		for (i=4; i<8; i++)			bsp[i] = bep[i-1];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lsi[1]=lsi[0];		lsi[0]=si;		/* if we are past the initial si, then we want to use it only once	*/		/* otherwise, we repeat s's											*/		if (abs(si)!=abs(isi))	{			/* do not get stuck on 1!	*/			if (isi!=1 && (abs(lsi[0])==1 && abs(si)==1))	si=0;			/* if proceeding si/2 does not take you below smin, then cut si in half	*/			else if ((s+((si/abs(si))*(abs(si)+1)/2))>=smin)															si=(si/abs(si))*(abs(si)+1)/2;			/* if proceeding si/2 does takes you below smin, then reverse si	*/			else											si/=-1*(si/abs(si))*(abs(si)+1)/2;			}		/* if on the absolute original si, then go with it unless we are in danger of dropping below the minimum	*/		else if ((s+si)<smin)								si/=-1*(si/abs(si))*(abs(si)+1)/2;		}	/* end cases of improved richness parameter */	/* optimal richness is overshot */	else {		s=bsp[3];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (si==isi && s==sin)	{			lsi[1]=lsi[0];			lsi[0]=si;			if (abs(lsi[1])==1 && abs(lsi[0])==1)	si=0;			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(si)==abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			/* go towards the one with the higher likelihood */			if (abs(lsi[0])==1 && abs(lsi[1])==1)	si=0;/*			else if (ss[1]>ss[0])						si=(si/abs(si))*(abs(si)+1)/-2;	*/			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(si)<abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			if ((s-si)>=smin)						si*=-1;			else									si=(si/abs(si))*(abs(si)+1)/2;				}		}		/* do not let s exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for s < observed! 	while ((s+si)>mxs || (s+si)< smin)	{		if (s==mxs)	si*=-1;		else	si/=2;		}	*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((ss[0]>=ss[1] && ss[0]<(ss[1]+SUPINC)) && (ss[1]>=ss[2] && ss[1]<(ss[2]+SUPINC)))	si=0;		/*	if (abs(si)%2==1 && abs(si)>1)	{		if (si>0)	++si;		else		--si;		}	*/	ss[2] = ss[1];	ss[1] = bep[0];	}	/* end search for best richness parameter	*/free_dvector(obsrvd);return bsp;}/* CALCULATE LIKELIHOOD OF THE BEST ZIPF (log-log) SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- bsp[0]: log likelihood	- bsp[1]: magnitude of increase per octave	- bsp[2]: distribution modifier	- bsp[3]: optimal richness	- bsp[4]: 1st quartile recovery rate	- bsp[5]: 2nd quartile recovery rate	- bsp[6]: 3rd quartile recovery rate	- bsp[7]: 4th quartile recovery rateCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *rate_fit_mul_Zipf(int *empdist, int ntaxa, int ncoll){int i, j, k;				/* LOOP VARIABLE														*/int s = 0;					/* LOOP RICHNESS														*/int si;						/* richness increment													*/int isi;					/* initial richness increment each loop									*/int lsi[2];					/* previous richness increment											*/int sin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxs=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 0.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double r = 0.000f;			/* "base" rate 															*/double rin = 0.001f;		/* initial "base" rate 													*/double rmin = 0.001f;		/* minimum "base" rate 													*/double rmax = 1.000f;		/* maximum "base" rate 													*/double rlast;				/* prior "base" rate 													*/double ri;					/* "base" rate alteration												*/double mri;					/* minimum "base" rate alteration										*/double lri;					/* prior alteration of base rate										*/double rs[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double ss[3];				/* previous richness log likelihoods (cell number = num previous).		*/double brp[6];				/* BEST decay for hypothesized evenness at given S - return array format */double bep[7];				/* BEST decay for hypothesized evenness at given S - return array format */double *bsp;				/* BEST richness parameters - return array								*/double pbrs;				/* previous best support for base rate									*/double pbes;				/* previous best support for modal decay								*/double pbss;				/* previous best support for richness									*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *fitdist, *fitdist2;	/* fit distribution														*/double x,y;					/* sum of expected number of taxa										*/int	mxt;int minoc;					/* minimum number of occurrences										*/int smin;					/* do not let this get hung up on bad richnesses with good proportions	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.//FILE	*fopen();//FILE 	*debugfile;//debugfile=fopen("fixinglognormal_mul.txt","w");bsp=dvector(8);for (i=0; i<8; i++) bsp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll+1);/* use Chao 2 estimator to get seed richness */sin=chao2(empdist,ntaxa);smin=sin-(sin/10);isi=si=ntaxa/4;if (si<2)	si=2;lsi[0]=lsi[1]=0;minoc=miniarray(empdist,ntaxa);			/* occurrences for rarest taxa; usually = 1	*/y=log(((double) empdist[0])/((double) minoc));k=ntaxa-(((int) obsrvd[minoc])/2);x=log(k-1); /* log of distance from #1 to midpoint of taxa with minimum	*/ein=y/x;iei=ein/10;pbss=0.0f;for (i=0; i<4; i++) bsp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ss[i]= -1.0*DBL_MAX;/* adjust true richness until that fails to improve likelihood	*/for (s=sin; abs(si)>0 && s>=smin; s+=si)	{//	fprintf(debugfile,"starting s = %d\n",s);	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	/* generally speaking, if you decrease richness, then you increase the probability of observation	*/	/* 		by increasing evenness, which means looking at lower values of ev.							*/	if (s!=sin && s<bsp[3])			if (ei>0)	ei*=-1;	else if (s!=sin && s>bsp[3])	if (ei<0)	ei*=-1;	/* added 2012-09-14: reduce the number of times you calculate a normal curve!	*/	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {				/* generate log-normal distribution with richness s and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,s);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */				/* added 2012-09-14 to reduce computation time	*///		fprintf(debugfile,"%10.9f\n",ev);		fitdist=proportional_zipf_distribution(ev,s);						fitdist2=dvector(s);		/* NOW, vary base r	*/		rin=empdist[ntaxa-(((int) obsrvd[1])/2)]/((double) ncoll) / fitdist[ntaxa-(((int) obsrvd[1])/2)];		rmax=1/fitdist[0];		if (rmax<rin)	rin=rmax/2;		rlast=1.0f;		ri=rin/10;		mri=rin/100;		pbrs=0.0f;		brp[0]=-1.0*DBL_MAX;		mxt=0;		/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*///		fprintf(debugfile,"start at r=%10.9f\n",rin);		for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{//			fprintf(debugfile,"s=%d, ev=%10.9f, r=%10.9f",s,ev,r);//			rescaledvector(fitdist,s,(r/rlast));			proportionaldvector(fitdist,fitdist2,r,s);			expect=expoccurrences(fitdist2,s,ncoll);			expect[0]=0;			x=sumdvector(expect,ncoll+1);			for (i=1; i<=ncoll; ++i)	expect[i]/=x;			rs[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	/**/			free_dvector(expect);//			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);						if (rs[0]>=brp[0])	{				pbrs=brp[0];				es[0]=brp[0]=rs[0];				brp[1]=r;		/* store modifier!	*/				x=0.875;				for (j=2; j<6; ++j)	{					k=x*s;					brp[j]=fitdist2[k];					x-=0.25;					}								/* if we've reduced absolute ri, then we do not want to repeat an r	*/				if (ri!=fabs(rin/10))	ri/=2;				lri=ri;				}			else	{				r-=ri;						/* go back to prior r	*/				x=ri;				if (ri==rin/10)	{					if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/					else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/					}				else if (ri==fabs(lri))		/* we just flipped, so decrease the change			*/					ri/=2;				else						/* we probably went the wrong way: reverse direction	*/					ri*=-1;				lri=x;				}			rlast=r;						/* we might need to limit this routine!	*/			++mxt;			if (mxt==10)	r=rmax;			}	/* finish varying base r	*/		/************* BEST BASE r found!!!!!  **************/		/*Debugging line */		if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",s,ev,es[0]);//		fprintf(debugfile,"finished with ev=%10.9f\n",ev);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*/			pbes = bep[0];								/* save last best ssq for evenness 	*/			ss[0]=bep[0] = es[0];						/* STORE FIT 						*/			bep[1] = ev;								/* STORE magnitude 					*/			for (j=2; j<7; ++j)				bep[j]=brp[j-1];						/* store rate modifier and quartiles	*//*			bep[2] = brp[1];							/* STORE rate modifier				*/ 			/* added 2012-10-16: store quartiles	*/						/* while we are getting better on the initial increment, or its negative, just ride with it			*/			if (fabs(ei)==fabs(iei))	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei*=-1;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/		if ((ev+ei)<=emin)	{			if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/			else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/			}		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		free_dvector(fitdist);		free_dvector(fitdist2);		}	/* end search for best magnitude parameter	*/		/* 2012-09-14: added to reduce calcuations of normal curve	*///	fprintf(debugfile,"finished with s=%d\n",s);	/* if this richness is better than the last */	if (bep[0] >= bsp[0]) {								/* IF BETTER THAN BEST FIT */				/* try to avoid long flat slopes	*///		if ((bep[0]-bsp[0])<smin)	++flat;//		else						flat=0;				/* reset evenness incrementer */		if (s!=sin)	{			iei=bep[1]-bsp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (s==sin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		for (i=0; i<3; i++)			bsp[i] = bep[i];		bsp[3] = s;		for (i=4; i<8; i++)			bsp[i] = bep[i-1];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lsi[1]=lsi[0];		lsi[0]=si;		/* if we are past the initial si, then we want to use it only once	*/		/* otherwise, we repeat s's											*/		if (abs(si)!=abs(isi))	{			/* do not get stuck on 1!	*/			if (isi!=1 && (abs(lsi[0])==1 && abs(si)==1))	si=0;			/* if proceeding si/2 does not take you below smin, then cut si in half	*/			else if ((s+((si/abs(si))*(abs(si)+1)/2))>=smin)															si=(si/abs(si))*(abs(si)+1)/2;			/* if proceeding si/2 does takes you below smin, then reverse si	*/			else											si/=-1*(si/abs(si))*(abs(si)+1)/2;			}		/* if on the absolute original si, then go with it unless we are in danger of dropping below the minimum	*/		else if ((s+si)<smin)								si/=-1*(si/abs(si))*(abs(si)+1)/2;		}	/* end cases of improved richness parameter */	/* optimal richness is overshot */	else {		s=bsp[3];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (si==isi && s==sin)	{			lsi[1]=lsi[0];			lsi[0]=si;			if (abs(lsi[1])==1 && abs(lsi[0])==1)	si=0;			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(si)==abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			/* go towards the one with the higher likelihood */			if (abs(lsi[0])==1 && abs(lsi[1])==1)	si=0;/*			else if (ss[1]>ss[0])						si=(si/abs(si))*(abs(si)+1)/-2;	*/			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(si)<abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			if ((s-si)>=smin)						si*=-1;			else									si=(si/abs(si))*(abs(si)+1)/2;				}		}		/* do not let s exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for s < observed! 	while ((s+si)>mxs || (s+si)< smin)	{		if (s==mxs)	si*=-1;		else	si/=2;		}	*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((ss[0]>=ss[1] && ss[0]<(ss[1]+SUPINC)) && (ss[1]>=ss[2] && ss[1]<(ss[2]+SUPINC)))	si=0;		/*	if (abs(si)%2==1 && abs(si)>1)	{		if (si>0)	++si;		else		--si;		}	*/	ss[2] = ss[1];	ss[1] = bep[0];	}	/* end search for best richness parameter	*/free_dvector(obsrvd);return bsp;}/* CALCULATE LIKELIHOOD OF THE BEST Gamma SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- bsp[0]: log likelihood	- bsp[1]: alpha = beta of gamma distribution	- bsp[2]: distribution modifier	- bsp[3]: optimal richness	- bsp[4]: 1st quartile recovery rate	- bsp[5]: 2nd quartile recovery rate	- bsp[6]: 3rd quartile recovery rate	- bsp[7]: 4th quartile recovery rateCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *rate_fit_mul_gammaone(int *empdist, int ntaxa, int ncoll){int i, j, k;				/* LOOP VARIABLE														*/int s = 0;					/* LOOP RICHNESS														*/int si;						/* richness increment													*/int isi;					/* initial richness increment each loop									*/int lsi[2];					/* previous richness increment											*/int sin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxs=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 0.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double r = 0.000f;			/* "base" rate 															*/double rin = 0.001f;		/* initial "base" rate 													*/double rmin = 0.001f;		/* minimum "base" rate 													*/double rmax = 1.000f;		/* maximum "base" rate 													*/double rlast;				/* prior "base" rate 													*/double ri;					/* "base" rate alteration												*/double mri;					/* minimum "base" rate alteration										*/double lri;					/* prior alteration of base rate										*/double rs[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double ss[3];				/* previous richness log likelihoods (cell number = num previous).		*/double brp[6];				/* BEST decay for hypothesized evenness at given S - return array format */double bep[7];				/* BEST decay for hypothesized evenness at given S - return array format */double *bsp;				/* BEST richness parameters - return array								*/double pbrs;				/* previous best support for base rate									*/double pbes;				/* previous best support for modal decay								*/double pbss;				/* previous best support for richness									*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *fitdist, *fitdist2;	/* fit distribution														*/double x;					/* sum of expected number of taxa										*/int	mxt;/*int minoc;					/* minimum number of occurrences										*/int smin;					/* do not let this get hung up on bad richnesses with good proportions	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.//FILE	*fopen();//FILE 	*debugfile;//debugfile=fopen("fixinglognormal_mul.txt","w");bsp=dvector(8);for (i=0; i<8; i++) bsp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll+1);/* use Chao 2 estimator to get seed richness */sin=chao2(empdist,ntaxa);smin=sin-(sin/10);isi=si=ntaxa/4;if (si<2)	si=2;lsi[0]=lsi[1]=0;ein=1.0f;iei=ein/10;pbss=0.0f;for (i=0; i<4; i++) bsp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ss[i]= -1.0*DBL_MAX;/* adjust true richness until that fails to improve likelihood	*/for (s=sin; abs(si)>0 && s>=smin; s+=si)	{//	fprintf(debugfile,"starting s = %d\n",s);	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	/* generally speaking, if you decrease richness, then you increase the probability of observation	*/	/* 		by increasing evenness, which means looking at lower values of ev.							*/	if (s!=sin && s<bsp[3])			if (ei>0)	ei*=-1;	else if (s!=sin && s>bsp[3])	if (ei<0)	ei*=-1;	/* added 2012-09-14: reduce the number of times you calculate a normal curve!	*/	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {				/* generate log-normal distribution with richness s and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,s);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */				/* added 2012-09-14 to reduce computation time	*///		fprintf(debugfile,"%10.9f\n",ev);		fitdist=gammapartitionsrev(ev,ev,s);						fitdist2=dvector(s);		/* NOW, vary base r	*/		rin=empdist[ntaxa-(((int) obsrvd[1])/2)]/((double) ncoll) / fitdist[ntaxa-(((int) obsrvd[1])/2)];		rmax=1/fitdist[0];		if (rmax<rin)	rin=rmax/2;		rlast=1.0f;		ri=rin/10;		mri=rin/100;		pbrs=0.0f;		brp[0]=-1.0*DBL_MAX;		mxt=0;		/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*///		fprintf(debugfile,"start at r=%10.9f\n",rin);		for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{//			fprintf(debugfile,"s=%d, ev=%10.9f, r=%10.9f",s,ev,r);//			rescaledvector(fitdist,s,(r/rlast));			proportionaldvector(fitdist,fitdist2,r,s);			expect=expoccurrences(fitdist2,s,ncoll);			expect[0]=0;			x=sumdvector(expect,ncoll+1);			for (i=1; i<=ncoll; ++i)	expect[i]/=x;			rs[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	/**/			free_dvector(expect);//			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);						if (rs[0]>=brp[0])	{				pbrs=brp[0];				es[0]=brp[0]=rs[0];				brp[1]=r;		/* store modifier!	*/				x=0.875;				for (j=2; j<6; ++j)	{					k=x*s;					brp[j]=fitdist2[k];					x-=0.25;					}								/* if we've reduced absolute ri, then we do not want to repeat an r	*/				if (ri!=fabs(rin/10))	ri/=2;				lri=ri;				}			else	{				r-=ri;						/* go back to prior r	*/				x=ri;				if (ri==rin/10)	{					if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/					else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/					}				else if (ri==fabs(lri))		/* we just flipped, so decrease the change			*/					ri/=2;				else						/* we probably went the wrong way: reverse direction	*/					ri*=-1;				lri=x;				}			rlast=r;						/* we might need to limit this routine!	*/			++mxt;			if (mxt==10)	r=rmax;			}	/* finish varying base r	*/		/************* BEST BASE r found!!!!!  **************/		/*Debugging line */		if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",s,ev,es[0]);//		fprintf(debugfile,"finished with ev=%10.9f\n",ev);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*/			pbes = bep[0];								/* save last best ssq for evenness 	*/			ss[0]=bep[0] = es[0];						/* STORE FIT 						*/			bep[1] = ev;								/* STORE magnitude 					*/			for (j=2; j<7; ++j)				bep[j]=brp[j-1];						/* store rate modifier and quartiles	*//*			bep[2] = brp[1];							/* STORE rate modifier				*/ 			/* added 2012-10-16: store quartiles	*/						/* while we are getting better on the initial increment, or its negative, just ride with it			*/			if (fabs(ei)==fabs(iei))	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei*=-1;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/		if ((ev+ei)<=emin)	{			if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/			else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/			}		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		free_dvector(fitdist);		free_dvector(fitdist2);		}	/* end search for best magnitude parameter	*/		/* 2012-09-14: added to reduce calcuations of normal curve	*///	fprintf(debugfile,"finished with s=%d\n",s);	/* if this richness is better than the last */	if (bep[0] >= bsp[0]) {								/* IF BETTER THAN BEST FIT */				/* try to avoid long flat slopes	*///		if ((bep[0]-bsp[0])<smin)	++flat;//		else						flat=0;				/* reset evenness incrementer */		if (s!=sin)	{			iei=bep[1]-bsp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (s==sin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		for (i=0; i<3; i++)			bsp[i] = bep[i];		bsp[3] = s;		for (i=4; i<8; i++)			bsp[i] = bep[i-1];		ein=bep[1];										/* set initial decay to best decay found so far */ 		lsi[1]=lsi[0];		lsi[0]=si;		/* if we are past the initial si, then we want to use it only once	*/		/* otherwise, we repeat s's											*/		if (abs(si)!=abs(isi))	{			/* do not get stuck on 1!	*/			if (isi!=1 && (abs(lsi[0])==1 && abs(si)==1))	si=0;			/* if proceeding si/2 does not take you below smin, then cut si in half	*/			else if ((s+((si/abs(si))*(abs(si)+1)/2))>=smin)															si=(si/abs(si))*(abs(si)+1)/2;			/* if proceeding si/2 does takes you below smin, then reverse si	*/			else											si/=-1*(si/abs(si))*(abs(si)+1)/2;			}		/* if on the absolute original si, then go with it unless we are in danger of dropping below the minimum	*/		else if ((s+si)<smin)								si/=-1*(si/abs(si))*(abs(si)+1)/2;		}	/* end cases of improved richness parameter */	/* optimal richness is overshot */	else {		s=bsp[3];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (si==isi && s==sin)	{			lsi[1]=lsi[0];			lsi[0]=si;			if (abs(lsi[1])==1 && abs(lsi[0])==1)	si=0;			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(si)==abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			/* go towards the one with the higher likelihood */			if (abs(lsi[0])==1 && abs(lsi[1])==1)	si=0;/*			else if (ss[1]>ss[0])						si=(si/abs(si))*(abs(si)+1)/-2;	*/			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(si)<abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			if ((s-si)>=smin)						si*=-1;			else									si=(si/abs(si))*(abs(si)+1)/2;				}		}		/* do not let s exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for s < observed! 	while ((s+si)>mxs || (s+si)< smin)	{		if (s==mxs)	si*=-1;		else	si/=2;		}	*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((ss[0]>=ss[1] && ss[0]<(ss[1]+SUPINC)) && (ss[1]>=ss[2] && ss[1]<(ss[2]+SUPINC)))	si=0;		/*	if (abs(si)%2==1 && abs(si)>1)	{		if (si>0)	++si;		else		--si;		}	*/	ss[2] = ss[1];	ss[1] = bep[0];	}	/* end search for best richness parameter	*/free_dvector(obsrvd);return bsp;}/* CALCULATE LIKELIHOOD OF BEST UNIFORM RECOVERY RATE GIVEN FINDS AND POSSIBLE FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- bep[0]: log likelihood	- bep[1]: preservation rate	- bep[2]: optimal richness			COMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *rate_fit_Pois_uni(int *empdist, int ntaxa, int ncoll) {int i=0;					/* LOOP VARIABLE														*/int rin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxr=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emax = 1.00f;		/* maximum sampling														*/double emin=0.0000000001f;	/* minimum that we'll evaluate magnitude change to consider				*/double ein = 0.000f;		/* initial slope														*/double iei = 0.000f;		/* initial recovery rate												*/double ei = 0.000f;			/* how much to increment recovery rate in each loop						*/double mei=0.000001f;		/* minimum evenness increment											*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double r;					/* best richness														*/double *bep;				/* BEST richness parameters - return array								*/double pbes=0.0f;				/* previous best support for modal decay								*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double x;					/* sum of expected number of taxa									*///double smin=0.05f;			/* if we increment log-likelihood by only this much 3 times in a row, then quit	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.bep=dvector(3);for (i=0; i<3; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll);/* use Chao 2 estimator to get seed richness */rin=chao2(empdist,ntaxa);x = sumivector(empdist,ntaxa);ein = (x/((double) rin))/((double) ncoll);iei=ei=ein/10;for (ev = ein; (((ev>=emin && ev<=emax) && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {			/* generate log-normal distribution with richness r and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,r);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */	//		cleardvector(fitdist,r,ev);	/* find the expected proportions of taxa with 0Éx finds */	expect=binomialvector(ncoll,ev);	x=1-expect[0];	r=((double) ntaxa)/x;	expect[0]=0;	for (i=1; i<=ncoll; ++i)	expect[i]*=r; 	es[0]=lnPoisson_vector_part(expect,obsrvd,ncoll,1);	free_dvector(expect);	/*Debugging line */	if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",r,ev,es[0]);	if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT */		pbes = bep[0];								/* save last best ssq for evenness */		bep[0] = es[0];								/* STORE FIT */		bep[1] = ev;								/* STORE UNIFORM RECOVERY */		bep[2] = r;									/* STORE INFERRED TAXA	*/			/* while we are getting better on the initial increment, or its negative, just ride with it			*/		if (fabs(ei)==fabs(iei))	{			lei[1]=lei[0];			lei[0]=ei;			if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			/* if we are using the original incrementer */			if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that					if (es[0]>es[2])	ei/=2;				else				ei/=-2;*/				if ((ev-ei)>emin)		ei*=-1;				else					ei/=2;				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*/			/*	if (es[0]>es[1])	ei/=2;	*/				if (fabs(lei[0])==fabs(lei[1]))	{					ei/=-2;					if ((ev+ei)<emin)	ei/=-1;					}				else	{					ei/=-1;					if ((ev+ei)<emin)	ei/=-2;					}				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{			lei[1]=lei[0];			lei[0]=ei;			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*			if (es[0]>es[2])	ei/=2;								*/			if (fabs(lei[0])==fabs(lei[1]))	ei/=2;			/* otherwise go to ev-x/2									*/			else							ei*=-1;			}		ev=bep[1];		}	/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/	if ((ev+ei)<=emin)	{		if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/		else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/		}	es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}free_dvector(obsrvd);return bep;}/* CALCULATES LIKELIHOOD OF AN AD HOC BEST-FIT DISTRIBUTION ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)RETURNS:	- es: log likelihoodCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double rate_fit_Pois_best(int *empdist, int ntaxa, int ncoll){double 	es=0.0f;				/* m for loop																*/double 	*obsrvd;				/* observed number of species with 0Émax finds								*//*double *fitdist;			/* fit distribution															*//* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll+1);es=lnPoisson_vector_part(obsrvd,obsrvd,ncoll,1);	free_dvector(obsrvd);return es;}/* CALCULATE LIKELIHOOD THAT A GIVEN DISTRIBUTION FITS THE GEOMETRIC SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa (size of array)	- ncoll (integer)RETURNS:	- bep[0]: log likelihood	- bep[1]: slope of geometric series	- bep[2]: rate modifier			COMMENTS:	- SUPINC, FITINC defined in header file*************************************************************************************************/double *rate_fit_Pois_geo(int *empdist, int ntaxa, int ncoll){int i = 0;					/* LOOP VARIABLE													*/int s = 0;					/* LOOP RICHNESS													*/int unqfnd=0;				/* number of different counts (=ncoll if all counts unique, =1 if all species have X finds )*/double r = 0.000f;			/* "base" rate 												*/double rin = 0.001f;		/* initial "base" rate 												*/double rmin = 0.001f;		/* minimum "base" rate 												*/double rmax = 1.000f;		/* maximum "base" rate 												*/double rlast;				/* prior "base" rate 												*/double ri;					/* "base" rate alteration											*/double mri;					/* minimum "base" rate alteration									*/double lri;					/* prior alteration of base rate									*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double evlast = 0.000f;		/* prior ev															*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double rs[3];double brp[2];double es[3];				/* previous log likelihoods (cell number = num previous).			*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist, *fitdist2;	/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbrs;				/* previous best support for base rate								*/double pbes;				/* previous best support for decay rate								*/int smin;					/* do not let this get hung up on bad richnesses with good proportions	*/int	mxt;double x, y;//FILE	*fopen();//FILE 	*debugfile;//debugfile=fopen("fixinggeometric_poi.txt","w");/* use Chao 2 estimator to get seed richness */i=chao2(empdist,ntaxa);smin=i-(i/10);bep=dvector(2);for (i=0; i<2; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll+1);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in ntaxa species */if (empdist[ntaxa-1]>=1)/*	ein=pow(empdist[0],(((double) empdist[ntaxa-1])/((double) ntaxa)));	*/	ein=pow(10,(log10(empdist[0])-log10(empdist[ntaxa-1]))/((double) (ntaxa-1)));else/*	ein=pow(empdist[0],1/((double) ntaxa));	*/	ein=pow(10,(log10(empdist[0])-1)/((double) (ntaxa-1)));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[ntaxa-1])	ein=1.0f;iei=ein-1;if (ei==0)	ei=0.00001f;pbes = 0.0f;/*	ei = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;lei[0]=lei[1]=0.0f;ei=iei;while (ei+ein<= emin)	ei/=2;for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {			x=1+((log(pow(10,-9))-log(1-(1/ev)))/log(1/ev));	s=x;	if ((x-s)>0.5)	++s;	//	fprintf(debugfile,"%10.9f\n",ev);	if (s>=smin)	{	//		fprintf(debugfile,"s ok for %10.9f\n",ev);		/* generate geometric distribution with richness s and decay of ev */		fitdist = proportional_geo_distribution(1/ev,pow(10,-9));				/* MAKE DISTRIBUTION *//*		rin=empdist[0]/((double) ncoll) / fitdist[0];	*/		/* set rescaling so that the median expected occurrences matches median observed	*/		if (ntaxa%2==1)			rin=empdist[ntaxa/2]/((double) ncoll)/fitdist[ntaxa/2];		else			rin=0.5*((empdist[ntaxa/2]/((double) ncoll)/fitdist[ntaxa/2])+(empdist[ntaxa/2]/((double) ncoll)/fitdist[(ntaxa/2)-1]));		rmax=1/fitdist[0];		if (rmax<rin)	rin=rmax/2;		rlast=1.0f;		ri=rin/10;		mri=rin/100;		pbrs=0.0f;		brp[0]=-1.0*DBL_MAX;		mxt=0;		fitdist2=dvector(s);//		fprintf(debugfile,"start at r=%10.9f\n",rin);		/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*/		for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{//			fprintf(debugfile,"ev=%10.9f, r=%10.9f",ev,r);			//rescaledvector(fitdist,s,(r/rlast));			proportionaldvector(fitdist,fitdist2,r,s);			expect=expoccurrences(fitdist2,s,ncoll);			expect[0]=0;			rs[0]=lnPoisson_vector_part(expect,obsrvd,ncoll,1);//			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);			free_dvector(expect);						if (rs[0]>=brp[0])	{				pbrs=brp[0];				es[0]=brp[0]=rs[0];				brp[1]=r;				/* if we've reduced absolute ri, then we do not want to repeat an r	*/				if (ri!=fabs(rin/10))	ri/=2;				lri=ri;				}			else	{				r-=ri;						/* go back to prior r	*/				x=ri;						/* save this for lri	*/				y=fabs(lri);				/* for debugging		*/				if (ri==rin/10)	{					if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/					else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/					}				else if (fabs(ri)==fabs(lri))		/* we just flipped, so decrease the change			*/					ri/=2;				else						/* we probably went the wrong way: reverse direction	*/					ri*=-1;				lri=x;				}			rlast=r;				/* keep this here in case we start off well and don't want a full initial step up or down	*/			/* we might need to limit this routine!	*/			++mxt;			if (mxt==10)	r=rmax;			}		free_dvector(fitdist);		free_dvector(fitdist2);		}			else	es[0]=-1*DBL_MAX;//	fprintf(debugfile,"finished with ev=%10.9f\n",ev);	/*Debugging line */	if (ev<=emin) printf("\nDANGER: Geo R=%d, ev=%f, S=%f ",s,ev,es[0]);	if (brp[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*///		fprintf(debugfile,"ev=%10.9f is better with lnL=%10.9f at r=%10.9f\n",ev,brp[0],brp[1]);		pbes = bep[0];								/* save last best ssq for evenness 	*/		bep[0] = brp[0];							/* STORE FIT 						*/		bep[1] = ev;								/* STORE SLOPE 						*/		bep[2] = brp[1];							/* store base rate modifier			*/				/* while we are getting better on the initial increment, just ride with it			*/		if (ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;						/* added 2012-10-16: it keeps weaseling out of reversing failed first alteration	*/			if (evlast==ein && ei==iei)				ei*=-1;			else if (ev==(ein+iei))	{				ei/=-2;				}			else if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that	*//*				if (es[0]>es[2])	ei/=2;				else				ei/=-2;	*/				ei/=2;						/* redone 2009.03.20 to get this to search properly	*/				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*//*				if (es[0]>es[1])	ei/=2;				else				ei/=-2;	*/				if (fabs(lei[0])==fabs(ei))	ei/=2;				else						ei*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || (2*fabs(ei)==fabs(lei[0])))	{			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4				if (es[0]>es[2])	ei/=2;			/* otherwise go to ev-x/2												else				ei*=-1;	*/			if (fabs(lei[0])==ei)		{				lei[1]=lei[0];				lei[0]=ei;				ei/=2;					}			else	{				lei[1]=lei[0];				lei[0]=ei;				ei*=-1;				}			}		ev=bep[1];		}			evlast=ev;	/* make sure that ei does not take ev below 1.0 */	while (ev+ei<= emin)	{		if (fabs(lei[0])==fabs(lei[1]))	ei/=2;		else							ei=-1*lei[0];		}			es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}//fclose(debugfile);free_dvector(obsrvd);return bep;}/* CALCULATE LIKELIHOOD OF THE BEST UNTRUNCATED LOG-NORMAL SERIES ASSUMING A MULTINOMIAL DISTRIBUTION FOR EXPECTED SPECIES WITH X FINDS. NEEDS:	- empdist (array with sorted absolute abundance)... MUST be sorted from highest to lowest	- ntaxa: number of sampled taxa in a bin	- ncoll: number of collections in a binRETURNS:	- bsp[0]: log likelihood	- bsp[1]: magnitude of increase per octave	- bsp[2]: modified initial rate	- bsp[3]: optimal richnessCOMMENTS:	- SUPINC, FITINC defined in header file*****************************************************************************************************/double *rate_fit_Pois_lgn(int *empdist, int ntaxa, int ncoll){int i=0;					/* LOOP VARIABLE														*/int s = 0;					/* LOOP RICHNESS														*/int si;						/* richness increment													*/int isi;					/* initial richness increment each loop									*/int lsi[2];					/* previous richness increment											*/int sin=0;					/* initial richness to use in each search (begins as ntaxa)				*/int mxs=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double r = 0.000f;			/* "base" rate 															*/double rin = 0.001f;		/* initial "base" rate 													*/double rmin = 0.001f;		/* minimum "base" rate 													*/double rmax = 1.000f;		/* maximum "base" rate 													*/double rlast;				/* prior "base" rate 													*/double ri;					/* "base" rate alteration												*/double mri;					/* minimum "base" rate alteration										*/double lri;					/* prior alteration of base rate										*/double rs[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double ss[3];				/* previous richness log likelihoods (cell number = num previous).		*/double brp[3];				/* BEST decay for hypothesized evenness at given S - return array format */double bep[3];				/* BEST decay for hypothesized evenness at given S - return array format */double *bsp;				/* BEST richness parameters - return array								*/double pbrs;				/* previous best support for base rate									*/double pbes;				/* previous best support for modal decay								*/double pbss;				/* previous best support for richness									*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*/double *normhist;			/* gives S partitions along a normal curve where S will match richness	*/double *fitdist, *fitdist2;	/* fit distribution												*/double mdmx;double spar;				/* area under lognormal curve										*/double x;					/* sum of expected number of taxa									*/int	mxt;int smin;					/* do not let this get hung up on bad richnesses with good proportions	*///int	flat=0;					/* counter for flattened increase in log likelihood		*.FILE	*fopen();FILE 	*debugfile;debugfile=fopen("fixinglognormal_pois.txt","w");bsp=dvector(4);for (i=0; i<4; i++) bsp[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,ntaxa,ncoll+1);/* use Chao 2 estimator to get seed richness */sin=chao2(empdist,ntaxa);smin=sin-(sin/10);isi=si=ntaxa/4;if (si<2)	si=2;lsi[0]=lsi[1]=0;if (2*sin<10)			mdmx=1.5;else if (2*sin<20)		mdmx=2.0;else if (2*sin<75)		mdmx=2.5;else if (2*sin<350)		mdmx=3.0;else if (2*sin<2000)	mdmx=3.5;else if (2*sin<15000)	mdmx=4.0;else 					mdmx=4.5;if (sin%2==1)				s=empdist[sin/2];else						s=(((double) empdist[sin/2])+((double) empdist[(sin/2)-1]))/2;if (sin/2 < ntaxa)			ein = pow(e,(log(((double) empdist[0])/((double) empdist[sin/2]))/mdmx));else	{	if (empdist[ntaxa-1]>0)	ein = pow(e,(log(((double) empdist[0])/((double) empdist[ntaxa-1]))/mdmx));	else					ein = pow(e,log(((double) empdist[0])/mdmx));	}if (ein==1)	ein=1.20f;iei=ein-1;pbss=0.0f;for (i=0; i<4; i++) bsp[i]=-1.0*DBL_MAX;for (i=0; i<3; ++i)	ss[i]= -1.0*DBL_MAX;/* adjust true richness until that fails to improve likelihood	*/for (s=sin; abs(si)>0 && s>=smin; s+=si)	{	fprintf(debugfile,"starting s = %d\n",s);	obsrvd[0]=0;	pbes = 0.0f;	/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/	for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;	for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;	lei[0]=lei[1]=0.0f;	ei=iei;	/* generally speaking, if you decrease richness, then you increase the probability of observation	*/	/* 		by increasing evenness, which means looking at lower values of ev.							*/	if (s!=sin && s<bsp[3])			if (ei>0)	ei*=-1;	else if (s!=sin && s>bsp[3])	if (ei<0)	ei*=-1;	/* added 2012-09-14: reduce the number of times you calculate a normal curve!	*/	normhist=normhistogram(s);	fitdist=dvector(s);	fitdist2=dvector(s);	/* increment slope until that fails to improve likelihood or resolution limit reached */	for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {				/* generate log-normal distribution with richness s and decay of magnitude of increase ev *//*		fitdist=proportional_lgn_distribution(ev,s);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */				/* added 2012-09-14 to reduce computation time	*/		fprintf(debugfile,"%10.9f\n",ev);		spar=0.0f;		for (i=0; i<s; ++i)	{			fitdist[i]=pow(ev,normhist[i]);			spar+=fitdist[i];			}		for (i=0; i<s; ++i)	fitdist[i]/=spar;				mxt=0;				/* NOW, vary base r	*///		rin=empdist[0]/((double) ncoll) / fitdist[0];		rin=empdist[ntaxa-(((int) obsrvd[1])/2)]/((double) ncoll) / fitdist[ntaxa-(((int) obsrvd[1])/2)];		rmax=1/fitdist[0];		if (rmax<rin)	rin=rmax/2;		rlast=1.0f;		ri=rin/10;		mri=rin/100;		pbrs=0.0f;		brp[0]=-1.0*DBL_MAX;				/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*/		fprintf(debugfile,"start at r=%10.9f\n",rin);		for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{			fprintf(debugfile,"s=%d, ev=%10.9f, r=%10.9f",s,ev,r);//			rescaledvector(fitdist,s,(r/rlast));			proportionaldvector(fitdist,fitdist2,r,s);			expect=expoccurrences(fitdist2,s,ncoll);			expect[0]=0;			rs[0]=lnPoisson_vector_part(expect,obsrvd,ncoll,1);			free_dvector(expect);			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);						if (rs[0]>=brp[0])	{				pbrs=brp[0];				es[0]=brp[0]=rs[0];				brp[1]=r;		/* store modifier!	*/								/* if we've reduced absolute ri, then we do not want to repeat an r	*/				if (ri!=fabs(rin/10))	ri/=2;				lri=ri;				}			else	{				r-=ri;						/* go back to prior r	*/				x=ri;				if (ri==rin/10)	{					if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/					else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/					}				else if (ri==fabs(lri))		/* we just flipped, so decrease the change			*/					ri/=2;				else						/* we probably went the wrong way: reverse direction	*/					ri*=-1;				lri=x;				}			rlast=r;						/* we might need to limit this routine!	*/			++mxt;			if (mxt==10)	r=rmax;			}	/* finish varying base r	*/		/************* BEST BASE r found!!!!!  **************/		/*Debugging line */		if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",s,ev,es[0]);		fprintf(debugfile,"finished with ev=%10.9f\n",ev);		if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*/			pbes = bep[0];								/* save last best ssq for evenness 	*/			ss[0]=bep[0] = es[0];						/* STORE FIT 						*/			bep[1] = ev;								/* STORE magnitude 					*/			bep[2] = brp[1];							/* STORE rate modifier				*/ 						/* while we are getting better on the initial increment, or its negative, just ride with it			*/			if (fabs(ei)==fabs(iei))	{				lei[1]=lei[0];				lei[0]=ei;				if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 				}			/* if we have a later improvement, wander halfway back to the last improvement 	*/			/* (remember, we always start at the most likely slope up to that point			*/			else	{				lei[1]=lei[0];				lei[0]=ei;				ei/=-2;				if ((ev+ei)<=emin)	ei*=-1;				}			}							/* If likelihood has not increased, then reset and change the increment  value	*/		else	{			/* if we went from x -> -x, then we want to cut the increment in half */			if (ei==-1*lei[0] || ei==iei)	{				lei[1]=lei[0];				lei[0]=ei;				/* if we are using the original incrementer */				if (ei==iei)	{					/* determine whether es[0] or es[2] is the second best - move towards that						if (es[0]>es[2])	ei/=2;					else				ei/=-2;*/					if ((ev-ei)>emin)		ei*=-1;					else					ei/=2;					}				else	{					/* determine whether es[0] or es[1] is the second best - move towards that	*/				/*	if (es[0]>es[1])	ei/=2;	*/					if (fabs(lei[0])==fabs(lei[1]))	{						ei/=-2;						if ((ev+ei)<emin)	ei/=-1;						}					else	{						ei/=-1;						if ((ev+ei)<emin)	ei/=-2;						}					}				}			/* if we just divided in half, then we want to reverse the increment */			else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{				lei[1]=lei[0];				lei[0]=ei;				/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*				if (es[0]>es[2])	ei/=2;								*/				if (fabs(lei[0])==fabs(lei[1]))	ei/=2;				/* otherwise go to ev-x/2									*/				else							ei*=-1;				}			ev=bep[1];			}		/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/		if ((ev+ei)<=emin)	{			if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/			else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/			}		es[2] = es[1];									/* Store last 2 attempts to identify	*/		es[1] = es[0];									/* when the peak is past 				*/		}	/* end search for best magnitude parameter	*/		/* 2012-09-14: added to reduce calcuations of normal curve	*/	free_dvector(normhist);	free_dvector(fitdist);	free_dvector(fitdist2);	fprintf(debugfile,"finished with s=%d\n",s);	/* if this richness is better than the last */	if (bep[0] >= bsp[0]) {								/* IF BETTER THAN BEST FIT */				/* try to avoid long flat slopes	*///		if ((bep[0]-bsp[0])<smin)	++flat;//		else						flat=0;				/* reset evenness incrementer */		if (s!=sin)	{			iei=bep[1]-bsp[1];			/* set ei to the difference bn. current & former best */			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		else if (s==sin || ei==0)	{			iei=bep[1]-ein;			if (fabs(iei)<0.01)			iei=0.01*(iei/fabs(iei));			}		for (i=0; i<3; i++)			bsp[i] = bep[i];		bsp[3] = s;		ein=bep[1];										/* set initial decay to best decay found so far */ 		lsi[1]=lsi[0];		lsi[0]=si;		/* if we are past the initial si, then we want to use it only once	*/		/* otherwise, we repeat s's											*/		if (abs(si)!=abs(isi))	{			/* do not get stuck on 1!	*/			if (isi!=1 && (abs(lsi[0])==1 && abs(si)==1))	si=0;			/* if proceeding si/2 does not take you below smin, then cut si in half	*/			else if ((s+((si/abs(si))*(abs(si)+1)/2))>=smin)															si=(si/abs(si))*(abs(si)+1)/2;			/* if proceeding si/2 does takes you below smin, then reverse si	*/			else											si/=-1*(si/abs(si))*(abs(si)+1)/2;			}		/* if on the absolute original si, then go with it unless we are in danger of dropping below the minimum	*/		else if ((s+si)<smin)								si/=-1*(si/abs(si))*(abs(si)+1)/2;		}	/* end cases of improved richness parameter */	/* optimal richness is overshot */	else {		s=bsp[3];				/* step back to best richness	 */				/* if we start off going downhill, then go the other way */		if (si==isi && s==sin)	{			lsi[1]=lsi[0];			lsi[0]=si;			if (abs(lsi[1])==1 && abs(lsi[0])==1)	si=0;			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is opposite of the last, then cut it in  half */		else if (abs(si)==abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			/* go towards the one with the higher likelihood */			if (abs(lsi[0])==1 && abs(lsi[1])==1)	si=0;/*			else if (ss[1]>ss[0])						si=(si/abs(si))*(abs(si)+1)/-2;	*/			else									si=(si/abs(si))*(abs(si)+1)/2;			}		/* if this increment is less then the last, then reverse it - unless that takes us too low	*/		else if (abs(si)<abs(lsi[0]))	{			lsi[1]=lsi[0];			lsi[0]=si;			if ((s-si)>=smin)						si*=-1;			else									si=(si/abs(si))*(abs(si)+1)/2;				}		}		/* do not let s exceed 5000 - that is the maximum richness that we can evaluate */	/* do not bother going for s < observed! 	while ((s+si)>mxs || (s+si)< smin)	{		if (s==mxs)	si*=-1;		else	si/=2;		}	*/		/* geometric will go on and on forever with miniscule increases when it is a very poor fit */	if ((ss[0]>=ss[1] && ss[0]<(ss[1]+SUPINC)) && (ss[1]>=ss[2] && ss[1]<(ss[2]+SUPINC)))	si=0;		/*	if (abs(si)%2==1 && abs(si)>1)	{		if (si>0)	++si;		else		--si;		}	*/	ss[2] = ss[1];	ss[1] = bep[0];	}	/* end search for best richness parameter	*/free_dvector(obsrvd);return bsp;}/*If there are 12 observed shared species between bins A & B estimated to have SA=60 and SB=80 species, then there can be up to 48 shared species.  If we are looking at how many species from SB were among SA, then itis 12+X.  Given TAD for A, we can ask the probability of finding 12 species given 12É60 truly shared species. For X=0, we hypothesize 12 shared species.  That means there is a 12/60=0.2 probability that any one species inTADA is a shared species. The probability that any species i is found is: 	·1-(1-pi)^N	where:	 	pi = prob. of finding a species	 	N = sampling opportunities	So, the expected number of sampled shared species given 12 truly shared ones is:	Q= 0.2 x ·(1-[1-pi]^N).Given expectation Q, we can use Poisson probability to estimate L[12+X | 12,TAD]We can also ask what proportion of the observed should be shared. Now,	lnL[12+X] = 12 x ln(Q/SA) + 48 x ln(1-Q/SA)**************************************************************/double **modelshared(double *tad, int S1, int S2, int S1S2, int N){int a, mxsh, shared, s;double	x, y, z;double *utad;double **sharedlikes;mxsh=imin(S1,S2)-S1S2;/* sometimes distribution will be longer than we want to use (truncated tads)	*/utad=dvector(S1);equaldvector(utad,tad,S1);x=sumdvector(utad,S1);rescaledvector(utad,S1,x);sharedlikes=dmatrix(2,mxsh);z=0.0f;for (a=0; a<mxsh; ++a)	{	shared = S1S2+a;//	prior=((double) shared)/((double) S1);	for (s=0; s<S1; ++s)	{		x=N*log(1-utad[s]);		y=exp(x);		z+=y;		}	}free_dvector(utad);return (sharedlikes);}double *sharedgivenTADs(unsigned long *shad1, unsigned long *shad2, int shared, int model1, int model2, int maxtest, int ncoll1, int ncoll2){int	sS, dud=0;double *test1, *test2;double	best, lnLS;double *result;result=dvector(2);best=-1*RAND_MAX;for (sS=shared; dud<3; ++sS)	{	/* model1 = 0: use geometric; model2 = 1: use log-normal	*/	if (model1==1)	test1=mul_lgn_at_set_S_occur((int *) shad1,shared,sS,ncoll1);//	else if (model1==1)	if (model2==1)	test2=mul_lgn_at_set_S_occur((int *) shad2,shared,sS,ncoll2);		lnLS=test1[0]+test2[0];	if (lnLS>best)	{		result[0]=sS;		result[1]=lnLS;		dud=0;		}	else	{		if (sS>=maxtest)	++dud;		}	free_dvector(test1);	free_dvector(test2);	}return (result);}double *sharedgivenTADs_supportbars(unsigned long *shad1, unsigned long *shad2, int shared, int model1, int model2, int maxS, double supportbar, int ncoll1, int ncoll2){int	sS, dud=0;double *test1, *test2;double	best;double *result;result=dvector(maxS+1);for (sS=0; sS<=maxS; ++sS)	result[sS]=-1*RAND_MAX;best=-1*RAND_MAX;for (sS=shared; sS<=maxS && dud==0; ++sS)	{	/* model1 = 0: use geometric; model2 = 1: use log-normal	*/	if (model1==1)		test1=mul_lgn_at_set_S_occur((int *) shad1,shared,sS,ncoll1);	else if (model1==0)	test1=mul_geo_at_set_S_occur((int *) shad1,shared,sS,ncoll1);//	else if (model1==1)	if (model2==1)		test2=mul_lgn_at_set_S_occur((int *) shad2,shared,sS,ncoll2);	else if (model2==0)	test2=mul_geo_at_set_S_occur((int *) shad2,shared,sS,ncoll2);		result[sS]=test1[0]+test2[0];	if (result[sS]>best || sS==shared)	{		best=result[sS];		dud=0;		}	else if (abs(result[sS]-best) > supportbar) 	dud=1;	free_dvector(test2);	free_dvector(test1);	}return (result);}double *mul_lgn_at_set_S_occur(int *empdist, int Sobs, int Shyp, int ncoll){int i, j, k;				/* LOOP VARIABLE														*/int mxs=5000;				/* this is as long as we can make an array								*/double lei[2];				/* last two evenness incrementers										*/double iei;					/* initial slope increment at each richness								*/double ev = 0.000f;			/* LOOP SLOPE 															*/double emin = 1.00f;		/* min slope															*/double mxev=75.0f;			/* maximum magnitude change to consider									*/double ein = 0.000f;		/* initial slope														*/double ei = 0.000f;			/* how much to increment ev in each loop								*/double mei=0.000001f;		/* minimum evenness increment											*/double r = 0.000f;			/* "base" rate 															*/double rin = 0.001f;		/* initial "base" rate 													*/double rmin = 0.001f;		/* minimum "base" rate 													*/double rmax = 1.000f;		/* maximum "base" rate 													*/double rlast;				/* prior "base" rate 													*/double ri;					/* "base" rate alteration												*/double mri;					/* minimum "base" rate alteration										*/double lri;					/* prior alteration of base rate										*/double rs[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double es[3];				/* previous modal decay log likelihoods (cell number = num previous).	*/double ss[3];				/* previous richness log likelihoods (cell number = num previous).		*/double brp[6];				/* BEST decay for hypothesized evenness at given S - return array format */double *bep;				/* BEST richness parameters - return array								*/double pbrs;				/* previous best support for base rate									*/double pbes;				/* previous best support for modal decay								*/double *expect;				/* expected number of species with 0Émax finds							*/double *obsrvd;				/* observed number of species with 0Émax finds							*//*double *normhist;			/* gives S partitions along a normal curve where S will match richness	*/double *fitdist, *fitdist2;	/* fit distribution												*/double spar;				/* area under lognormal curve										*/double u, v, w, x, y, z;					/* sum of expected number of taxa									*/int	mxt;bep=dvector(7);for (i=0; i<2; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,Sobs,ncoll+1);obsrvd[0]=0;pbes = 0.0f;if (Sobs%2==1)	{	x=((double) (Sobs+1))/((double) (Sobs+2));	z=empdist[Sobs/2];	}else	{	x=((double) Sobs)/((double) (Sobs+1));	z=(empdist[Sobs/2]+empdist[(Sobs/2)-1])/2;	}y=normsinv(x);w=((double) empdist[0])/z;u=log(w);v=u/y;ein=pow(e,(log((double) empdist[0]/z)/y));if (ein==1)	ein=1.20f;iei=ein-1;/* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;lei[0]=lei[1]=0.0f;ei=iei;/* added 2012-09-14: reduce the number of times you calculate a normal curve!	*///normhist=normhistogram(Shyp);fitdist=dvector(Shyp);fitdist2=dvector(Shyp);for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {		/* generate log-normal distribution with richness Shyp and decay of magnitude of increase ev *///	fitdist=proportional_lgn_distribution(ev,Shyp);				/* MAKE DISTRIBUTION; removed 2012-09-14 to reduce computation time */		/* added 2012-09-14 to reduce computation time	*///		fprintf(debugfile,"%10.9f\n",ev);	spar=0.0f;	for (i=0; i<Shyp; ++i)	{//		fitdist[i]=pow(ev,normhist[i]);		x=((double) (Shyp-i))/((double) (Shyp+1));		y=normsinv(x);		fitdist[i]=pow(ev,y);		spar+=fitdist[i];		}	for (i=0; i<Shyp; ++i)	fitdist[i]/=spar;		mxt=0;		/* NOW, vary base r	*///		rin=empdist[0]/((double) ncoll) / fitdist[0];	rin=empdist[Sobs-(((int) obsrvd[1])/2)]/((double) ncoll) / fitdist[Sobs-(((int) obsrvd[1])/2)];	rmax=1/fitdist[0];	if (rmax<rin)	rin=rmax/2;	rlast=1.0f;	ri=rin/10;	mri=rin/100;	pbrs=0.0f;	brp[0]=-1.0*DBL_MAX;		/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*///		fprintf(debugfile,"start at r=%10.9f\n",rin);	for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{//			fprintf(debugfile,"Shyp=%d, ev=%10.9f, r=%10.9f",Shyp,ev,r);//			rescaledvector(fitdist,Shyp,(r/rlast));		proportionaldvector(fitdist,fitdist2,r,Shyp);		expect=expoccurrences(fitdist2,Shyp,ncoll);		expect[0]=0;		x=sumdvector(expect,ncoll+1);		for (i=1; i<=ncoll; ++i)	expect[i]/=x;		rs[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	/**/		free_dvector(expect);//			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);				if (rs[0]>=brp[0])	{			pbrs=brp[0];			es[0]=brp[0]=rs[0];			brp[1]=r;		/* store modifier!	*/			x=0.875;			for (j=2; j<6; ++j)	{				k=x*Shyp;				brp[j]=fitdist2[k];				x-=0.25;				}						/* if we've reduced absolute ri, then we do not want to repeat an r	*/			if (ri!=fabs(rin/10))	ri/=2;			lri=ri;			}		else	{			r-=ri;						/* go back to prior r	*/			x=ri;			if (ri==rin/10)	{				if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/				else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/				}			else if (ri==fabs(lri))		/* we just flipped, so decrease the change			*/				ri/=2;			else						/* we probably went the wrong way: reverse direction	*/				ri*=-1;			lri=x;			}		rlast=r;				/* we might need to limit this routine!	*/		++mxt;		if (mxt==10)	r=rmax;		}	/* finish varying base r	*/	/************* BEST BASE r found!!!!!  **************/	/*Debugging line */	if (ev<=emin) printf("\nDANGER: ln R=%d, ev=%f, S=%f ",Shyp,ev,es[0]);//		fprintf(debugfile,"finished with ev=%10.9f\n",ev);	if (es[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*/		pbes = bep[0];								/* save last best ssq for evenness 	*/		ss[0]=bep[0] = es[0];						/* STORE FIT 						*/		bep[1] = ev;								/* STORE magnitude 					*/		for (j=2; j<7; ++j)			bep[j]=brp[j-1];						/* store rate modifier and quartiles	*//*			bep[2] = brp[1];							/* STORE rate modifier				*/ 		/* added 2012-10-16: store quartiles	*/				/* while we are getting better on the initial increment, or its negative, just ride with it			*/		if (fabs(ei)==fabs(iei))	{			lei[1]=lei[0];			lei[0]=ei;			if ((ev+ei)<=emin)	ei/=-2;				/* 6/2/05: if we are dropping towards the min, back up just to make sure we search space */ 			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			/* if we are using the original incrementer */			if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that					if (es[0]>es[2])	ei/=2;				else				ei/=-2;*/				if ((ev-ei)>emin)		ei*=-1;				else					ei/=2;				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*/			/*	if (es[0]>es[1])	ei/=2;	*/				if (fabs(lei[0])==fabs(lei[1]))	{					ei/=-2;					if ((ev+ei)<emin)	ei/=-1;					}				else	{					ei/=-1;					if ((ev+ei)<emin)	ei/=-2;					}				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || 2*fabs(ei)==fabs(lei[0]))	{			lei[1]=lei[0];			lei[0]=ei;			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4	*			if (es[0]>es[2])	ei/=2;								*/			if (fabs(lei[0])==fabs(lei[1]))	ei/=2;			/* otherwise go to ev-x/2									*/			else							ei*=-1;			}		ev=bep[1];		}	/* make sure that ei does not take ev below 1.0 *//*		while (ev+ei<= emin)	ei/=2;	*/	if ((ev+ei)<=emin)	{		if (fabs(ei)==fabs(lei[0]))			ei=lei[0]/2;	/* this will use half of the last positive ei 	*/		else if (2*fabs(ei)==fabs(lei[0]))	ei*=-1;			/* this will happen if there is improvment		*/		}	es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	}	/* end search for best magnitude parameter	*/free_dvector(fitdist);free_dvector(fitdist2);//free_dvector(normhist);free_dvector(obsrvd);return bep;}double *mul_geo_at_set_S_occur(int *empdist, int Sobs, int Shyp, int ncoll){int i = 0;					/* LOOP VARIABLE													*/int minf;					/* finds for rarest taxon											*/int unqfnd=0;				/* number of different counts (=ncoll if all counts unique, =1 if all species have X finds )*/double	end;double r = 0.000f;			/* "base" rate 												*/double rin = 0.001f;		/* initial "base" rate 												*/double rmin = 0.001f;		/* minimum "base" rate 												*/double rmax = 1.000f;		/* maximum "base" rate 												*/double rlast;				/* prior "base" rate 												*/double ri;					/* "base" rate alteration											*/double mri;					/* minimum "base" rate alteration									*/double lri;					/* prior alteration of base rate									*/double ev = 0.000f;			/* LOOP SLOPE 														*/double emin = 1.000000001f;	/* min slope														*/double ein = 0.000f;		/* initial slope													*/double ei = 0.000f;			/* how much to increment ev in each loop							*/double evlast = 0.000f;		/* prior ev															*/double lei[2];				/* last two slope increments										*/double iei;					/* initial slope increment at each richness							*/double mei=0.000001f;		/* minimum evenness increment										*/double rs[3];double brp[2];double es[3];				/* previous log likelihoods (cell number = num previous).			*/double *bep;				/* BEST ev PARAMETERS (DISTRIBUTION SLOPE) - return array format	*/double *fitdist, *fitdist2;	/* fit distribution													*/double *expect;				/* expected number of species with 0Émax finds						*/double *obsrvd;				/* observed number of species with 0Émax finds						*/double pbrs;				/* previous best support for base rate								*/double pbes;				/* previous best support for decay rate								*/int	mxt;double x, y;//FILE	*fopen();//FILE 	*debugfile;//debugfile=fopen("fixinggeometric_mul.txt","w");/* use Chao 2 estimator to get seed richness */bep=dvector(2);for (i=0; i<2; i++) bep[i]= -1.0*DBL_MAX;/* we need arrays giving both the number of taxa with x finds and all x finds with 1+ species */obsrvd=idhistogramfull(empdist,Sobs,ncoll+1);/* find a good seed value for the geometric, based on the slope that would go from max to 1 in Sobs species *//* find mid-rank of rarest taxa	*/minf=empdist[Sobs-1];end=(Sobs-1)-((obsrvd[minf]/2)-0.5);/* if there are 10 species and you go from 20 to 1 (with only #10 having 1),then you decrease 20X in 9 ranks.			That means that x^9 = 1/20 = 0.05		9*ln(x) = ln(0.05)		ln(x) = ln(0.5)/9		x = e^(ln[0.5]/9)	end = 0.0, Sobs=10,If 2 taxa have only 1, then you decrease 20X in 8.5 ranks		That means that x^8.5 = 1/20 = 0.05		8.5*ln(x) = ln(0.05)		ln(x) = ln(0.5)/8.5		x = e^(ln[0.5]/8.5)	end = 0.5, Sobs=10,					If 3 taxa have only 1, then you decrease 20X in 8 ranks		That means that x^8 = 1/20 = 0.05		8*ln(x) = ln(0.05)		ln(x) = ln(0.5)/8		x = e^(ln[0.5]/8)	end = 1.0, Sobs=10,														*/x=log(empdist[0])-log(empdist[Sobs-1]);y=((log(empdist[0])-log(empdist[Sobs-1]))/end);ein=pow(e,((log(empdist[0])-log(empdist[Sobs-1]))/end));if (ein<1.0)	ein=1.0f;if (empdist[0]==empdist[Sobs-1])	ein=1.0f;iei=(ein-1)/2;if (ei==0)	ei=0.00001f;pbes = 0.0f;/*	ei = (double) FITINC / 10;	*//* increment starting at 0.1 since we are almost never going to find slopes of 2+	*/for (i=0; i<2; i++) bep[i] = -1.0*DBL_MAX;for (i=0; i<3; i++) es[i] = -1.0*DBL_MAX;lei[0]=lei[1]=0.0f;ei=iei;//while (ei+ein<= emin)	ei/=2;for (ev = ein; ((ev>=emin && fabs(ei)>mei) && ((pbes == 0.0f) || (bep[0] > (pbes + SUPINC)))); ev += ei) {	//		fprintf(debugfile,"s ok for %10.9f\n",ev);	/* generate geometric distribution with richness s and decay of ev */	fitdist = proportional_geos_distribution(ev,Shyp);				/* MAKE DISTRIBUTION *//*		rin=empdist[0]/((double) ncoll) / fitdist[0];	*/	/* set rescaling so that the median expected occurrences matches median observed	*/	if (Shyp%2==1)		rin=empdist[Sobs/2]/((double) ncoll)/fitdist[Sobs/2];	else		rin=0.5*((empdist[Sobs/2]/((double) ncoll)/fitdist[Sobs/2])+(empdist[Sobs/2]/((double) ncoll)/fitdist[(Sobs/2)-1]));	rmax=1/fitdist[0];	if (rmax<rin)	rin=rmax/2;	rlast=1.0f;	ri=rin/10;	mri=rin/100;	pbrs=0.0f;	brp[0]=-1.0*DBL_MAX;	mxt=0;	fitdist2=dvector(Shyp);//		fprintf(debugfile,"start at r=%10.9f\n",rin);	/* vary "base" rate, using a base that makes taxon #1 the same as the empirical to begin	*/	for (r=rin; (((r>rmin && r<rmax) && fabs(ri)>mri) && (pbrs==0.0f || (brp[0]>(pbrs+SUPINC)))); r+=ri)	{		proportionaldvector(fitdist,fitdist2,r,Shyp);		expect=expoccurrences(fitdist2,Shyp,ncoll);		expect[0]=0;		x=sumdvector(expect,ncoll+1);		for (i=1; i<=ncoll; ++i)	expect[i]/=x;		rs[0]=lnmultinomsuff(obsrvd,expect,empdist[0]+1);	/**///			fprintf(debugfile,", lnL=%10.9f\n",rs[0]);		free_dvector(expect);				if (rs[0]>=brp[0])	{			pbrs=brp[0];			es[0]=brp[0]=rs[0];			brp[1]=r;			/* if we've reduced absolute ri, then we do not want to repeat an r	*/			if (ri!=fabs(rin/10))	ri/=2;			lri=ri;			}		else	{			r-=ri;						/* go back to prior r	*/			x=ri;						/* save this for lri	*/			y=fabs(lri);				/* for debugging		*/			if (ri==rin/10)	{				if (rlast==rin)	ri*=-1;	/* we immediately get off on the wrong foot			*/				else			ri/=2;	/* we improve upon rin with initial ri, but stop	*/				}			else if (fabs(ri)==fabs(lri))		/* we just flipped, so decrease the change			*/				ri/=2;			else						/* we probably went the wrong way: reverse direction	*/				ri*=-1;			lri=x;			}		rlast=r;				/* keep this here in case we start off well and don't want a full initial step up or down	*/		/* we might need to limit this routine!	*/		++mxt;		if (mxt==10)	r=rmax;		}		/* now, ask if this is better than what we had	*/	if (brp[0] >= bep[0]) {							/* IF BETTER THAN BEST FIT 			*///		fprintf(debugfile,"ev=%10.9f is better with lnL=%10.9f at r=%10.9f\n",ev,brp[0],brp[1]);		pbes = bep[0];								/* save last best ssq for evenness 	*/		bep[0] = brp[0];							/* STORE FIT 						*/		bep[1] = ev;								/* STORE SLOPE 						*/		bep[2] = brp[1];							/* store base rate modifier			*/				/* while we are getting better on the initial increment, just ride with it			*/		if (ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;			}		/* if we have a later improvement, wander halfway back to the last improvement 	*/		/* (remember, we always start at the most likely slope up to that point			*/		else	{			lei[1]=lei[0];			lei[0]=ei;			ei/=-2;			if ((ev+ei)<=emin)	ei*=-1;			}		}					/* If likelihood has not increased, then reset and change the increment  value	*/	else	{		/* if we went from x -> -x, then we want to cut the increment in half */		if (ei==-1*lei[0] || ei==iei)	{			lei[1]=lei[0];			lei[0]=ei;						/* added 2012-10-16: it keeps weaseling out of reversing failed first alteration	*/			if (evlast==ein && ei==iei)				ei*=-1;			else if (ev==(ein+iei))	{				ei/=-2;				}			else if (ei==iei)	{				/* determine whether es[0] or es[2] is the second best - move towards that	*//*				if (es[0]>es[2])	ei/=2;				else				ei/=-2;	*/				ei/=2;						/* redone 2009.03.20 to get this to search properly	*/				}			else	{				/* determine whether es[0] or es[1] is the second best - move towards that	*//*				if (es[0]>es[1])	ei/=2;				else				ei/=-2;	*/				if (fabs(lei[0])==fabs(ei))	ei/=2;				else						ei*=-1;				}			}		/* if we just divided in half, then we want to reverse the increment */		else if (ei==-1*iei || (2*fabs(ei)==fabs(lei[0])))	{			/* if ev+x/2 got closer than ev-x, back up and go to ev+x/4				if (es[0]>es[2])	ei/=2;			/* otherwise go to ev-x/2												else				ei*=-1;	*/			if (fabs(lei[0])==ei)		{				lei[1]=lei[0];				lei[0]=ei;				ei/=2;					}			else	{				lei[1]=lei[0];				lei[0]=ei;				ei*=-1;				}			}		ev=bep[1];		}			evlast=ev;	/* make sure that ei does not take ev below 1.0 */	while (ev+ei<= emin)	{		if (fabs(lei[0])==fabs(lei[1]))	ei/=2;		else							ei=-1*lei[0];		}			es[2] = es[1];									/* Store last 2 attempts to identify	*/	es[1] = es[0];									/* when the peak is past 				*/	free_dvector(fitdist);	free_dvector(fitdist2);	}//fclose(debugfile);free_dvector(obsrvd);return bep;}double *sharedrichnesssupport(int sSobs, int sSmax, int binA, int binB, int possFindsA, int possFindsB, int modelA, int modelB, int richA, int richB, double **params){int sShyp, s;double x, y, missesA=0.0f, missesB=0.0f;double *support;double *distA, *distB;support=dvector(sSmax+1);/* estimate expected proportion of missing taxa for both bins	*/if (modelA==0)	{	distA=proportional_geos_distribution(params[binA][0],richA);	rescaledvector(distA,richA,params[binA][1]);	}else if (modelA==1)	{	distA=proportional_lgn_distribution(params[binA][0],((int) params[binA][2]));	rescaledvector(distA,richA,params[binA][1]);	}if (modelB==0)	{	distB=proportional_geos_distribution(params[binB][0],richB);	rescaledvector(distB,richB,params[binB][1]);	}else if (modelB==1)	{	distB=proportional_lgn_distribution(params[binB][0],((int) params[binB][2]));	rescaledvector(distB,richB,params[binB][1]);	}missesA=0;for (s=0; s<richA; ++s)	{	x=possFindsA*log(1-distA[s]);	y=pow(e,x);	missesA+=y;	}missesB=0;for (s=0; s<richB; ++s)	{	x=possFindsB*log(1-distB[s]);	y=pow(e,x);	missesB+=y;	}missesA/=((double) richA);		/* prob. of missing a species from Bin A	*/missesB/=((double) richB);		/* prob. of missing a species from Bin B	*/for (sShyp=sSobs; sShyp<=sSmax; ++sShyp)	{	x=binomexact(sSobs,sShyp,(1-missesA));	y=binomexact(sSobs,sShyp,(1-missesB));	support[sShyp]=log(x)+log(y);	}free_dvector(distA);free_dvector(distB);return (support);}